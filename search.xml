<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>大数据OLAP组件</title>
      <link href="/2021/09/02/%E5%A4%A7%E6%95%B0%E6%8D%AEOLAP%E7%BB%84%E4%BB%B6/"/>
      <url>/2021/09/02/%E5%A4%A7%E6%95%B0%E6%8D%AEOLAP%E7%BB%84%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<h2 id="什么是-OLAP"><a href="#什么是-OLAP" class="headerlink" title="什么是 OLAP"></a>什么是 OLAP</h2><blockquote><p>OLAP(OnLine Analytical Processing)，即联机分析处理。OLAP 对业务数据执行多维分析，并提供复杂计算，趋势分析和复杂数据建模的能力。它主要用于支持企业决策管理分析，是许多商务智能（BI）应用程序背后的技术。 OLAP 使最终用户可以对多个维度的数据进行即席分析，从而获取他们所需知识，以便更好地制定决策。OLAP 技术已被定义为实现“快速访问共享的多维信息”的能力。</p></blockquote><p><strong>传统的关系型数据库</strong>采用的是 <strong>OLTP</strong>，主要数据操作是<strong>随机读写</strong>，主要采用 <strong>3NF</strong> 的实体关系模型存储数据，从而在事务处理中解决数据的冗余和一致性问题。用 E-R 模型的一个原则就是，尽量把一个表拆分，拆分的越细越好，拆分后尽量满足 3NF 范式的原则，<strong>减少冗余</strong>。</p><p>相反，OLAP 系统的主要数据操作是<strong>批量读写</strong>，事务处理中的一致性不是 OLAP 所关注的，其主要关注数据的整合，以及在一次性的复杂大数据查询和处理的性能，因此它需要采用不同的<strong>建模方法</strong>，例如<strong>维度</strong>建模。OLAP 是<strong>数据仓库</strong>系统的主要应用，支持复杂的分析操作，侧重决策支持，并且提供直观易懂的查询结果。</p><p>所以，OLAP 的核心概念有：</p><ul><li>维度（Dimension）：维度是描述与业务主题相关的一组属性，单个属性或属性集合可以构成一个维。如时间、地理位置、年龄和性别等都是维度。</li><li>维的层次（Level of Dimension）：一个维往往可以具有多个层次，例如<strong>时间维度分为年、季度、月和日</strong>等层次，<strong>地区维可以是国家、地区、省、市</strong>等层次。这里的层次表示数据细化程度，对应概念分层。</li><li>维的成员（Member of Dimension）：若维是多层次的，则不同的层次的取值构成一个维成员。部分维层次同样可以构成维成员，例如“<strong>某年某季度</strong>”、“<strong>某季某月</strong>”等都可以是时间维的成员。</li><li>度量（Measure）：表示事实在某一个维成员上的取值。例如<strong>开发部门汉族男性有 39 人，就表示在部门、民族、性别三个维度上，企业人数的事实度量</strong>。</li></ul><h2 id="OLAP-的分类"><a href="#OLAP-的分类" class="headerlink" title="OLAP 的分类"></a>OLAP 的分类</h2><h3 id="MOLAP"><a href="#MOLAP" class="headerlink" title="MOLAP"></a>MOLAP</h3><blockquote><p>MOLAP 是 OLAP的经典形式。<strong>MOLAP 将数据存储在优化的多维数组中，而不是关系数据库中</strong>。维的属性值被映射成多维数组的下标值或下标的范围，而度量数据作为多维数组的值存储在数组的单元中。由于 MOLAP 采用了新的存储结构，从物理层实现，因此又称为物理 OLAP（PhysicalOLAP）；而 ROLAP 主要通过一些软件工具或中间软件实现，物理层仍采用关系数据库的存储结构，因此称为 虚拟OLAP（VirtualOLAP）。</p></blockquote><h3 id="ROLAP"><a href="#ROLAP" class="headerlink" title="ROLAP"></a>ROLAP</h3><blockquote><p><strong>ROLAP 将分析用的多维数据存储在关系数据库中</strong>。这种方式依赖 SQL 语言实现传统 OLAP 的切片和切块功能，本质上，切片和切块等动作都等同于在 SQL 语句中添加<code>WHERE</code>子句。ROLAP 工具不使用预先计算的多维数据集，而是对标准关系数据库及其表进行查询，以获取回答问题所需的数据。ROLAP 工具具有询问任何问题的能力，因为该方法（SQL）不仅限于多维数据集的内容。</p></blockquote><h2 id="开源组件"><a href="#开源组件" class="headerlink" title="开源组件"></a>开源组件</h2><p>开源大数据 OLAP 组件，可以分为 MOLAP 和 ROLAP 两类。ROLAP 中又可细分为 MPP 数据库和 SQL 引擎两类。对于 SQL 引擎又可以再细分为基于 MPP 架构的 SQL 引擎和基于通用计算框架的 SQL 引擎：</p><p><img data-src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F4b9b8184-4d35-4f5a-b3c1-caab3a87b3dd%2FUntitled.png?table=block&id=c7827d1b-7c78-4f84-becf-45f7c8f36b7a&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=1140&userId=&cache=v2" alt="开源 OLAP"><span class="image-caption">开源 OLAP</span></p><h3 id="开源-MOLAP-系统分析"><a href="#开源-MOLAP-系统分析" class="headerlink" title="开源 MOLAP 系统分析"></a>开源 MOLAP 系统分析</h3><h4 id="Kylin"><a href="#Kylin" class="headerlink" title="Kylin"></a>Kylin</h4><p><img data-src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F893026c2-4a00-4613-8c51-d23437b30ac7%2FUntitled.png?table=block&id=00845d0c-e2d8-41b8-8ebe-85abcbb86890&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=670&userId=&cache=v2" alt="Kylin"><span class="image-caption">Kylin</span></p><blockquote><p>Apache Kylin 是一个开源的分布式分析引擎，提供 Hadoop/Spark 之上的 SQL 查询接口及多维分析（OLAP）能力以支持超大规模数据，它能在<strong>亚秒</strong>内查询巨大的 Hive 表。不管是 Hive 还是 Spark SQL，经过计算生成报表的时间都在分钟级以上。<br>Kylin 的核心思想是预计算，理论基础是：以空间换时间。即将多维分析可能用到的度量进行预计算，将计算好的结果保存成 Cube 并存储到 HBase 中，而后用户能够经过 JDBC Driver 以 SQL 的方式对数据进行直接访问、快速查询。把高复杂度的聚合运算，多表连接等操作转换成对预计算结果的查询。</p></blockquote><p><img data-src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F53911a48-11cc-4569-8f1c-3790605c1c81%2FUntitled.png?table=block&id=e4cc962d-4128-4439-a445-719fb5dc807c&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=2400&userId=&cache=v2" alt="Kylin 架构"><span class="image-caption">Kylin 架构</span></p><p><strong>优点</strong>：</p><ul><li>亚秒级查询响应交互，在同样的数据集上提供比 Hive 更好的性能</li><li>支持百亿、千亿甚至万亿级别交互式分析</li><li>提供与多种数据可视化 BI 工具的整合能力，如 Tableau，PowerBI、Excel 等</li><li>可以在数据产生时进行<strong>实时处理</strong></li><li>提供标准 SQL 支持大部分<strong>查询</strong>功能</li></ul><p><strong>缺点</strong>：</p><ul><li>由于 Kylin 是一个分析引擎，只读，不支持 <code>insert</code>，<code>update</code>，<code>delete</code> 等 SQL 操作，用户修改数据的话需要重新批量导入（构建）</li><li>需要预先建立模型后加载数据到 Cube 后才可进行查询</li><li>使用 Kylin 的建模人员需要了解一定的数据仓库知识</li></ul><h4 id="Druid"><a href="#Druid" class="headerlink" title="Druid"></a>Druid</h4><blockquote><p>Apache Druid 是高性能的实时分析数据库，实时 OLAP 系统。主要提供对大量的基于时序的数据进行 OLAP 查询能力。支持毫秒级的快速的交互式查询。</p></blockquote><p>Druid 通过位图索引，预计算最细粒度的聚合 + 实时聚合这种方式来牺牲一点点 RT，来改善维度爆炸的问题。</p><p><strong>优点</strong>：</p><ul><li>为分析而设计：为 OLAP 工作流的探索性分析而构建。它支持各种 filter、aggregator 和查询类型。</li><li>交互式查询：低延迟数据摄取架构允许事件在它们创建后毫秒内查询。</li><li>高可用：你的数据在系统更新时依然可用、可查询。规模的扩大和缩小不会造成数据丢失。</li><li>可伸缩：每天处理数十亿事件和 TB 级数据。</li></ul><p><strong>缺点</strong>：</p><ul><li>不支持<code>join</code>，导致用户需要导入大宽表</li><li>不支持更新操作，数据不可更改</li><li>无法查询明细，无法做到精确查询</li><li>不支持事实表之间的关联</li></ul><h3 id="开源-MPP-数据库分析"><a href="#开源-MPP-数据库分析" class="headerlink" title="开源 MPP 数据库分析"></a>开源 MPP 数据库分析</h3><h4 id="Greenplum"><a href="#Greenplum" class="headerlink" title="Greenplum"></a>Greenplum</h4><p>时间回到 2002 年，那时整个互联网数据量正处于快速增长期，一方面传统数据库难以满足当前的计算需求，另一方面传统数据库大多基于 SMP 架构，这种架构最大的一个特点是共享所有资源，扩展性能差，因此面对日益增长的数据量，难以继续支撑，需要一种具有分布式并行数据计算能力的数据库，Greenplum 正是在此背景下诞生了。 和传统数据库的 SMP 架构不同，Greenplum 主要基于 MPP 架构，这是由多个服务器通过节点互联网络连接而成的系统，每个节点只访问自己的本地资源（包括内存、存储等），是一种完全无共享（Share Nothing）结构，扩展能力较之前有明显提升。</p><h4 id="ClickHouse"><a href="#ClickHouse" class="headerlink" title="ClickHouse"></a>ClickHouse</h4><blockquote><p>ClickHouse 是一款由俄罗斯 Yandex 公司开发的 C++ 开源高性能 OLAP 组件。在 Yandex 内部, ClickHouse 主要用于在线流量分析产品 Yandex Metrica，类似于 Google Analytics 或者百度统计。</p></blockquote><p><strong>特点</strong>：</p><ul><li>SQL 支持: 支持大部分 SQL 功能。 列式存储，数据压缩: 列式存储能够更加有利于 OLAP 聚合查询，同时也能大大提高数据压缩率。</li><li>多核（垂直扩展），分布式处理（水平扩展）: 使用多线程和多分片并行处理。</li><li>实时数据摄入: 数据可以实时批量摄入立即被查询。</li><li>向量化引擎 / 代码编译生成: 传统火山模型的虚函数，分支预测等开销大大降低了整个算子流水线的执行，尤其对于 OLAP 这种聚合计算，CPU 密集的场景下。向量化引擎通过将算子处理从当个 tuple 变成向量的方式分摊了这部分的开销，也更容易使用 SMID 去加速 CPU 计算，尽可能地将计算保持在 CPU Cache 内。而代码编译生成通过改成以数据为中心的方式消除这部分的开销，尽可能地将计算保持在 CPU 寄存器中。当然这两项技术也不是万能的，由于有些情况，比如 Aggregation 或者 Join 时过多的数据，不可避免地只能通过物化到内存中，导致瓶颈产生，无法有效地提高性能。两者在有些场景甚至是可以混合使用的，一些前沿论文中还有使用软件预取的方式去尽可能地优化。</li><li>主键索引，二级索引: ClickHouse 主要采用了稀疏索引的方式做主键索引，minmax，set，ngrambf/tokenbf 等 Bloom Filter 去做二级索引。</li></ul><p><strong>缺点</strong>：</p><ul><li>没有高速，低延迟的更新和删除方法。</li><li>稀疏索引使得点查性能不佳。</li><li>不支持事务。</li></ul><p>ClickHouse 要比类似的产品 Presto、Impala 快很多。其应用场景有：</p><ul><li>用户行为分析，精细化运营分析: 日活，留存率分析，路径分析，有序漏斗转化率分 析，Session 分析等。</li><li><strong>实时</strong>日志分析，监控分析。</li><li><strong>实时</strong>数仓。</li></ul><h3 id="基于-MPP-架构的-SQL-引擎分析"><a href="#基于-MPP-架构的-SQL-引擎分析" class="headerlink" title="基于 MPP 架构的 SQL 引擎分析"></a>基于 MPP 架构的 SQL 引擎分析</h3><h4 id="Presto"><a href="#Presto" class="headerlink" title="Presto"></a>Presto</h4><blockquote><p>Presto 是由 Facebook 开发的开源大数据分布式高性能 SQL 查询引擎。起初，Facebook 使用 Hive 来进行交互式查询分析，但 Hive 是基于 MapReduce 为批处理而设计的，延时很高，满足不了用户对于交互式查询想要快速出结果的场景。为了解决 Hive 并不擅长的交互式查询领域，Facebook 开发了 Presto，专门为交互式查询所设计，提供分钟级乃至亚秒级低延时的查询性能。</p></blockquote><h4 id="Impala"><a href="#Impala" class="headerlink" title="Impala"></a>Impala</h4><blockquote><p>Impala 是 Cloudera 在受到 Google 的 Dremel 启发下开发的实时交互 SQL 大数据查询工具，Impala 没有再使用缓慢的 Hive + MapReduce 批处理，而是通过使用与商用并行关系数据库中类似的分布式查询引擎（由 Query Planner、Query Coordinator 和 Query Exec Engine 三部分组成），可以直接从 HDFS 或 HBase 中用 SELECT、JOIN 和统计函数查询数据，从而大大降低了延迟。<br>Impala 架构类似分布式数据库 Greenplum 数据库，一个大的查询通过分析为一个个子查询，分布到底层的执行，最后再合并结果，通过多线程并发来暴力 SCAN 来实现高速。</p></blockquote><p>架构是完美的，现实是骨感的，实际使用过程中，Impala 性能和稳定性还差得远。尤其是 Impala 虽然号称支持 HDFS 和 HBase，但实际使用中发现，运行在 HDFS 上，性能还差强人意，运行在 HBase 上性能很差，另外还经常有内存溢出之类的问题尚待解决。</p><h3 id="基于通用计算框架的-SQL-引擎分析"><a href="#基于通用计算框架的-SQL-引擎分析" class="headerlink" title="基于通用计算框架的 SQL 引擎分析"></a>基于通用计算框架的 SQL 引擎分析</h3><h4 id="SparkSQL"><a href="#SparkSQL" class="headerlink" title="SparkSQL"></a>SparkSQL</h4><p>Spark SQL 是在 Spark 的基础之上构建的，于 2014 年 5 月发布。从名称上可以看出，该模块是 Spark 提供的关系型操作 API，实现了<strong>SQL-on-Spark</strong>的功能。对于一些熟悉 SQL 的用户，可以直接使用 SQL 在 Spark 上进行复杂的数据处理。</p><p>Spark SQL 是 Spark 的其中一个模块，用于结构化数据处理。与基本的 Spark RDD API 不同，Spark SQL 提供的接口为 Spark 提供了有关数据结构和正在执行的计算的更多信息，Spark SQL 会使用这些额外的信息来执行额外的优化。使用 SparkSQL 的方式有很多种，包括 SQL、DataFrame API 以及 Dataset API。值得注意的是，无论使用何种方式何种语言，其执行引擎都是相同的。实现这种统一，意味着开发人员可以轻松地在不同的 API 之间来回切换，从而使数据处理更加地灵活。</p><h4 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h4><p><img data-src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F92053782-2568-4b8d-a3cd-9ca41d441cf5%2FUntitled.png?table=block&id=45df2dd5-0fa0-4c9c-93b5-9f2b29bc8e91&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=1600&userId=&cache=v2" alt="Hive"><span class="image-caption">Hive</span></p><p>Hive 由 Facebook 实现并开源，是基于 Hadoop 的一个数据仓库工具，可以将结构化的数据映射为一张数据库表，并提供 HQL(Hive SQL) 查询功能，底层数据是存储在 HDFS 上。Hive 的本质是将 SQL 语句转换为 MapReduce 任务运行，使不熟悉 MapReduce 的用户很方便地利用 HQL 处理和计算 HDFS 上的结构化的数据，适用于<strong>离线</strong>的<strong>批量数据</strong>计算。Hive 依赖于 HDFS 存储数据，将 HQL 转换成 MapReduce 执行，所以说 Hive 是基于 Hadoop 的一个数据仓库工具，实质就是一款基于 HDFS 的 MapReduce计算框架，对存储在 HDFS 中的数据进行分析和管理。</p><p><strong>优点</strong>：</p><ul><li>可扩展性，横向扩展</li><li>支持自定义函数，可以根据自己的需求来实现自定义函数</li><li>良好的容错性，即使节点出现问题，SQL 语句仍可执行</li></ul><p><strong>缺点</strong>：</p><ul><li>不支持记录级别的增删改操作，但是用户可以通过查询生成新表或者将查询的结果导入到文件中</li><li><strong>查询延时非常严重</strong>，因为 MapReduce Job 的启动过程消耗时间很长，所以不能用于交互查询系统中</li><li>不支持事务，所以主要用于 OLAP 而不能用于 OLTP</li></ul><hr><h4 id="Doris"><a href="#Doris" class="headerlink" title="Doris"></a>Doris</h4><h4 id="Snowflake"><a href="#Snowflake" class="headerlink" title="Snowflake"></a>Snowflake</h4><h4 id="Hudi"><a href="#Hudi" class="headerlink" title="Hudi"></a>Hudi</h4><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] <a href="https://www.jianshu.com/p/a078fed07acc">大数据OLAP系统（1）——概念篇</a><br>[2] <a href="https://www.jianshu.com/p/4b3bcbabad77">大数据OLAP系统（2）——开源组件篇</a></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据仓库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>实时数仓建设</title>
      <link href="/2021/09/01/%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93%E5%BB%BA%E8%AE%BE/"/>
      <url>/2021/09/01/%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93%E5%BB%BA%E8%AE%BE/</url>
      
        <content type="html"><![CDATA[<h2 id="实时数仓概念"><a href="#实时数仓概念" class="headerlink" title="实时数仓概念"></a>实时数仓概念</h2><p><strong>实时数仓</strong>：以端到端低延迟、SQL 标准化、快速响应变化、数据统一为目标。</p><blockquote><p>一个通用的实时生产平台跟一个通用交互式实时分析引擎相互配合，同时满足实时和准实时业务场景。两者合理分工，互相补充，形成易开发、易维护且效率高的流水线，兼顾开发效率与生产成本，以较好的投入产出比满足业务的多样性需求。</p></blockquote><p>在传统的 BI 体系中，基于<strong>离线大数据构建数据仓库</strong>的过程，大部分是 T+1 的隔日离线计算。即每天凌晨开始从原始日志数据构建数仓，将多层级的离线计算任务，通过工作流系统进行串联。数仓构建任务失败后可以有由工作流系统触发任务重跑。一般来说，离线数仓构建任务的失败重跑，只影响数据生产出来的时间，不影响数据的完整性、正确性。</p><p><img data-src="https://www.notion.sp/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F0eaae7d7-3dce-4b11-b4de-db1139b15883%2FUntitled.png?table=block&id=1f038912-2e08-4e95-924e-fc3f22ab98b2&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=2160&userId=&cache=v2" alt="实时数仓 vs. 离线数仓"><span class="image-caption">实时数仓 vs. 离线数仓</span></p><p>实时仓库的核心有以下几个特点：</p><ul><li><p><strong>重视数仓的水平拆分</strong>。</p><p>离线数仓中，数据的载体是 Hive 表，借助 Hive 的分区字段和谓词下推机制，我们可以在各个层级构建一些稍大的表，而将关键的维度字段设置成分区，使用户在查大表的时候达到查小表的效果。在实时数仓中，数据的载体是 Kafka 队列，如果向用户提供一个大流，需要用户在消费数据实时过滤出其中的一小部分数据进行使用，那么对 Kafka 的带宽资源和 Flink 的计算资源都是极大的浪费。</p><p>所以，<strong>我们需要尽量将常用的维度进行水平拆分构建</strong>。</p></li><li><p><strong>重视维度退化</strong>。</p><p>在离线数仓中，一个维度放在事实表里还是放在维度表里是一件可权衡的事情。一些不太常用的维度可以保留在维度表里，让用户查询使用时再进行 Join。而在建设实时数仓时应该尽量帮助数据下游方减少这些代价，提前将会用到的维度退化到数仓的事实流中，将实时流变成一个宽流，避免下游业务方在使用数据时，自行去处理流 Join 外部表的这类复杂场景。</p></li><li><p><strong>重视层级缩短</strong>。</p><p>在实时数仓的构建过程中，数据在多层级 Kafka 中传递，数据处理的链路越长，数据的延迟越大、稳定性越差。因此，在实时数仓中，要尽可能引导用户使用短链路生产的实时数据。</p></li></ul><h2 id="实时技术选型"><a href="#实时技术选型" class="headerlink" title="实时技术选型"></a>实时技术选型</h2><p>目前，市面上已经开源的实时技术还是很多的，比较通用的有 Storm、Spark Streaming 以及 Flink。从技术成熟度来说，前几年的 Storm，在性能稳定性、可靠性以及扩展性上是无可替代的。但随着 Flink 越来越成熟，从技术性能上以及框架设计优势上已经超越了 Storm，从趋势来讲就像 Spark 替代 MapReduce 一样，Storm 也会慢慢被 Flink替代。</p><p><img data-src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F661792b8-1fe1-487a-aa65-967a0561aab0%2FUntitled.png?table=block&id=c7559d92-df02-4595-84df-c4b7f7ce13ac&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=4020&userId=&cache=v2" alt="Storm vs. Flink"><span class="image-caption">Storm vs. Flink</span></p><h2 id="实时架构"><a href="#实时架构" class="headerlink" title="实时架构"></a>实时架构</h2><h3 id="Lambda-架构"><a href="#Lambda-架构" class="headerlink" title="Lambda 架构"></a>Lambda 架构</h3><p><img data-src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F94392bd1-8523-487e-b100-720595160a70%2FUntitled.png?table=block&id=d686c15a-2ca1-4593-875f-89b3fea5f8c4&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=4910&userId=&cache=v2" alt="Lambda 架构"><span class="image-caption">Lambda 架构</span></p><p>Lambda 是比较经典的一款架构，以前实时的场景不是很多，以离线为主，当附加了实时场景后，由于离线和实时的时效性不同，导致技术生态是不一样的。而Lambda 架构相当于<strong>附加了一条实时生产链路</strong>，在应用层面进行一个整合，<strong>双路生产，各自独立。</strong>在业务应用中，顺理成章成为了一种被采用的方式。</p><p>双路生产会存在一些问题，比如加工逻辑 Double，开发运维也会 Double，资源同样会变成两个资源链路。因为存在以上问题，所以又演进了一个 <strong>Kappa</strong> 架构。</p><h3 id="Kappa-架构"><a href="#Kappa-架构" class="headerlink" title="Kappa 架构"></a>Kappa 架构</h3><p><img data-src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F7eba7b68-ac2d-4735-827a-2a4d7d2c1739%2FUntitled.png?table=block&id=9c505370-8497-4e66-a3a0-2d4c774bf9f3&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=4890&userId=&cache=v2" alt="Kappa 架构"><span class="image-caption">Kappa 架构</span></p><p>Kappa 从架构设计来讲，比较简单，生产统一，一套逻辑同时生产离线和实时。但是在实际应用场景有比较大的局限性，在业内直接用 Kappa 架构生产落地的案例不多见，且场景比较单一。</p><h2 id="架构设计"><a href="#架构设计" class="headerlink" title="架构设计"></a>架构设计</h2><p>在业务早期，为了满足业务需要，一般是 Case By Case，先把需求完成。业务对于实时性要求是比较高的，从时效性的维度来说，没有进行中间层沉淀的机会。在这种场景下，一般是拿到业务逻辑直接嵌入，这是最简单有效的方法，在业务发展初期这种开发模式也比较常见。</p><p><img data-src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F0f6b50fe-ca20-4a79-bba0-9ff2cab31678%2FUntitled.png?table=block&id=4406a8f9-2555-47cb-88d9-11dba0a545e9&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=3360&userId=&cache=v2" alt="业务早期架构"><span class="image-caption">业务早期架构</span></p><p>如上图所示，拿到数据源后，我们会经过数据清洗、扩维，通过 Storm 或 Flink 进行业务逻辑处理，最后直接进行业务输出。把这个环节拆开来看，数据源端会重复引用相同的数据源，后面进行 ETL 清洗、过滤、扩维等操作，都要重复做一遍。唯一不同的是业务的代码逻辑是不一样的，如果业务较少，这种模式还可以接受，但当后续业务量上去后，会出现谁开发谁运维的情况，维护工作量会越来越大，作业无法形成统一管理。而且所有人都在申请资源，导致资源成本急速膨胀，资源不能集约有效利用，因此要思考如何从整体来进行实时数据的建设。</p><p>所以，如何来构建实时数仓呢？首先要进行拆解，有哪些数据，有哪些场景，这些场景有哪些共同特点。例如下图的，<strong>日志类</strong>和<strong>业务类</strong>。</p><p><img data-src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F5f0fd0fa-43aa-4552-9bfd-eaa6a96b5a1a%2FUntitled.png?table=block&id=5a86434f-40e2-4791-93b5-bc5bfbe471f5&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=3100&userId=&cache=v2"></p><ul><li><strong>日志类</strong>：数据量特别大，半结构化，嵌套比较深。日志类的数据有个很大的特点，日志流一旦形成是不会变的，通过埋点的方式收集平台所有的日志，统一进行采集分发，就像一颗树，树根非常大，推到前端应用的时候，相当于从树根到树枝分叉的过程（从 1 到 n 的分解过程）。如果所有的业务都从根上找数据，看起来路径最短，但包袱太重，数据检索效率低。日志类数据一般用于生产监控和用户行为分析，时效性要求比较高，时间窗口一般是 5min 或 10min，或截止到当前的一个状态，主要的应用是实时大屏和实时特征，例如用户每一次点击行为都能够立刻感知到等需求。</li><li><strong>业务类</strong>：主要是业务交易数据，业务系统一般是自成体系的，以 Binlog 日志的形式往下分发，业务系统都是事务型的，主要采用范式建模方式。特点是结构化，主体非常清晰，但数据表较多，需要多表关联才能表达完整业务，因此是一个 n 到 1 的集成加工过程。</li></ul><p>日志类和业务类的场景一般是同时存在的，交织在一起，无论是 Lambda 架构还是 Kappa 架构，单一的应用都会有一些问题。因此针对场景来选择架构与实践才更有意义。</p><hr><p>基于以上问题，可以使用<strong>流批结合</strong>的方式来应对不同的业务场景。</p><p><img data-src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F0c585b8d-87d9-44d3-ae9d-db795766de48%2FUntitled.png?table=block&id=5cd647e2-9ab1-4f1f-83b6-5531ad0596e6&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=3500&userId=&cache=v2"></p><p>如上图所示，数据从日志统一采集到消息队列，再到数据流的 ETL 过程，作为基础数据流的建设是统一的。之后对于日志类实时特征，实时大屏类应用走实时流计算。对于 Binlog 类业务分析走实时 OLAP 批处理。</p><blockquote><p>流式处理分析业务的痛点是什么？对于范式业务，Storm 和 Flink 都需要很大的外存，来实现数据流之间的业务对齐，需要大量的计算资源。且由于外存的限制，必须进行窗口的限定策略，最终可能放弃一些数据。计算之后，一般是存到 Redis 里做查询支撑，且 KV 存储在应对分析类查询场景中也有较多局限。</p></blockquote><blockquote><p>实时 OLAP 怎么实现？有没有一种自带存储的实时计算引擎，当实时数据来了之后，可以灵活的在一定范围内自由计算，并且有一定的数据承载能力，同时支持分析查询响应呢？随着技术的发展，目前 MPP 引擎发展非常迅速，性能也在飞快提升，所以这里使用的是 Apache Doris 引擎。</p></blockquote><hr><p><img data-src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fae9a2a7a-efa1-4596-8f24-97ad446c9a03%2FUntitled.png?table=block&id=cc38be06-fcd5-4b7d-8822-c117ce649e0c&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=3600&userId=&cache=v2"></p><p>其实实时和离线数仓是相似的。开始都是 Case By Case，当数据规模涨到一定的程度时，就会考虑如何进行治理。而在如何进行管理的问题上，首先考虑的就是分层的处理逻辑：</p><ul><li><strong>数据贴源层</strong>：在数据源的层面，离线和实时在数据源是一致的，主要分为日志类和业务类，日志类又包括用户日志、DB 日志以及服务器日志等。</li><li><strong>实时明细层</strong>：在数据明细层，为了解决重复建设的问题，要进行统一构建，利用离线数仓的模式，建设统一的基础明细数据层，按照主题进行管理，明细层的目的是给下游提供直接可用的数据，因此要对基础层进行统一的加工，比如清洗、过滤、扩维等。</li><li><strong>数据汇总层</strong>：汇总层通过 Flink 或 Storm 的简洁算子 Transformer 直接可以算出结果，并且形成汇总指标池，所有的指标都统一在汇总层加工，所有人按照统一的规范管理建设，形成可复用的汇总结果。</li></ul><h2 id="平台化建设"><a href="#平台化建设" class="headerlink" title="平台化建设"></a>平台化建设</h2><p>架构确定之后，后面考虑的是如何进行平台化的建设，实时平台化建设是完全附加于实时数仓管理之上进行的。</p><p><img data-src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F13a47813-99a6-459c-b2a2-35c62ccf0307%2FUntitled.png?table=block&id=3c016361-7f81-44e1-95eb-f9bc2ba97c9c&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=3500&userId=&cache=v2"></p><p>首先进行<strong>功能的抽象</strong>，把功能抽象成组件，这样就可以达到标准化的生产，系统化的保障就可以更深入的建设，对于基础加工层的清洗、过滤、合流、扩维、转换、加密、筛选等功能都可以抽象出来，基础层通过这种组件化的方式构建直接可用的数据结果流。通过冗余的方式可以提高生产效率，是一种以空间换时间思想的应用。</p><p>通过基础层的加工，数据全部沉淀到 IDL 层，同时写到 OLAP 引擎的基础层，再往上是实时汇总层计算，基于 Storm、Flink 或 Doris，生产多维度的汇总指标，形成统一的汇总层，进行统一的存储分发。</p><p>当这些功能都有了以后，<strong>元数据管理</strong>，指标管理，数据安全性、SLA、数据质量等系统能力也会逐渐构建起来。</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] <a href="https://tech.meituan.com/2021/08/26/data-warehouse-in-meituan-waimai.html">美团外卖实时数仓建设实践</a></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据仓库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>离线数仓搭建</title>
      <link href="/2021/08/31/%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E6%90%AD%E5%BB%BA/"/>
      <url>/2021/08/31/%E7%A6%BB%E7%BA%BF%E6%95%B0%E4%BB%93%E6%90%AD%E5%BB%BA/</url>
      
        <content type="html"><![CDATA[<h2 id="离线数仓分层概念"><a href="#离线数仓分层概念" class="headerlink" title="离线数仓分层概念"></a>离线数仓分层概念</h2><blockquote><p>数据仓库定义：是为企业所有决策制定过程，提供所有系统数据支持的战略集合。</p></blockquote><p><img data-src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fecda541c-ceca-45a7-bafb-adf516b3bd0c%2FUntitled.png?table=block&id=aa2b93f0-a535-4710-a0f2-1416ab940127&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=1050&userId=&cache=v2"></p><p>在技术选型方面，主要有：</p><p><img data-src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fd5cd8536-d3c8-4ecf-8d96-7e49d3cdb0d8%2FUntitled.png?table=block&id=371a7078-c2da-4a93-a23a-845f3f1f196b&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=1860&userId=&cache=v2"></p><p>其中，离线平台组件主要是</p><ul><li>离线计算元数据组件：HIVE META</li><li>离线计算引擎：HIVE / Spark SQL / Presto</li></ul><p>实时平台则是一些实时计算框架：</p><p>Flume / Kafka / HBase / Kylin / Spark Streaming / Flink 等。</p><p>分布式在线存储组件则是：HBase / Kafka / Druid 等。</p><p>整个数据仓库搭建以及使用的流程大致是：</p><ol><li>需求分析</li><li>架构设计</li><li>生成数据</li><li>采集数据</li><li>搭建行为数仓</li><li>搭建业务数仓</li><li>导出数据</li><li>作业调度</li><li>数据可视化</li></ol><hr><p><img data-src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F537e911b-cd89-4760-9460-4a2951e7821e%2FUntitled.png?table=block&id=8e66d15c-e1f8-4474-b3f0-9d9db85ee24b&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=950&userId=&cache=v2" alt="数据仓库分层"><span class="image-caption">数据仓库分层</span></p><h3 id="ODS-层（Operational-Data-Store）"><a href="#ODS-层（Operational-Data-Store）" class="headerlink" title="ODS 层（Operational Data Store）"></a>ODS 层（Operational Data Store）</h3><p>原始数据层 | 操作数据层 | 数据运营层 | <strong>数据贴源层</strong>，存放原始数据，直接加载<strong>原始日志</strong>、<strong>数据</strong>，数据保持原貌不做处理。</p><p><img data-src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ff0c5e0bf-a812-4537-afc1-f9a9fd1f7e26%2FUntitled.png?table=block&id=42e8597d-24b3-42dc-82d3-7c3c3b6abb09&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=1420&userId=&cache=v2"></p><p>ODS 层数据的来源方式可以是：</p><ul><li>业务库<ul><li>例如使用 sqoop 每天定时抽取一次</li><li>使用 cancal 监听 MySQL 的 binlog，实时接入</li></ul></li><li>埋点日志<ul><li>可以使用 flume 定时同步</li><li>可以使用 Spark Streaming 或者 Flink 来实时接入（实时数仓）</li><li>Kafka</li></ul></li><li>消息队列<ul><li>ActiveMQ 或者 Kafka 的数据等</li></ul></li></ul><p>ODS 的作用是：</p><ul><li>在业务系统和数据仓库之间形成一个<strong>隔离层</strong>，降低数据来源复杂性</li><li>转移一部分业务系统查询细节的功能，降低业务系统的查询压力</li><li>完成数据仓库中一些不能完成的功能，因为数据仓库中的数据粒度是根据实际需要而确定的，有时并不会存储过于细节的粒度。此时 ODS 层就可以完成。</li></ul><h3 id="DWD-层（Data-Warehouse-Detail）"><a href="#DWD-层（Data-Warehouse-Detail）" class="headerlink" title="DWD 层（Data Warehouse Detail）"></a>DWD 层（Data Warehouse Detail）</h3><p><strong>数据明细层</strong>，对 ODS 层数据进行清洗，去除空值、脏数据、超过极限范围的数据。DWD 层处理后的表，能够成为非常明确可用的基础明细数据。</p><h3 id="DWB-层（Data-Warehouse-Base）"><a href="#DWB-层（Data-Warehouse-Base）" class="headerlink" title="DWB 层（Data Warehouse Base）"></a>DWB 层（Data Warehouse Base）</h3><p>数据基础层，存储的是客观数据，一般用作中间层，可以认为是大量指标的数据层。它是对 DWD 数据明细层进行清洗转换。</p><p>（<strong>这一层有时可以省略</strong>）</p><h3 id="DWS-层（Data-Warehouse-Service）"><a href="#DWS-层（Data-Warehouse-Service）" class="headerlink" title="DWS 层（Data Warehouse Service）"></a>DWS 层（Data Warehouse Service）</h3><p><strong>数据汇总层</strong> | 数据服务层，以 DWD/DWB 层为基础，针对明细粒度的数据进行短周期的轻度汇总。一般是<strong>宽表</strong>。用于提供后续的业务查询，OLAP 分析，数据分发等。</p><blockquote><p>宽表，字段比较多的数据库表。通常是指业务主题相关的指标、维度、属性关联在一起的一张数据库表。<br>由于把不同的内容都放在同一张表存储，宽表已经不符合<strong>三范式</strong>的模型设计规范，随之带来的主要坏处就是<strong>数据的大量冗余</strong>，与之相对应的好处就是<strong>查询性能的提高与便捷</strong>。</p></blockquote><h3 id="ADS-层（Application-Data-Store）"><a href="#ADS-层（Application-Data-Store）" class="headerlink" title="ADS 层（Application Data Store）"></a>ADS 层（Application Data Store）</h3><p>为各种统计报表提供数据，针对某一个特定的维度进行的汇总。通常说的报表数据或者大宽表就放在这里。例如，前端报表、分析图表、KPI、仪表盘、OLAP 分析等。</p><p>（<strong>有时可以直接叫 APP 层</strong>）</p><h2 id="离线数仓命名规范"><a href="#离线数仓命名规范" class="headerlink" title="离线数仓命名规范"></a>离线数仓命名规范</h2><ul><li>ODS 层命名为 ods 前缀</li><li>DWD 层命名为 dwd 前缀</li><li>DWS 层命名为 dws 前缀</li><li>ADS 层命名为 ads 前缀</li><li>维度表命名为 dim 前缀</li><li>每日全量导入命名为 df(day full) 前缀</li><li>每日增量导入命名为 di(day increase) 后缀</li></ul>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据仓库 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SpringMVC 配置文件</title>
      <link href="/2021/05/06/SpringMVC%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"/>
      <url>/2021/05/06/SpringMVC%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<h2 id="目录规范">目录规范</h2><ul><li>java：存放 Java 代码</li><li>resources：存放资源文件，例如 Spring、Mybatis、Log 的配置文件等</li><li>mapper：存放 dao 中每个方法对应的 sql，在这里配置就无需写 impl 实现类</li><li>spring：存放 Spring 的相关配置文件，有 dao、service、web 三个包</li><li>sql：存放数据库文件</li><li>webapp：存放前端的静态资源（如果是非前后端分离项目）</li><li>resources：前端项目的静态资源（例如图片资源等）</li><li>WEB-INF：外部浏览器无法访问，只有内部才可以访问。web.xml 以及 jsp 文件放置在这里</li><li>test：测试文件</li></ul><h3 id="具体包名">具体包名</h3><ul><li>dao：是数据访问层（接口），包括数据库操作、文件读写操作、以及 Redis 缓存操作等。</li><li>entity：将封装 dao 层取出来的数据作为一个对象，一般用作在 dao 层和 service 层之间传递</li><li>dto：数据传输层，dto 有时候也叫 vo</li><li>service：业务逻辑层，用来设计业务接口</li><li>impl：业务逻辑实现层，用来实现业务接口</li><li>web：控制器层，或者叫 controller 包</li></ul><h2 id="配置文件">配置文件</h2><p>先在 Spring 文件夹中新建 <code>spring-dao.xml</code>文件。</p><ol type="1"><li>读取数据库连接相关参数</li><li>配置数据连接池</li><li>配置连接属性</li><li>配置 SqlSessionFactory 对象（Mybatis）</li><li>扫描 dao 层接口，动态实现 dao 接口</li></ol><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- spring-dao.xml --&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">beans</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://www.springframework.org/schema/beans&quot;</span></span></span><br><span class="line"><span class="tag"><span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag"><span class="attr">xmlns:context</span>=<span class="string">&quot;http://www.springframework.org/schema/context&quot;</span></span></span><br><span class="line"><span class="tag"><span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://www.springframework.org/schema/beans</span></span></span><br><span class="line"><span class="tag"><span class="string">http://www.springframework.org/schema/beans/spring-beans.xsd</span></span></span><br><span class="line"><span class="tag"><span class="string">http://www.springframework.org/schema/context</span></span></span><br><span class="line"><span class="tag"><span class="string">http://www.springframework.org/schema/context/spring-context.xsd&quot;</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 配置整合 mybatis 过程 --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 1. 配置数据库相关参数 properties 的属性：$&#123;url&#125; --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">context:property-placeholder</span> <span class="attr">location</span>=<span class="string">&quot;classpath:jdbc.properties&quot;</span> /&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 2. 数据库连接池 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">&quot;dataSource&quot;</span> <span class="attr">class</span>=<span class="string">&quot;com.mchange.v2.c3p0.ComboPooledDataSource&quot;</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 配置连接池属性 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;driverClass&quot;</span> <span class="attr">value</span>=<span class="string">&quot;$&#123;jdbc.driver&#125;&quot;</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;jdbcUrl&quot;</span> <span class="attr">value</span>=<span class="string">&quot;$&#123;jdbc.url&#125;&quot;</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;user&quot;</span> <span class="attr">value</span>=<span class="string">&quot;$&#123;jdbc.username&#125;&quot;</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;password&quot;</span> <span class="attr">value</span>=<span class="string">&quot;$&#123;jdbc.password&#125;&quot;</span> /&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- c3p0 连接池的私有属性 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;maxPoolSize&quot;</span> <span class="attr">value</span>=<span class="string">&quot;30&quot;</span> /&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;minPoolSize&quot;</span> <span class="attr">value</span>=<span class="string">&quot;10&quot;</span> /&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 关闭连接后不自动 commit --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;autoCommitOnClose&quot;</span> <span class="attr">value</span>=<span class="string">&quot;false&quot;</span> /&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 获取连接超时时间 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;checkoutTimeout&quot;</span> <span class="attr">value</span>=<span class="string">&quot;10000&quot;</span> /&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 当获取连接失败重试次数 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;acquireRetryAttempts&quot;</span> <span class="attr">value</span>=<span class="string">&quot;2&quot;</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 3. 配置 SqlSessionFactory 对象 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">&quot;sqlSessionFactory&quot;</span> <span class="attr">class</span>=<span class="string">&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 注入数据库连接池 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;dataSource&quot;</span> <span class="attr">ref</span>=<span class="string">&quot;dataSource&quot;</span> /&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 配置 MyBaties 全局配置文件：mybatis-config.xml --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;configLocation&quot;</span> <span class="attr">value</span>=<span class="string">&quot;classpath:mybatis-config.xml&quot;</span> /&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 扫描 entity 包 使用别名 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;typeAliasesPackage&quot;</span> <span class="attr">value</span>=<span class="string">&quot;ac.hurley.ssm.entity&quot;</span> /&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 扫描 sql 配置文件：mapper 需要的 xml 文件 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;mapperLocations&quot;</span> <span class="attr">value</span>=<span class="string">&quot;classpath:mapper/*.xml&quot;</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 4. 配置扫描 Dao 接口包，动态实现 Dao 接口，注入到 spring 容器中 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">bean</span> <span class="attr">class</span>=<span class="string">&quot;org.mybatis.spring.mapper.MapperScannerConfigurer&quot;</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 注入 sqlSessionFactory --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;sqlSessionFactoryBeanName&quot;</span> <span class="attr">value</span>=<span class="string">&quot;sqlSessionFactory&quot;</span> /&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 给出需要扫描 Dao 接口包 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;basePackage&quot;</span> <span class="attr">value</span>=<span class="string">&quot;ac.hurley.ssm.dao&quot;</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">beans</span>&gt;</span></span><br></pre></td></tr></table></figure><p>配置 MySQL 数据库相关参数，读取配置文件<code>jdbc.properties</code>。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">jdbc.driver=com.mysql.jdbc.Driver</span><br><span class="line">jdbc.url=jdbc:mysql://localhost:3306/ssm?useUnicode=true&amp;characterEncoding=utf8</span><br><span class="line">jdbc.username=root</span><br><span class="line">jdbc.password=password</span><br></pre></td></tr></table></figure><p>接着配置 dao 层的 Mybatis 核心文件<code>mybatis-config.xml</code>。</p><ol type="1"><li>使用自增主键</li><li>使用列别名</li><li>开启驼峰命名转换</li></ol><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- mybatis-config.xml --&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;</span></span><br><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">configuration</span></span></span><br><span class="line"><span class="meta">  <span class="meta-keyword">PUBLIC</span> <span class="meta-string">&quot;-//mybatis.org//DTD Config 3.0//EN&quot;</span></span></span><br><span class="line"><span class="meta">  <span class="meta-string">&quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 配置全局属性 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">settings</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 使用 jdbc 的 getGeneratedKeys 获取数据库自增主键值 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">setting</span> <span class="attr">name</span>=<span class="string">&quot;useGeneratedKeys&quot;</span> <span class="attr">value</span>=<span class="string">&quot;    &quot;</span> /&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- 使用列别名替换列名 默认：     --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">setting</span> <span class="attr">name</span>=<span class="string">&quot;useColumnLabel&quot;</span> <span class="attr">value</span>=<span class="string">&quot;    &quot;</span> /&gt;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">&lt;!-- 开启驼峰命名转换：Table&#123;create_time&#125; -&gt; Entity&#123;createTime&#125; --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">setting</span> <span class="attr">name</span>=<span class="string">&quot;mapUnderscoreToCamelCase&quot;</span> <span class="attr">value</span>=<span class="string">&quot;    &quot;</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">settings</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p>然后，是准备好 service 层的<code>spring-service.xml</code>文件。</p><ol type="1"><li>扫描 service 包内的所有<code>@Service</code>注解</li><li>配置事务管理器，把事务管理交给 Spring 来完成</li><li>配置基于注解的声明式服务，可以直接在方法上加上<code>@Transaction</code>注解</li></ol><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- spring-service.xml --&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">beans</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://www.springframework.org/schema/beans&quot;</span></span></span><br><span class="line"><span class="tag"><span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag"><span class="attr">xmlns:context</span>=<span class="string">&quot;http://www.springframework.org/schema/context&quot;</span></span></span><br><span class="line"><span class="tag"><span class="attr">xmlns:tx</span>=<span class="string">&quot;http://www.springframework.org/schema/tx&quot;</span></span></span><br><span class="line"><span class="tag"><span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://www.springframework.org/schema/beans</span></span></span><br><span class="line"><span class="tag"><span class="string">http://www.springframework.org/schema/beans/spring-beans.xsd</span></span></span><br><span class="line"><span class="tag"><span class="string">http://www.springframework.org/schema/context</span></span></span><br><span class="line"><span class="tag"><span class="string">http://www.springframework.org/schema/context/spring-context.xsd</span></span></span><br><span class="line"><span class="tag"><span class="string">http://www.springframework.org/schema/tx</span></span></span><br><span class="line"><span class="tag"><span class="string">http://www.springframework.org/schema/tx/spring-tx.xsd&quot;</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 扫描 service 包下所有使用注解的类型 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">context:component-scan</span> <span class="attr">base-package</span>=<span class="string">&quot;ac.hurley.ssm.service&quot;</span> /&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 配置事务管理器 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">bean</span> <span class="attr">id</span>=<span class="string">&quot;transactionManager&quot;</span></span></span><br><span class="line"><span class="tag"><span class="attr">class</span>=<span class="string">&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 注入数据库连接池 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;dataSource&quot;</span> <span class="attr">ref</span>=<span class="string">&quot;dataSource&quot;</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 配置基于注解的声明式事务 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">tx:annotation-driven</span> <span class="attr">transaction-manager</span>=<span class="string">&quot;transactionManager&quot;</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">beans</span>&gt;</span></span><br></pre></td></tr></table></figure><p>然后，是配置 web 层，新建<code>spring-web.xml</code>文件。</p><ol type="1"><li>开启 SpringMVC 的注解模式，可以使用到<code>@RequestMapping</code>、<code>@PathVariable</code>、<code>@ResponseBody</code>等</li><li>对静态资源处理，如 js、css、图片等文件</li><li>配置 JSP，显示 ViewResolver，例如在 Controller 方法里返回一个<code>login</code>，那么就会返回<code>/WEB-INF/login.jsp</code>中</li><li>扫描 web 层里的<code>@Controller</code>注解</li></ol><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- spring-web.xml --&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">beans</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://www.springframework.org/schema/beans&quot;</span></span></span><br><span class="line"><span class="tag"><span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag"><span class="attr">xmlns:context</span>=<span class="string">&quot;http://www.springframework.org/schema/context&quot;</span></span></span><br><span class="line"><span class="tag"><span class="attr">xmlns:mvc</span>=<span class="string">&quot;http://www.springframework.org/schema/mvc&quot;</span></span></span><br><span class="line"><span class="tag"><span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://www.springframework.org/schema/beans</span></span></span><br><span class="line"><span class="tag"><span class="string">http://www.springframework.org/schema/beans/spring-beans.xsd</span></span></span><br><span class="line"><span class="tag"><span class="string">http://www.springframework.org/schema/context</span></span></span><br><span class="line"><span class="tag"><span class="string">http://www.springframework.org/schema/context/spring-context.xsd</span></span></span><br><span class="line"><span class="tag"><span class="string">http://www.springframework.org/schema/mvc</span></span></span><br><span class="line"><span class="tag"><span class="string">http://www.springframework.org/schema/mvc/spring-mvc-3.0.xsd&quot;</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 配置 SpringMVC --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 1. 开启 SpringMVC 注解模式 --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 简化配置：</span></span><br><span class="line"><span class="comment">(1) 自动注册 DefaultAnootationHandlerMapping,AnotationMethodHandlerAdapter</span></span><br><span class="line"><span class="comment">(2) 提供一些列：数据绑定，数字和日期的 format @NumberFormat, @DateTimeFormat, xml,json 默认读写支持</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">mvc:annotation-driven</span> /&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">&lt;!-- 2. 静态资源默认 servlet 配置</span></span><br><span class="line"><span class="comment">(1) 加入对静态资源的处理：js,gif,png</span></span><br><span class="line"><span class="comment">(2) 允许使用&quot;/&quot;做整体映射</span></span><br><span class="line"><span class="comment"> --&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">mvc:default-servlet-handler</span>/&gt;</span></span><br><span class="line"></span><br><span class="line">     <span class="comment">&lt;!-- 3. 配置 jsp 显示 ViewResolver --&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">bean</span> <span class="attr">class</span>=<span class="string">&quot;org.springframework.web.servlet.view.InternalResourceViewResolver&quot;</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;viewClass&quot;</span> <span class="attr">value</span>=<span class="string">&quot;org.springframework.web.servlet.view.JstlView&quot;</span> /&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;prefix&quot;</span> <span class="attr">value</span>=<span class="string">&quot;/WEB-INF/jsp/&quot;</span> /&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;suffix&quot;</span> <span class="attr">value</span>=<span class="string">&quot;.jsp&quot;</span> /&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">bean</span>&gt;</span></span><br><span class="line"></span><br><span class="line">     <span class="comment">&lt;!-- 4. 扫描 web 相关的 bean --&gt;</span></span><br><span class="line">     <span class="tag">&lt;<span class="name">context:component-scan</span> <span class="attr">base-package</span>=<span class="string">&quot;ac.hurley.ssm.web&quot;</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">beans</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>最后就是修改<code>web.xml</code>文件，它位于 webapp 的 WEB-INF 包下。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- web.xml --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">web-app</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://xmlns.jcp.org/xml/ns/javaee&quot;</span> <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span></span></span><br><span class="line"><span class="tag"><span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://xmlns.jcp.org/xml/ns/javaee</span></span></span><br><span class="line"><span class="tag"><span class="string">                      http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd&quot;</span></span></span><br><span class="line"><span class="tag"><span class="attr">version</span>=<span class="string">&quot;3.1&quot;</span> <span class="attr">metadata-complete</span>=<span class="string">&quot;    &quot;</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 如果是用 mvn 命令生成的 xml，需要修改 servlet 版本为3.1 --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 配置 DispatcherServlet --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">servlet</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">servlet-name</span>&gt;</span>seckill-dispatcher<span class="tag">&lt;/<span class="name">servlet-name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">servlet-class</span>&gt;</span>org.springframework.web.servlet.DispatcherServlet<span class="tag">&lt;/<span class="name">servlet-class</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 配置 springMVC 需要加载的配置文件</span></span><br><span class="line"><span class="comment">spring-dao.xml,spring-service.xml,spring-web.xml</span></span><br><span class="line"><span class="comment">Mybatis - &gt; spring -&gt; springmvc</span></span><br><span class="line"><span class="comment"> --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">init-param</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">param-name</span>&gt;</span>contextConfigLocation<span class="tag">&lt;/<span class="name">param-name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">param-value</span>&gt;</span>classpath:spring/spring-*.xml<span class="tag">&lt;/<span class="name">param-value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">init-param</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">servlet</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">servlet-mapping</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">servlet-name</span>&gt;</span>seckill-dispatcher<span class="tag">&lt;/<span class="name">servlet-name</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 默认匹配所有的请求 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">url-pattern</span>&gt;</span>/<span class="tag">&lt;/<span class="name">url-pattern</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">servlet-mapping</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">web-app</span>&gt;</span></span><br></pre></td></tr></table></figure><p>因为我们在项目中会经常用到日志，所以还需要配置日志文件，在 resources 包里新建<code>logback.xml</code>文件，给出的日志输出格式也是最基本的控制台输出。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- logback.xml --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span> <span class="attr">debug</span>=<span class="string">&quot;    &quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">appender</span> <span class="attr">name</span>=<span class="string">&quot;STDOUT&quot;</span> <span class="attr">class</span>=<span class="string">&quot;ch.qos.logback.core.ConsoleAppender&quot;</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- encoders are by default assigned the type ch.qos.logback.classic.encoder.PatternLayoutEncoder --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">encoder</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>%d&#123;HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;36&#125; - %msg%n<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">encoder</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">appender</span>&gt;</span></span><br><span class="line"></span><br><span class="line">    <span class="tag">&lt;<span class="name">root</span> <span class="attr">level</span>=<span class="string">&quot;debug&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">appender-ref</span> <span class="attr">ref</span>=<span class="string">&quot;STDOUT&quot;</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">root</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p>最后的配置文件结构图如下所示：</p><p><img data-src="https://i.loli.net/2021/05/06/xGFVyAzi9NXBE7L.png" width="300"></p>]]></content>
      
      
      <categories>
          
          <category> Spring </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringMVC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JS 有三宝——var、let、const</title>
      <link href="/2021/01/11/JS%E4%B8%89%E5%AE%9D--var%20let%20const/"/>
      <url>/2021/01/11/JS%E4%B8%89%E5%AE%9D--var%20let%20const/</url>
      
        <content type="html"><![CDATA[<h2 id="var">var</h2><p>最早，JavaScript 是使用<code>var</code>来声明变量的，但是由于设计得并不合理，后来在 ES6 版本推出了<code>let</code>和<code>const</code>。</p><span id="more"></span><p>var 的作用域是<strong>全局</strong>和<strong>函数</strong>作用域，而作用域指的是变量能够作用的范围。所以，全局作用域指的就是变量伴随了整个程序的生命周期；而函数作用域指的是在函数体内定义，可以在该函数内的任意地方使用。</p><p>什么是全局作用域？在 App 开发中，一个 App 就是一个进程，那么全局作用域就是在这个应用内部都可以访问到该变量，并且它一直在执行环境中，不会被释放。而浏览器中，就得把一个页面看做是一个全局，所以，全局变量的生命周期和这个页面的生命周期是一样的。</p><p>可是，使用<code>var</code>声明变量有很大的弊端。「它会使变量提升」，即「在代码执行之前，JavaScript 引擎把变量和函数的声明部分提升到对应作用域的开始位置」。如果变量提升后，<code>var</code>声明的变量的初始值就是<code>undefined</code>。</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">call();</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">call</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="comment">// name 被提升</span></span><br><span class="line">    <span class="built_in">console</span>.log(name);</span><br><span class="line">    <span class="keyword">var</span> name = <span class="string">&#x27;三宝&#x27;</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="let">let</h2><p>为此，在 ES6 中，提出了<code>let</code>这个声明变量的方式，使用<code>let</code>声明的变量是<strong>块级作用域</strong>。即用<code>let</code>声明的变量只能在这个块内部使用，而同一变量是不可以重复声明的。不过，如果是在不同的作用域中，即跳出了这个块，那么是可以重复定义的。</p><p>什么是块呢？只要有两个大括号就属于一个域。块就是两个大括号包起来的内容。</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">let</span> i = <span class="number">0</span>; i &lt; <span class="number">2</span>; i++) &#123;</span><br><span class="line">    <span class="comment">// 代码块</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">    <span class="comment">// 代码块</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">call</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="comment">// 代码块</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于使用<code>let</code>声明的变量，如果在未声明时就使用，那么会报错<code>Cannot access</code> XXX <code>before initialization</code>。</p><h3 id="const">const</h3><p>但是有时候我们声明一个变量之后，一旦赋值了就不需要再更改了，那么我们就可以用<code>const</code>，即声明常量最常用的手段。所以，在日常开发中，能要用<code>const</code>就要用<code>const</code>，它能够保证程序的状态更加稳定。在别的方面，<code>const</code>都与<code>let</code>类似，不同之处就在于它的不变性，且使用<code>const</code>声明的变量在声明时，就一定要设定初始值。</p><h3 id="总结">总结</h3><ol type="1"><li><code>var</code>声明的变量的作用域是全局或者函数级别的，而<code>let</code>和<code>const</code>声明的变量是块级的，一个<code>&#123;&#125;</code>表示一个代码块。</li><li><code>var</code>声明的变量可以更新，可以重新声明；<code>let</code>声明的变量可以更新，但是不能重新声明；<code>const</code>声明的变量既不能重新更新也不能重新声明；</li><li><code>var</code>和<code>let</code>声明的变量可以不初始化，但是<code>const</code>声明的变量必须初始化；</li><li>其实，<code>var</code>、<code>let</code>、<code>const</code>声明的变量都会发生变量提升（即先使用后定义），<code>var</code>如果这样会被初始化为<code>undefined</code>，而<code>let</code>和<code>const</code>声明的变量则不会被初始化，会直接报错。</li></ol><h3 id="参考文献">参考文献</h3><ul><li><a href="https://mp.weixin.qq.com/s/uZOj5HzJmH_fNeUEPipqwA">var 很傻、let 很亲切 、const 更坚定</a></li></ul>]]></content>
      
      
      <categories>
          
          <category> 前端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JavaScript </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>微服务框架(二)——Spring Cloud</title>
      <link href="/2021/01/02/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%A1%86%E6%9E%B6(%E4%BA%8C)%E2%80%94%E2%80%94Spring%20Cloud/"/>
      <url>/2021/01/02/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%A1%86%E6%9E%B6(%E4%BA%8C)%E2%80%94%E2%80%94Spring%20Cloud/</url>
      
        <content type="html"><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><blockquote><p>Spring Cloud provides tools for developers to quickly build some of the common patterns in distributed systems (e.g. configuration management, service discovery, circuit breakers, intelligent routing, micro-proxy, control bus, one-time tokens, global locks, leadership election, distributed sessions, cluster state). Coordination of distributed systems leads to boiler plate patterns, and using Spring Cloud developers can quickly stand up services and applications that implement those patterns. They will work well in any distributed environment, including the developer’s own laptop, bare metal data centres, and managed platforms such as Cloud Foundry.</p></blockquote><span id="more"></span><p>Spring Cloud 是一系列框架的有序集合，它利用 SpringBoot 的开发便利性，巧妙地简化了分布式系统的基础设施的开发，如服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控等，都可以做到一键启动和部署。</p><p><strong>选用 Spring Cloud 的好处包括</strong>：</p><ul><li>基于 HTTP 协议，使用 RESTFUL 风格，接口简单方便，高效透明（Dubbo 是使用 RPC 协议，性能稍优于 HTTP 协议，但是耦合度更高）</li></ul><h2 id="核心成员"><a href="#核心成员" class="headerlink" title="核心成员"></a>核心成员</h2><ul><li>服务注册中心：<strong>Spring Cloud Netflix Eureka</strong></li><li>服务监控：<strong>SpringBoot Admin</strong></li><li>断路器：<strong>Spring Cloud Netflix Hystrix</strong></li><li>服务网关：<strong>Spring Cloud Netflix Zuul</strong></li><li>分布式配置：<strong>Spring Cloud Config</strong></li><li>服务跟踪：<strong>Spring Cloud Sleuth</strong></li><li>消息总线：<strong>Spring Cloud Bus</strong></li><li>数据流：<strong>Spring Cloud Stream</strong></li><li>批量任务：<strong>Spring Cloud Task</strong></li><li>服务调用方式：RESTFUL API</li></ul><h3 id="Spring-Cloud-Eureka"><a href="#Spring-Cloud-Eureka" class="headerlink" title="Spring Cloud Eureka"></a>Spring Cloud Eureka</h3><p>Eureka 是 Netflix 开发的服务发现组件，本身是一个基于 REST 的服务，主要用于定位运行在 AWS 域中的中间层服务，以达到负载均衡和中间层服务故障转移的目的。Spring Cloud 将其集成在其子项目 spring-cloud-netflix 上，以实现 Spring Cloud 的服务发现功能。</p><p>我们可以将自定义的 API 接口注册到 Spring Cloud Eureka 上，Eureka 负责服务的注册与发现，它的角色与 ZooKeeper 差不多，都是服务的注册与发现。所以，构成 Eureka 体系的包括：服务注册中心、服务提供者、服务消费者，主要包含两个组件：Eureka Server 和 Eureka Client。</p><p><img data-src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fabfd5a3d-ffe5-47d3-9693-92734bcdd380%2FUntitled.png?table=block&id=f1ac62d9-745c-4048-996b-2817e3a586e4&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=1440&userId=&cache=v2" alt="High Level Architecture"><span class="image-caption">High Level Architecture</span></p><blockquote><p>The architecture above depicts how Eureka is deployed at Netflix and this is how you would typically run it. There is <strong>one</strong> eureka cluster per <strong>region</strong> which knows only about instances in its region. There is at the least <strong>one</strong> eureka server per zone to handle <strong>zone</strong> failures.</p><p>Services <strong>register</strong> with Eureka and then send <strong>heartbeats</strong> to renew their leases every 30 seconds. If the client cannot renew the lease for a few times, it is taken out of the server registry in about 90 seconds. The registration information and the renewals are replicated to all the eureka nodes in the cluster. The clients from any zone can look up the <strong>registry</strong> information (happens every 30 seconds) to locate their services (which could be in any zone) and make remote calls.</p></blockquote><p>Eureka Server 提供服务注册功能，提供者节点启动后，会在 Eureka Server 中进行注册，所以 Eureka Server 的服务注册表中将会存储所有可用服务节点的信息。各个提供者会向 Euraka Server 发送心跳，以告知 Eureka Server 自己的健康状况，默认周期为 30 秒。如果在多个心跳周期内都没有接收到某个提供者节点的心跳，那么 Eureka Server 就会认为其已经无法提供服务，就会将该节点从服务注册表中移除。Eureka Server 之间是通过复制的方式完成数据的同步。</p><p>Eureka Client 是一个 Java 客户端，是用于简化消费者与 Eureka Server 的交互。同时，Eureka Client 内置有负载均衡器，为消费者从 Eureka Server 的服务注册表中选择合适的提供者。</p><p>Eureka 提供了客户端缓存机制，即使所有的 Eureka Server 都宕机，客户端仍然能够利用缓存的信息为消费者提供服务发现功能。但此时就不再接受服务注册。</p><p>综上，Eureka 通过心跳检查、客户端缓存等机制，确保了系统的高可用性、灵活性和可伸缩性。</p><h3 id="Spring-Cloud-Hystrix"><a href="#Spring-Cloud-Hystrix" class="headerlink" title="Spring Cloud Hystrix"></a>Spring Cloud Hystrix</h3><p>Hystrix 的意思是豪猪，所以，它表明了框架的主要功能：<strong>自我保护功能</strong>。Hystrix 是一个用于处理分布式系统的延迟和容错的开源库。Hystrix 具有服务降级，熔断，线程池隔离，信号量隔离，缓存等功能。它能够保证在一个依赖出现问题的情况下，不会倒置整体服务失败，避免级联故障，提高分布式系统的弹性。</p><p>「断路器」本身是一种开关装置，当某个服务单元发生故障之后，通过断路器的故障监控（类似保险熔断），向调用方法返回一个符合预期的，可处理的被选相应（FallBack 降级操作），而不是长时间的等待或者抛出无法处理的异常。这样保证了服务调用方法的线程不会长时间，不必要地占用，从而避免了故障在分布式系统中的蔓延，从而导致雪崩效应。</p><p>如下图所示，断路器有对应的三个阶段：</p><ul><li>第一阶段：正常</li><li>第二阶段：发现超时或者失败后，标识失败</li><li>第三阶段：达到阈值之后，触发了熔断器策略，标识服务不可用，熔断器就自动断开。如果此时 B 对 C 有访问，熔断器会给 B 立刻返回失败，不再调用 C。同时进行间断性尝试，判断服务是否恢复</li></ul><p><img data-src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fc0ea64c4-d0e3-4fb8-a0b6-00e98063ed6f%2FUntitled.png?table=block&id=8a1e3ed0-796d-4243-b9a6-c31a77bcbffe&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=1540&userId=&cache=v2" alt="Hystrix 的三种情况"><span class="image-caption">Hystrix 的三种情况</span></p><p>Hystrix 存在三种模式：</p><ul><li><strong>断路器模式</strong>：设置超时或者失败等熔断策略</li><li><strong>后备策略模式</strong>：在第二阶段或者第三阶段失败时，如果存在后备策略，都会去执行后备策略</li><li><strong>舱壁模式</strong>：保证一个服务独享一个线程池</li></ul><p>所以，Hystrix 的功能执行如下：</p><ul><li>熔断触发前，超时或者失败发生时：<ul><li>如果存在后备策略，执行后备策略</li><li>如果不存在后备策略，抛出异常处理</li></ul></li><li>在熔断触发之前后，立即返回失败，保护下游失败<ul><li>存在后备策略，则执行</li><li>不存在，则抛出异常</li></ul></li><li>在熔断器触发了之后，还可以定期检查服务是否正常，将服务恢复正常</li></ul><h3 id="Spring-Cloud-Zuul"><a href="#Spring-Cloud-Zuul" class="headerlink" title="Spring Cloud Zuul"></a>Spring Cloud Zuul</h3><p>Spring Cloud Zuul 是 Spring Cloud Netflix 子项目的核心组件之一，可以作为微服务架构中的 API 网关使用，支持动态请求路由、负载均衡、效验过滤、服务容错、服务聚合等功能。API 网关为微服务架构中的服务提供了统一的访问入口，客户端通过 API 网关访问相关服务。</p><p>Zuul 的核心是一系列的 Filters，其作用类比于 Servlet 框架的 Filter，或者 AOP。其大部分功能都是通过过滤器来实现的，它们能够执行非常大范围的操作，并且可以在请求-响应生命周期的不同阶段运行，如下图所示：</p><p><img data-src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fa6f2c487-a28e-4f3f-a1ed-601dfadcb09c%2FUntitled.png?table=block&id=72526c44-29bd-4f51-94de-e163810497fb&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=1740&userId=&cache=v2" alt="Zuul"><span class="image-caption">Zuul</span></p><p>其定义了四种标准过滤器类型：</p><ul><li>PRE：这种过滤器在请求被路由之前调用。可以用这种过滤器实现身份验证、在集群中选择请求的微服务、记录调试信息等</li><li>ROUTING：这种过滤器是用于构建发送给微服务的请求，并使用 Apache HttpClient 或者 Netflix Ribbon 请求微服务</li><li>POST：这种过滤器在路由到微服务以后执行，可用来为响应添加标准的 HTTP Header、收集统计信息和指标、将相应从微服务发回给客户端等</li><li>ERROR：在其它阶段发生错误时执行该过滤器</li></ul><p><img data-src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F15798a35-c61c-4c8c-837a-67bf13f2af1f%2FUntitled.png?table=block&id=4e6471da-8fcb-441d-8f8f-808bac8ad498&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=1920&userId=&cache=v2" alt="Zuul 四种标准过滤器模型"><span class="image-caption">Zuul 四种标准过滤器模型</span></p><h3 id="Spring-Cloud-Config"><a href="#Spring-Cloud-Config" class="headerlink" title="Spring Cloud Config"></a>Spring Cloud Config</h3><p>在分布式系统中，因为服务数量很多，为了方便服务配置文件统一管理，实时更新，所以需要分布式配置中心组件。在 Spring Cloud 中，有分布式配置中心组件 Spring Cloud Config，它支持配置服务放在配置服务的内存中（本地），也支持放在远程 Git 中。</p><p>在 Spring Cloud Config 组件中，分两个角色：</p><ul><li>Config Server：一个可横向扩展、集中式的配置服务器，它用于集中管理应用程序各个环境下的配置，为客户端提供获取配置信息、加密、解密信息等访问接口</li><li>Config Client：是 Config Server 的客户端，是微服务架构中的各个微服务应用或基础设施，通过指定的配置中心来管理应用资源与业务相关的配置内容，并在启动的时候从配置中心获取和加载配置信息。</li></ul><p>基于消息总线的配置中心架构需要依赖外部的MQ组件，例如 RabbitMQ 或者 Kafka 等实现远程环境变更通知，客户端实时配置变更可以基于 Git Hook 功能实现。</p><h3 id="Spring-Cloud-Sleuth"><a href="#Spring-Cloud-Sleuth" class="headerlink" title="Spring Cloud Sleuth"></a>Spring Cloud Sleuth</h3><p>随着微服务部署的节点增多，以及对各个微服务的拆分后，对服务本身的日志和调用链路的监控变得更加困难。Spring Cloud Sleuth 就是为了解决分布式链路追踪这个问题而生的。</p><p>Spring Cloud Sleuth 的实体概念主要来源于谷歌在 2010 年发表的一篇论文：《Dapper, a Large-Scale Distributed Systems Tracing Infrastructure》：</p><ul><li>Span：基本工作单元。发送RPC就是一个新的 span，就像 RPC 发送响应那样。Span 携带了 span 的唯一 64 位标识、另外一个 Trace 的 64 位的标识。Span 还有其余的数据，例如描述、带时间戳的事件、键值 annotations（标签）等。</li><li>Trace：一组 span 造成的树状结构；</li><li>Annotation：用于及时记录事件的存在</li></ul><p>微服务日志追踪主要包括：</p><ul><li>日志输出</li><li>日志收集</li><li>分布式链路追踪：以集成 Zipkin 服务为基础，准备 4 个微服务工程：<ul><li>eureka server：复杂服务注册</li><li>zipkin server：负责链路数据收集以及查询</li><li>zuul-gateway：服务网关，负责调用</li><li>personal-service：作为后台 server，负责调用</li></ul></li></ul><h3 id="Spring-Cloud-Bus"><a href="#Spring-Cloud-Bus" class="headerlink" title="Spring Cloud Bus"></a>Spring Cloud Bus</h3><p>Spring Cloud Config 的作用的帮助更新配置文件，即配置文件可以通过 Config Server 存储到 Git 地方，通过 Config Client 进行读取。但是配置发生变化时，又是如何进行更新的呢？</p><p>一种简单的方式是关闭服务，重新让 Config Client 进行获取。但是这样需要关闭服务，Spring Cloud 肯定不允许这样做。那么，它需要通过「消息总线」的方式来进行通知。</p><p>这套机制是：我们使用消息代理来构建一个 Topic，然后把微服务架构中的所有服务都连接到这个主题上，当我们向该主题发送消息时，所有订阅了该主题的服务都会收到消息并进行消费。目前 Spring Cloud Bus 支持两种主流的消息代理：RabbitMQ 和 Kafka。</p><p><img data-src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fabe679f8-7ab8-46d7-9bb2-b94cb507df6b%2FUntitled.png?table=block&id=4d41b6b8-dd47-48d2-a640-89c4741a3977&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=1280&userId=&cache=v2" alt="Spring Cloud Bus 的执行步骤"><span class="image-caption">Spring Cloud Bus 的执行步骤</span></p><p>从上图可以看出 Spring Cloud Bus 的执行步骤：</p><ul><li>提交代码给客户端 A</li><li>客户端 A 收到了请求，从 Server 端更新配置，发送给 Spring Cloud Bus</li><li>Spring Cloud Bus 接收到消息，<strong>通知</strong>其它的客户端</li><li>其它客户端接收到通知，请求 Server 端，获取最新的配置</li><li>这样，全部的客户端都能获取到更新的配置</li></ul><h3 id="Spring-Cloud-Stream"><a href="#Spring-Cloud-Stream" class="headerlink" title="Spring Cloud Stream"></a>Spring Cloud Stream</h3><p>Spring Cloud Stream 在 Spring Cloud 体系内用于构建高度可扩展的基于事件驱动的微服务。而 SCS(Spring Cloud Stream) 是在 Spring Message 和 Spring Integration 两个项目的基础上完成构建的。</p><p>Spring Message 模块是 Spring Framework 的一个模块，其作用就是统一消息的编程模型。</p><p>生产者 Producer 发送消息到消息通道 Message Channel中，消费者 Consumer 调用<code>receive()</code>方法从消息通道中获取到消息。</p><p>Spring Integration 提供了 Spring 编程模型的扩展，用来支持企业集成模式（Enterprise Integration Patterns）。</p><p>Spring Integration 是对 Spring Messaging 的扩展。它提出了不少新的概念，包括消息的路由 MessageRoute、消息的分发 MessageDispatcher、消息过滤 Filter、消息转换 Transfoer、消息聚合 Aggregator、消息分隔 Splitter等等。</p><hr><p>SCS 则是 Spring Integration 的加强，同时与 SpringBoot 体系融合，也是 Spring Cloud Bus 的基础。<strong>它屏蔽了底层消息中间件的实现细节，希望以统一的一套 API 来进行消息的发送/消费，底层消息中间件的实现细节由各消息中间件的 Binder 来完成</strong>。</p><p><img data-src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fc9ce6244-b6c6-4991-949f-3a9f5025a4f9%2FUntitled.png?table=block&id=a4d7b3ec-4da7-409a-9635-b33b7cbdd734&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=5580&userId=&cache=v2" alt="Binder 细节"><span class="image-caption">Binder 细节</span></p><p>Binder 是提供与外部消息中间件集成的组件，会构造 Binding，内部构造实现生产者和消费者。<strong>它是连接应用程序跟消息中间件的桥梁，用于消息的消费和生产</strong>。</p><p>SCS 解决了开发人员无感知的使用消息中间件的问题，因为 SCS 对消息中间件的进一步封装，可以做到代码层面对中间件的无感知，甚至还可以动态切换中间件。这使得微服务开发的高度解耦，服务可以主要关注自己的流程。</p><h3 id="Spring-Cloud-Task"><a href="#Spring-Cloud-Task" class="headerlink" title="Spring Cloud Task"></a>Spring Cloud Task</h3><p>Spring Cloud Task 允许用户使用 Spring Cloud 开发和运行短期微服务，并在云和本地运行，甚至还可以在 Spring Cloud Data Flow 上运行。</p><p>Spring Cloud Task 主要是来解决<code>short lived microservices</code>的问题的。因为一般的应用服务都是长时间运转的不停止的，但是有些服务却具有以下特点：</p><ul><li>定时的服务</li><li>临时的服务</li><li>占用资源过多的服务</li></ul><p>这些服务因为重要性偏低，所以可以交个 Spring Cloud Task 来执行。除此之外，有些任务是串联的。一个业务会牵扯到多个业务，任务之间是通过事件触发的，这就是 Spring Cloud Stream 来解决的。</p>]]></content>
      
      
      <categories>
          
          <category> 微服务 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring Cloud </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>微服务框架(一)——Dubbo</title>
      <link href="/2021/01/01/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%A1%86%E6%9E%B6(%E4%B8%80)--Dubbo/"/>
      <url>/2021/01/01/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%A1%86%E6%9E%B6(%E4%B8%80)--Dubbo/</url>
      
        <content type="html"><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><blockquote><p>Dubbo 是一个分布式服务框架，致力于提高性能和透明化的 RPC 远程过程调用的方案，以及 SOA 服务治理方案。</p></blockquote><span id="more"></span><p>其核心部分包括了：</p><ul><li><strong>远程通讯</strong>：提供对多种基于长连接的 NIO 框架的抽象封装，包括多种线程模型，序列化，以及「请求-响应」模式的信息交换模式等。</li><li><strong>集群容错</strong>：提供基于接口方法的透明远程过程调用，包括了多协议支持，以及软负载均衡，失败容错，地址路由，动态配置等集群支持。</li><li><strong>自动发现</strong>：基于注册中心目录服务，使服务消费者能够动态地查找服务提供方，使地址透明，使服务提供方可以平滑增加或者减少机器。</li><li><strong>服务自动注册与发现</strong>：不再需要写死服务提供方的地址，注册中心基于接口名来查询服务提供者的 IP 地址，并且能够平滑地添加或者删除服务提供者。</li></ul><h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p><img data-src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fee0603ab-b099-4ebd-a2ec-41951b062eb4%2FUntitled.png?table=block&id=d0923cc5-ea67-4c11-bcff-da6096561c4c&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=1540&userId=&cache=v2" alt="Dubbo 架构"><span class="image-caption">Dubbo 架构</span></p><p><strong>节点角色的说明</strong>：</p><ul><li><strong>Provider</strong>：暴露服务的服务提供方</li><li><strong>Consumer</strong>：调用远程服务的服务消费方</li><li><strong>Registry</strong>：服务注册与发现的注册中心</li><li><strong>Monitor</strong>：统计服务的调用次数和调用时间的监控中心</li><li><strong>Container</strong>：服务运行的容器</li></ul><p><strong>调用关系说明</strong>：</p><ul><li>服务容器负责启动，加载，运行服务提供者</li><li>服务提供者在启动时，向注册中心注册自己提供的服务</li><li>服务消费者在启动时，向注册中心订阅自己所需要的服务</li><li>注册中心会返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者</li><li>服务消费者会从提供者地址列表中，基于软负载均衡的算法，选一台提供者进行调用，入股哦调用失败，再选择另一台进行调用</li><li>服务消费者和提供者，都会在内存中累计调用次数和调用时间，定时每分钟发送一个统计次数的数据到监控中心</li></ul><h3 id="注册中心"><a href="#注册中心" class="headerlink" title="注册中心"></a>注册中心</h3><p>Dubbo 提供的注册中心有以下几种类型可以选择：</p><ul><li>Multicast 注册中心</li><li>ZooKeeper 注册中心：ZooKeeper 集群由一组 Server 节点组成，这一组 Server 节点中存在一个角色作为 Leader 的节点，其它节点则为 Follower。当客户端 Client 连接到 ZooKeeper 集群后，执行写请求时，这些请求会被发送到 Leader 节点上，然后 Leader 节点上的数据变更会同步到集群中其它的 Follower 节点。</li><li>Redis 注册中心</li><li>Simple 注册中心</li></ul><h3 id="网络协议"><a href="#网络协议" class="headerlink" title="网络协议"></a>网络协议</h3><p>远程通信需要指定通信双方所约定的协议，在保证通信双方理解协议语义的基础上，保证高效、稳定的消息传输。Dubbo 继承了目前主流的网络通信框架：</p><ul><li>Mina</li><li>Netty</li><li>Grizzly</li></ul><h3 id="远程调用协议"><a href="#远程调用协议" class="headerlink" title="远程调用协议"></a>远程调用协议</h3><p>Dubbo 支持的远程调用协议：</p><ul><li>Dubbo 协议</li><li>HTTP 协议</li><li>RMI 协议</li><li>Web Service 协议</li><li>Thrift 协议</li><li>Redis 协议</li></ul><p>在通信过程中，不同的服务等级一般对应着不同的服务质量，所以要根据应用的创建场景来选择协议。</p><h2 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h2><h3 id="连通性"><a href="#连通性" class="headerlink" title="连通性"></a>连通性</h3><ul><li><p>注册中心负责服务地址的注册与查找，<strong>相当于目录服务</strong>，服务提供者和消费者只在启动的时候与注册中心交互，所以注册中心不会转发请求，压力较小。</p></li><li><p>监控中心负责统计各个服务的调用次数、调用时间等，统计先在内存汇总后每分钟一个发送到监控中心的服务器里。</p></li><li><p>服务提供者向注册中心注册其提供的服务，并汇报调用时间到监控中心，此时间内是不包括网络开销的。</p></li><li><p>服务消费者向注册中心获取服务提供者的地址列表，并根据负载算法直接调用提供者，同时汇报调用时间到监控中心，此时间是包含网络开销的。</p></li><li><p>注册中心、服务提供者、服务消费者三者之间都是<strong>长连接</strong>，监控中心除外。</p></li><li><p>注册中心通过长连接感知服务提供者的存在，如果服务提供者宕机了，注册中心会立即推送事件通知消费者；如果注册中心和监控中心都宕机了，不会影响已有的提供者和消费者，消费者在本地缓存了提供者的列表；注册中心和监控中心全部都宕机了，服务消费者可以直接连接服务提供者。</p></li></ul><h3 id="健壮性"><a href="#健壮性" class="headerlink" title="健壮性"></a>健壮性</h3><ul><li>监控中心宕机了，不影响使用，只是会缺少部分采样数据；</li><li>数据库宕机了，注册中心仍能够缓存提供服务列表进行查询，但是不能注册新的服务</li><li>注册中心对等的集群中的任意一台宕机了，将自动切换到另外一台</li><li>注册中心全部宕机了，服务提供者和服务消费者仍然能够通过本地缓存进行通讯</li><li>如果服务提供者无状态了，任意一台宕机了，也不影响使用</li><li>如果服务提供者全部宕机了，服务消费者应用将无法使用，并且无限次重连等待服务提供者恢复</li></ul><h3 id="伸缩性"><a href="#伸缩性" class="headerlink" title="伸缩性"></a>伸缩性</h3><p>注册中心对等集群，可以动态增加机器部署实例，所有客户端将自动发现新的注册中心；如果服务提供者无状态了，也可以动态增加机器部署实例，并且注册中心将推送新的服务提供者信息给消费者</p><h3 id="升级性"><a href="#升级性" class="headerlink" title="升级性"></a>升级性</h3><p>当服务集群规模进一步扩大，带动 IT 结构进一步升级，需要实现动态部署，进行流动计算，现有的分布式服务架构不会带来阻力。</p>]]></content>
      
      
      <categories>
          
          <category> 微服务 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Dubbo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重入锁 ReentrantLock 以及公平性问题</title>
      <link href="/2020/12/09/%E9%87%8D%E5%85%A5%E9%94%81ReentrantLock%E4%BB%A5%E5%8F%8A%E5%85%AC%E5%B9%B3%E6%80%A7%E9%97%AE%E9%A2%98/"/>
      <url>/2020/12/09/%E9%87%8D%E5%85%A5%E9%94%81ReentrantLock%E4%BB%A5%E5%8F%8A%E5%85%AC%E5%B9%B3%E6%80%A7%E9%97%AE%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h2 id="概念">概念</h2><p>重入锁 ReentrantLock，是指支持重进入的锁，表示锁可以支持一个线程对资源的重复加锁，即「任意线程在获取到这个锁之后，如果再次获取该锁，不会被锁阻塞」。重入锁还支持锁时的<strong>公平</strong>和<strong>非公平性</strong>（默认）的选择。</p><span id="more"></span><h3 id="实现">实现</h3><p>实现重入的机制，需要解决以下两个问题：</p><ul><li>线程需要再次获取锁：锁一定要能够识别获取锁的线程是否是当前占据锁的线程，如果符合，就能够获取成功</li><li>锁需要得到最终的释放：线程重复了 n 次获取了锁之后，就需要在第 n 次释放锁后，其它的线程才能获取到该锁。主要是通过<strong>计数器</strong>来实现。锁每获取一次，计数器就要自增 1；每释放一次，计数器就要自减 1，一直减到 0 为止，表示当前线程已经成功释放了该锁，其它线程可以来获取该锁。</li></ul><h3 id="重入性和公平性">重入性和公平性</h3><p>ReentrantLock 不支持隐式的重入锁，但是可以在调用<code>lock()</code>方法时，已经获取到锁的线程，能够再次调用<code>lock()</code>方法获取锁且不被阻塞。ReentrantLock 的公平与否，是通过构造方法来决定的，内部类<code>Sync</code>继承了<code>AQS</code>，分为公平锁<strong>FairSync</strong>和非公平锁<strong>NonfairSync</strong>。</p><h3 id="公平锁和非公平锁">公平锁和非公平锁</h3><blockquote><p>先对锁进行获取的请求肯定是优先执行的，锁获取的顺序也符合请求的绝对时间顺序，类似于 FIFO，那么就是公平锁。反之，就是非公平锁。</p></blockquote><p>以下是公平锁与非公平锁的测试输出结果：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 公平锁的结果</span></span><br><span class="line">FAIR lock by [<span class="number">9</span>], waiting by []</span><br><span class="line">FAIR lock by [<span class="number">10</span>], waiting by [<span class="number">11</span>, <span class="number">12</span>, <span class="number">9</span>]</span><br><span class="line">FAIR lock by [<span class="number">11</span>], waiting by [<span class="number">12</span>, <span class="number">9</span>, <span class="number">13</span>, <span class="number">10</span>]</span><br><span class="line">FAIR lock by [<span class="number">12</span>], waiting by [<span class="number">9</span>, <span class="number">13</span>, <span class="number">10</span>, <span class="number">11</span>]</span><br><span class="line">FAIR lock by [<span class="number">9</span>], waiting by [<span class="number">13</span>, <span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>]</span><br><span class="line">FAIR lock by [<span class="number">13</span>], waiting by [<span class="number">10</span>, <span class="number">11</span>, <span class="number">12</span>]</span><br><span class="line">FAIR lock by [<span class="number">10</span>], waiting by [<span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>]</span><br><span class="line">FAIR lock by [<span class="number">11</span>], waiting by [<span class="number">12</span>, <span class="number">13</span>]</span><br><span class="line">FAIR lock by [<span class="number">12</span>], waiting by [<span class="number">13</span>]</span><br><span class="line">FAIR lock by [<span class="number">13</span>], waiting by []</span><br><span class="line"></span><br><span class="line"><span class="comment">// 非公平锁的结果</span></span><br><span class="line">UNFAIR lock by [<span class="number">10</span>], waiting by [<span class="number">9</span>, <span class="number">11</span>]</span><br><span class="line">UNFAIR lock by [<span class="number">10</span>], waiting by [<span class="number">9</span>, <span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>]</span><br><span class="line">UNFAIR lock by [<span class="number">9</span>], waiting by [<span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>]</span><br><span class="line">UNFAIR lock by [<span class="number">9</span>], waiting by [<span class="number">11</span>, <span class="number">12</span>, <span class="number">13</span>]</span><br><span class="line">UNFAIR lock by [<span class="number">11</span>], waiting by [<span class="number">12</span>, <span class="number">13</span>]</span><br><span class="line">UNFAIR lock by [<span class="number">11</span>], waiting by [<span class="number">12</span>, <span class="number">13</span>]</span><br><span class="line">UNFAIR lock by [<span class="number">12</span>], waiting by [<span class="number">13</span>]</span><br><span class="line">UNFAIR lock by [<span class="number">12</span>], waiting by [<span class="number">13</span>]</span><br><span class="line">UNFAIR lock by [<span class="number">13</span>], waiting by []</span><br><span class="line">UNFAIR lock by [<span class="number">13</span>], waiting by []</span><br></pre></td></tr></table></figure><p>从结果中我们可以看出，公平锁每次都是从同步队列中的第一个节点获取锁，而非公平锁则是会连续两次获取锁。</p><p>从开销上来看，<strong>公平锁的开销会更大一些</strong>，因为它每次都要切换到另一个线程，而对于非公平锁，会出现连续获取锁的对象，切换次数要少一些，所以<strong>非公平锁的开销会更小一些</strong>。所以，公平锁保证了锁的获取按照顺序进行，保证了公平性，解决了<strong>饥饿问题</strong>，但是增加了大量的线程切换。</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 锁 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RabbitMQ ActiveMQ RocketMQ 入门</title>
      <link href="/2020/11/22/RabbitMQ%20ActiveMQ%20RocketMQ%E5%85%A5%E9%97%A8/"/>
      <url>/2020/11/22/RabbitMQ%20ActiveMQ%20RocketMQ%E5%85%A5%E9%97%A8/</url>
      
        <content type="html"><![CDATA[<h2 id="消息队列">消息队列</h2><p>消息队列，即 Message Queue(MQ)，是一种应用程序对应用程序的通信方法，。应用程序通过读写出入队列的消息来通信，而无须专用连接来连接它们。</p><span id="more"></span><p>消息队列是是典型的生产者、消费者模型。生产者不断生成消息添加到队列中，消费者不断地从队列中获取消息。因为消息的生产和消费都是异步的，并且消息队列只关注消息的发送与接收，并没有业务逻辑的侵入，这样就实现了生产者和消费者之间的解耦。</p><p>消息传递是指程序之间通过在消息中发送数据进行通信，而不是通过直接调用彼此来通信。</p><p>使用消息队列的好处就是将一些无需即时返回且耗时的操作提取出来，进行了异步处理，大大节省了服务器的请求响应时间，从而提高了系统的吞吐量。</p><h3 id="为什么使用消息队列">为什么使用消息队列</h3><p>主要在三个方面：<strong>异步</strong>、<strong>解耦</strong>、<strong>削峰</strong></p><h4 id="异步处理">异步处理</h4><p>例如，用户注册模块，需要发送注册邮件和注册短信，那么传统的方式有：</p><ol type="1"><li>串行的方式：将注册信息直接写入数据库后，然后先发送注册邮件，再发送注册短信，以上三个任务都完成了，才返回给客户端；这种方式会让用户一直等待，假如每个阶段要消耗 50ms，那么用户就需要等待 150ms；</li><li>并行的方式：将注册的信息写入数据库后，同时发送邮件和短信，这样就让邮件和短信的阶段并行操作，节省了时间，用户只需要等待 100ms；</li></ol><p>然而，如果使用消息队列，就更能够高效地处理。引入消息队列后，可以把发送邮件、短信等操作当作不是必须的业务逻辑来异步处理。假设，写入消息队列的时间是 5ms，那么用户总共只需要等待写入数据库的时间加上写入消息队列的时间，总共是 55ms。</p><h4 id="应用解耦">应用解耦</h4><p>例如，对于一个购物系统而言，用户下单后，订单系统需要通知库存系统，那么最普通的做法就是「订单系统直接调用库存系统的接口去通知并更改」。</p><p>这种做法的缺点就是：</p><ul><li>当库存系统出现故障时，那么订单会失败</li><li>订单系统和库存系统直接联系过于紧密，高度耦合</li></ul><p>那么，如果引入消息队列呢？</p><p>用户下单后，订单系统完成持久化处理后，将消息写入消息队列中，直接返回用户订单下单成功；库存系统通过订阅订单系统的信息，获取下单消息，进行库存管理的操作。</p><p>这样，即使库存系统出现了故障，消息队列里存储的消息至少保证了消息的可靠传递，不会导致消息丢失。</p><h4 id="流量削峰">流量削峰</h4><p>例如，一个系统每天大部分时间的请求只有每秒 50 个，但是高峰期期间却会突增到每秒 10000 个请求，而系统最高只能处理 1000 个请求。所以，这样直接访问肯定会导致系统崩溃的。即<strong>低峰期无压力，高峰期扛不住</strong>。那么，如果使用了消息队列，把所有的请求都先写入消息队列，系统再从消息队列里慢慢拉取请求，只要拉取并处理的速度不超过系统自己能够处理的最大能力即可。</p><h3 id="消息队列的缺点">消息队列的缺点</h3><ul><li>系统的可用性降低了，因为引入的外部依赖越过，系统就越复杂</li><li>使用消息队列，需要保证消息不能重复消费，消息不能丢失，已经消息传递的顺序等等问题</li><li>当生产者生产消息并添加到消息队列中就会直接返回请求成功，但是必须要确保已添加到消息队列的消息不会堆积，处理也不会出现问题，不然数据的一致性就会出现问题</li></ul><h2 id="amqp">AMQP</h2><p>AMQP，即 Advanced Message Queuing Protocol，一个提供统一消息服务的应用层标准<strong>高级消息队列协议</strong>，是为面向消息的中间件设计的。基于此协议的客户端与消息中间件可传递消息，并不受不同产品或者不同编程语言等条件的限制。</p><blockquote><p>AMQP 的主要特征是面向消息、队列、路由（包括点对点和发布/订阅）、可靠性、安全等。</p></blockquote><h3 id="jms">JMS</h3><p>JMS（Java Message Service）是 Sun 公司最早提出的消息标准，是为了 Java 应用提供统一的消息操作，它与 AMQP 有以下的不同：</p><ul><li>JSM 定义了同一个接口；AMQP 是通过规定协议来统一数据交互的格式；</li><li>JMS 只能在 Java 语言中使用；而 AMQP 只是协议，是跨语言的；</li><li>JMS 规定了两种消息模型；而 AMQP 的消息模型则更加丰富；</li></ul><h3 id="常见的-amqp">常见的 AMQP</h3><ul><li>ActiveMQ：基于 JMS</li><li>RabbitMQ：基于 AMQP 协议，稳定性好</li><li>RocketMQ：基于 JMS，是阿里开发的，由 Apache 维护</li><li>Kafka：分布式的消息系统，高吞吐量</li></ul><h2 id="消息队列的应用场景">消息队列的应用场景</h2><p>一个大型的软件系统，会有很多的组件或者模块或者子系统，如果将这些模块进行通信呢？传统的 IPC 是很多都在单一系统上，模块耦合性很大，不适合拓展；如果使用 Socket 进行通信，那么又需要考虑到以下一些问题：</p><ul><li>信息的发送者和接收者如何维持这个连接，如果一方连接中断，丢失的数据怎么办</li><li>如何降低发送者和接收者的耦合度</li><li>如何让 Priority 高的接收者更先接受到数据</li><li>如果做到负载均衡？</li><li>如何做到可拓展，甚至可以将该通信模块发送到集群 cluster 上？</li><li>如何保证接收者接受到了完整、正确的数据</li></ul><p>AMQP 协议就解决了以上问题，而 RabbitMQ 就是基于 AMQP 实现的。</p><h2 id="rabbitmq-简介">RabbitMQ 简介</h2><blockquote><p>RabbitMQ is the most widely deployed open source message broker.</p></blockquote><p>RabbitMQ 就是在 AMQP 的基础上实现的，可复用的企业消息系统。它可以用于大型软件系统各个模块之间的高效通信，支持<strong>高并发</strong>，支持可拓展。</p><h3 id="常用命令">常用命令</h3><ul><li>启动 rabbitmq：<code>rabbitmq-service start</code></li><li>关闭 rabbitmq：<code>rabbitmq-service stop</code></li><li>启动监控管理器：<code>rabbitmq-plugins enable rabbitmq_management</code></li><li>关闭监控管理器：<code>rabbitmq-plugins disable rabbitmq_management</code></li><li>关闭应用：<code>rabbitmqctl stop_app</code></li><li>启动应用：<code>rabbitmqctl start_app</code></li></ul><h3 id="概念介绍">概念介绍</h3><ul><li>Broker：消息队列服务器实体</li><li>Exchange：消息交换机，指定消息按什么原则，路由由哪个队列（用于转发消息，但是不会被存储）</li><li>Queue：消息队列载体，每个消息都会被投入到一个或者多个队列中</li><li>Binding：将 exchange 和 queue 按照路由的规则绑定起来</li><li>Rounting Key：路由的关键字，exchange 就是根据这个关键字进行消息投递</li><li>vhost：虚拟主机，一个 broker 里可以开启多个 vhost，用作不同用户的权限分离</li><li>producer：消息生产者，就是投递消息的程序</li><li>consumer：消息消费者，就是接受消息的程序</li><li>channel：消息通道，在客户端的每个连接里，可以建立多个 channel，每个 channel 代表一个任务</li></ul><h3 id="四种交换机-exchange">四种交换机 Exchange</h3><h4 id="direct-exchange">Direct Exchange</h4><p>其行为是「先匹配，再投送」。绑定时会设定一个 rounting key，只有消息的 rounting key 匹配时，才会被交换机投送到绑定的队列中去。这是 RabbitMQ 默认的交换机模式，也是最简单的模式，是根据 key 全文匹配去寻找队列。</p><h4 id="topic-exchange">Topic Exchange</h4><p>按规则转发消息主要是<strong>根据通配符</strong>。在这种交换机下，队列和交换机的绑定会定义一种路由模式。通配符需要在这种路由模式和路由键之间匹配后，交换机才能转发消息。</p><p>路由键必须是一串字符，用句号（.）隔开。</p><p>路由模式必须包含一个星号（*），主要是用于匹配路由键指定位置的一个单词，（#）表示相当于一个或者多个单词</p><h4 id="headers-exchange">Headers Exchange</h4><p>设置 header attribute 参数类型的交换机，headers 是一个自定义匹配规则的类型。在队列与交换器绑定时，会设定一组键值对规则，消息中也包括了一组键值对属性，当有一对或者全部匹配时，消息就会被投送到对应的队列中。</p><h4 id="fanout-exchange">Fanout Exchange</h4><p>转发消息到所有绑定队列中，消息广播的模式，不管路由键或者是路由模式，会把消息发给绑定给它的全部队列。</p><h3 id="使用流程">使用流程</h3><blockquote><p>消息在 Producer 中产生，发送到消息队列的 Exchange 上，Exchange 根据配置的路由方式 Rounting Key，发送到并绑定 Queue。Queue 将消息通过 push 或者 pull 的方式传递给 Consumer。</p></blockquote><ol type="1"><li>客户端连接到消息队列的服务器，开启一个 channel</li><li>客户端声明一个 exchange，并设置相关属性</li><li>客户端声明一个 queue，并设置相关属性</li><li>客户端使用 rounting key，在 exchange 和 queue 之间建立好绑定关系</li><li>客户端投递信息到 exchange</li><li>exchange 收到信息后，根据 rounting key 和 binding 关系，将消息传递到 queue 中</li></ol><h2 id="activemq-简介">ActiveMQ 简介</h2><h2 id="rocketmq-简介">RocketMQ 简介</h2>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 消息队列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>理解 Spring 的控制反转和依赖注入以及 AOP</title>
      <link href="/2020/11/15/%E7%90%86%E8%A7%A3Spring%E7%9A%84IOC%E5%92%8CDI%E4%BB%A5%E5%8F%8AAOP/"/>
      <url>/2020/11/15/%E7%90%86%E8%A7%A3Spring%E7%9A%84IOC%E5%92%8CDI%E4%BB%A5%E5%8F%8AAOP/</url>
      
        <content type="html"><![CDATA[<h2 id="依赖倒置原则"><a href="#依赖倒置原则" class="headerlink" title="依赖倒置原则"></a>依赖倒置原则</h2><p>在了解控制反转之前，有必要了解软件设计里的一个重要思想：<strong>依赖倒置原则</strong>。</p><p>这里可以举一个汽车的例子来说明。假如我们来设计一辆汽车，先设计轮子，再根据轮子的大小去设计底盘，根据底盘去设计车身，最终根据车身来设计好整个车子。这样就会形成了一个如下的依赖关系：</p><p><img data-src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F75e1eb1b-dbf3-4ce6-8511-ce9e22a7165d%2FUntitled.png?table=block&id=df0a0c25-d2c9-448d-8723-2b43d91876ab&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=3120&userId=&cache=v2"></p><p>这种设计的维护性非常低。假如完工之后，需要更改轮子的设计，那么轮子上层的所有事物的设计都得修改，即整个设计都需要修改。</p><p>所以，我们需要换一种思路来实现。先设计出汽车的模型，再设计车身，根据车身设计底盘的大小，最后设计底层的轮子。那么，依赖关系就导致了。轮子的设计取决于底盘，底盘取决于车身，车身依赖车子的设计。所以，依赖关系变成了这样：</p><p><img data-src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F91709ca1-f7bf-4af1-96d9-1eeb29cc112d%2FUntitled.png?table=block&id=be653fcb-a133-4fee-96d7-a5532ccb5631&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=3010&userId=&cache=v2"></p><p>这样，当需要修改轮子时，只要改动轮子自己的设计就可，因为没有实物是依赖于轮子的。如果是修改底盘，也只会影响到它底层的轮子，高层的事物不会被影响，就不会出现「牵一发而动全身」的情况了。</p><p>所以，原本是「高层建筑依赖底层建筑」，而现在变成了「底层建筑依赖于高层建筑」。</p><h2 id="控制反转和依赖注入"><a href="#控制反转和依赖注入" class="headerlink" title="控制反转和依赖注入"></a>控制反转和依赖注入</h2><p>Spring 中经常提到的控制反转（Inversion of Control，IOC）和依赖注入（dependency injection-DI）是等同的概念，<strong>控制反转是通过通过依赖注入实现的</strong>。所谓的依赖注入指的是：</p><blockquote><p><strong>容器</strong>负责创建对象和维护对象间的依赖关系，而不是通过<strong>对象本身</strong>来负责自己的创建和解决自己的依赖。</p><p>即 Spring 这个容器替开发者管理着一系列的类，需要的时候，就不用自己去定义，而是直接向 Spring 容器去索取。</p></blockquote><p>依赖注入的主要目的是为了<strong>解耦</strong>，这是一种<strong>组合</strong>的概念。举个例子，如果一个类要具有某个功能时，如果是继承具有此功能的父类，那么该子类就与父类耦合。而如果这个类是去<strong>组合</strong>具有这个功能的其它类，那么耦合度就会大大降低。</p><p><strong>注入方式</strong>：</p><ul><li><code>set</code>方式注入</li><li>构造方法注入</li><li>字段注入</li></ul><p><strong>注入类型</strong>：</p><ul><li>值类型注入</li><li>引用类型注入</li></ul><p>Spring IoC 容器（ApplicationContext）是负责创建 Bean，并通过容器将功能类 Bean 注入到自己需要的 Bean 中。Spring 提供了多种不同的方式，如使用 XML、<strong>注解</strong>、Java配置等来实现 Bean 的创建和注入。以上的这些配置方式都被称为是<strong>配置元数据</strong>，即<strong>描述数据的数据</strong>。Spring 容器通过解析这些配置元数据就可以进行 Bean 的初始化、配置和管理依赖等。</p><p><strong>声明 Bean 的注解</strong>：</p><ul><li><code>@Component</code>组件：没有明确的角色。</li><li><code>@Service</code>：在业务逻辑层（Service 层）中使用</li><li><code>@Repository</code>：在数据访问层（dao 层）中使用</li><li><code>@Controller</code>：在表现层（MVC -&gt; SpringMVC）中使用</li></ul><p><strong>注入 Bean 的注解</strong>，一般情况下通用（下面三个注解都可以注解在<code>set</code>方法或者属性上，优点是代码少，层次清晰）：</p><p><code>@Autowired</code>：Spring 提供的注解<br><code>@Inject</code>：JSR-330 提供的注解<br><code>@Resource</code>：JSR-250 提供的注解</p><h3 id="ApplicationContext-和-BeanFactory-的区别"><a href="#ApplicationContext-和-BeanFactory-的区别" class="headerlink" title="ApplicationContext 和 BeanFactory 的区别"></a>ApplicationContext 和 BeanFactory 的区别</h3><p><strong>ApplicationContext 接口</strong></p><ol><li>每次容器启动时，就会创建容器中配置的所有对象</li><li>提供了更多的功能</li></ol><p><strong>BeanFactory 接口</strong></p><ol><li>是 Spring 的原始接口，针对原始接口的实现类的功能较为单一</li><li>BeanFactory 接口实现类的容器，特点是每次在获得对象时才会创建对象</li></ol><h2 id="AOP"><a href="#AOP" class="headerlink" title="AOP"></a>AOP</h2><p>AOP 即面向切面编程。Spring 的 AOP 是用来解耦，<strong>AOP 可以让一组类共享相同的行为</strong>。</p><p>面向对象是通过继承类和接口的方式，会使代码的耦合度增加。AOP 就是弥补了 OOP 的不足之处。它能够让那些与业务无关，<strong>但是却被业务模块共同调用的逻辑或者责任</strong>（例如事务处理、日志管理、权限控制等）封装起来，降低模块间的耦合度，有利于未来的拓展性和可维护性。</p><h3 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h3><p>例如，银行系统里会有一个「取款」的流程和「查询余额」的流程。如果把它们两个的步骤都列举出来，会发现有一个相同的「验证流程」。那么，这个验证用户的代码是否可以提取出来，不放进主流程里呢？这里 AOP 就起到作用了。</p><p>在编写上述这个例子时，我们可以完全不考虑验证用户的步骤。我们可以在另外一个地方，写好验证用户的代码，然后通过，比如 Spring，告知这段代码会被添加到哪些地方，Spring 就会帮助我们 copy 过去。这样就降低了模块间的耦合度。</p><h3 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h3><ul><li><strong>横切关注点</strong>：要对哪些方法进行拦截，拦截后怎么处理，这些关注点都是<strong>横切关注点</strong>。</li><li><strong>切面（aspect）</strong>：切面是指对横切关注点的抽象</li><li><strong>连接点（joinpoint）</strong>：指被拦截到的点，即<strong>被拦截的方法</strong></li><li><strong>切入点（pointcut）</strong>：对连接点进行拦截的定义</li><li><strong>通知（advice）</strong>：拦截到连接点之间要执行的代码</li><li><strong>目标对象</strong>：代理的目标对象</li><li><strong>织入</strong>：将切面应用到目标对象并导致代理对象创建的过程</li><li><strong>引入</strong>：引入可以在运行期为类动态地添加一些方法或者字段</li></ul><h2 id="常用注解"><a href="#常用注解" class="headerlink" title="常用注解"></a>常用注解</h2><ul><li><code>@Controller</code>：表明这个类是 Spring 里的 Controller，将其声明为 Spring 的一个 Bean，Dispatcher Servlet 会自动扫描注解了解此注解的类，并且会把 Web 请求映射到注解<code>@RequestMapping</code>中。</li><li><code>@RequestMapping</code>：该注解是用来映射Web请求、处理类和方法的，可注解在类，也可注解在方法上。</li><li><code>@ResponseBody</code>：允许请求的参数放在请求体中</li><li><code>@PathVariable</code>：通过 path 可以看出，是用来接收路径参数的。</li><li><code>@RestController</code>：这其实是一个组合注解，组合了<code>@Controller</code>和<code>@ResponseBody</code>，所以如果是编写一个与界面交互数据有关的类，那么其实可以直接使用此注解。否则，就需要加<code>@Controller</code>和<code>@ResponseBody</code>的注解。</li></ul>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>线程池————建服务器应用程序的有效方法</title>
      <link href="/2020/11/09/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E2%80%94%E2%80%94%E2%80%94%E2%80%94%E5%BB%BA%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%9C%89%E6%95%88%E6%96%B9%E6%B3%95/"/>
      <url>/2020/11/09/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E2%80%94%E2%80%94%E2%80%94%E2%80%94%E5%BB%BA%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%9C%89%E6%95%88%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h2 id="简介">简介</h2><p>当需要频繁地创建多个线程进行耗时操作，每次都通过<code>new Thread</code>的方式去创建显然不是一种好的方式，因为每次<code>new Thread</code>新建和销毁对象性能较差，线程缺乏统一地管理，可能线程之间会竞争，可能会占用过多系统资源导致死锁，并且缺乏定时执行、线程中断等功能。</p><span id="more"></span><p>Java提供了 <strong>4</strong> 种线程池，它能够有效地管理、调度线程，避免过多的资源消耗。</p><p>它的优点如下：</p><ul><li>重用存在的线程，减少对象的创建、销毁的开销；</li><li>可有效地控制最大并发线程数，提高系统资源的使用率，同时避免过多资源竞争，避免阻塞；</li><li>可以提供定时执行、定期执行、单线程、并发数控制等功能；</li></ul><p>线程池都实现了<code>ExecutorService</code>接口，该接口定义了线程池需要实现的接口，比如<code>submit</code>、<code>execute</code>、<code>shutdown</code>等方法。它的实现有<code>ThreadPoolExecutor</code>以及<code>ScheduledThreadPoolExecutor</code>等等。JDK 还提供了一个<code>Executors</code>的工厂类来简化创建线程池的流程。</p><h3 id="组成部分">组成部分</h3><p>一个线程包括以下四个基本组成部分：</p><ul><li>线程池管理器（ThreadPool）：用于创建并管理线程池，包括<strong>创建线程池</strong>、<strong>销毁线程池</strong>、<strong>添加新任务</strong>等；</li><li>工作线程（WorkThread）：线程池中线程，在没有任务时是处于等待状态，可以循环地执行任务；</li><li>任务接口（Task）：每个任务必须实现的接口，以供工作线程调度任务的执行。它规定了任务的入口，任务执行完成后的收尾工作，任务的执行状态等等；</li><li>任务队列（TaskQueue）：用于存放没有处理的任务，提供一个缓冲机制。</li></ul><h3 id="设置线程数">设置线程数</h3><ol type="1"><li><p>高并发、任务执行时间短的业务怎么使用线程池</p><p><strong>线程池线程数可以设置为 CPU 核心数 + 1，减少线程上下文的切换</strong></p></li><li><p>并发不高、任务执行时间长的业务怎样使用线程池</p><ul><li>如果业务时间是集中在 IO 操作上，就是 <strong>IO 密集型的任务</strong>。因为 IO 操作并不占用 CPU，所以不要让所有的 CPU 闲下来，<strong>可以适当加大线程池中的线程数目（2 * CPU 核心数）</strong>，让 CPU 可以处理更多的业务</li><li>如果是业务时间集中在计算操作上，那么就是 <strong>CPU 密集型的任务</strong>。所以同样设置为 <strong>CPU 核心数 + 1</strong>，减少线程上下文的切换即可。</li></ul></li><li><p>并发高、业务执行时间长的业务怎样使用线程池</p><p>如果既是并发程度高，又是业务执行时间长的话，解决的关键在于整体架构的设计而不是线程池。</p></li></ol><h2 id="启动指定数量的线程threadpoolexecutor">启动指定数量的线程——ThreadPoolExecutor</h2><p>ThreadPoolExecutor 是线程池的主要实现之一，功能是启动指定数量的线程以及将任务添加到一个队列中，并且将任务分发给空闲的线程。<code>Executors</code>的生命周期包括 3 种状态：运行、空闲、终止。</p><p>ThreadPoolExecutor 的构造函数如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ThreadPoolExecutor</span><span class="params">(<span class="keyword">int</span> corePoolSize, <span class="keyword">int</span> maximumPoolSize, <span class="keyword">long</span> keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler)</span></span></span><br></pre></td></tr></table></figure><h3 id="workingqueue">workingQueue</h3><p>workingQueue 有下列几个常用的实现：</p><p><code>ArrayBlockingQueue</code>：基于<strong>数组</strong>结构实现的有界队列，按照 FIFO 原则对任务进行排序。如果队列满了还有任务进来，就调用拒绝策略。 <code>LinkedBlockingQueue</code>：基于<strong>链表</strong>结构实现的无界队列，按照 FIFO 原则对任务进行排序。因为是<strong>无界</strong>，所以肯定不会满，所以采用此队列会忽略拒绝策略。 <code>SynchronousQueue</code>：直接将任务提交给线程而不是将它加入到该队列中，所以实际上这个队列是空的。当新任务来了，但是线程池中不存在任何可以被调用的线程时，就会调用拒绝策略。 <code>PriorityBlockingQueue</code>：具有优先级的有界队列，可以自定义优先级。</p><p>当线程池与工作队列都满了的情况，对于新添加任务也有一些默认实现的处理策略，例如拒绝策略等。</p><ul><li><code>AbortPolicy</code>：拒绝任务，会抛出异常，是线程池默认的策略</li><li><code>CallerRunsPolicy</code>：拒绝新任务进入，如果该线程池还没有被关闭，那么新任务执行在调用线程中。</li><li><code>DiscardOldestPolicy</code>：如果执行程序尚未关闭，那么工作队列头部的任务将被删除，然后重试执行程序（如果失败，继续反复重试）。这样的结果会导致最后加入的任务反而可能被执行到，而先前加入的任务都被抛弃了。</li><li><code>DiscardPolicy</code>：加不进的任务都会被抛弃，不会抛出异常。</li></ul><h2 id="可缓存线程池cachedthreadpool">可缓存线程池——CachedThreadPool</h2><blockquote><p>任务线程传入时自动分配线程，线程不够时自动创建新的线程</p></blockquote><ul><li>线程数无限制</li><li>有空闲线程就复用空闲线程，若无空闲线程则新建线程，一定程度上减少频繁创建/销毁线程，减少系统开销</li></ul><h2 id="固定长度的线程池fixedthreadpool">固定长度的线程池——FixedThreadPool</h2><blockquote><p>指定线程池线程的个数，任务线程传入时自动分配线程，线程不够时，剩余的任务线程排队等待线程池中的线程执行完毕</p></blockquote><ul><li>可控制线程最大的并发数（即同时执行的线程数）</li><li>超出的线程会在队列中等待</li></ul><h2 id="定时执行一些任务scheduledthreadpoolexecutor">定时执行一些任务——ScheduledThreadPoolExecutor</h2><blockquote><p>指定线程池中线程的个数，任务线程传入时自动分配线程，可以设定任务线程第一次执行时的延时时间和之后每次执行的间隔时间。</p></blockquote><p>当需要定时地执行一些任务时，就可以通过<code>ScheduledThreadPoolExecutor</code>来实现，只需要通过<code>Executors</code>的<code>new ScheduledThreadPool</code>函数就可以创建定时执行任务的线程池。</p><ul><li>不要对那些同步等待其他任务结果的任务排队，否则可能导致死锁。在死锁中，所有线程都被一些任务所占用，而这些任务依次排队等待，又无法执行，这样所有的线程都属于忙碌状态。</li><li>理解任务————要有效地调整线程池的大小。</li><li>避免线程太少或者线程太多。</li></ul><h2 id="单线程化的线程池singlethreadexecutor">单线程化的线程池——SingleThreadExecutor</h2><ul><li>有且仅有一个工作线程在执行任务</li><li>所有任务按照指定的顺序执行，即遵循队列的先入队出队的原则</li></ul><h2 id="有效的方法blockingqueue">有效的方法——BlockingQueue</h2><p>阻塞队列提供了一系列有用的特性。例如，当队列满了时再调用<code>put</code>函数添加元素时，调用线程将被堵塞，直到队列不再是填满状态为止。</p><p>BlockingQueue 中重要的方法有：</p><ul><li><code>add(e)</code></li><li><code>offer(e)</code></li><li><code>offer(e,time,unit)</code></li><li><code>put(e)</code></li><li><code>take()</code></li><li><code>poll(time,unit)</code></li><li><code>element()</code></li><li><code>peek()</code></li><li><code>remove()</code></li></ul><p>BlockingQueue 主要有三种：</p><ul><li>基于数组的先进先出队列，有界：ArrayBlockingQueue</li><li>基于链表的先进先出队列，无界：LinkedBlockingQueue</li><li>无缓冲的等待队列，无界：SynchronousQueue</li></ul><h3 id="arrayblockingqueue">ArrayBlockingQueue</h3><p>之前已经介绍了，ArrayBlockingQueue 是一个基于<strong>数组</strong>结构实现的有界环形队列，按照 FIFO 原则对任务进行排序。如果队列满了还有任务进来，就调用拒绝策略。其原理就是利用了 Lock 锁的 Condition 通知机制进行阻塞控制。</p><p>那么，它主要使用<code>ReentrantLock</code>类中有一个<code>Condition</code>，它用于实现线程间的通信，是为了解决<code>Object.wait()</code>、<code>notify()</code>、<code>notifyAll()</code>难以使用的问题。</p><ul><li><code>await()</code>：线程等待的方法</li><li><code>await(int time, TimeUnit unit)</code>：线程等待特定的时间，超过时间则为超时</li><li><code>signal()</code>：随机唤醒某个等待线程</li><li><code>signalAll()</code>：唤醒所有等待中的线程</li></ul><p>当 MyArrayBlockingQueue 的元素为最大容量时，如果再往该队列中添加元素，就会调用<code>notFull.await()</code>函数使得线程阻塞，直到其它线程调用了<code>take()</code>方法从该队列中取出了元素，才不是已满状态。可以使用<code>notFull.signalAll()</code>方法唤醒所有的等待线程，使得添加元素的操作得以进行。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyArrayBlockingQueue</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 数据数组</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> T[] items;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 锁</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Lock lock = <span class="keyword">new</span> ReentrantLock();</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 队满的条件</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> Condition notFull = lock.newCondition();</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 队空的条件</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> Condition notEmpty = lock.newCondition();</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 队列的头部索引</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> head;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 队列的尾部索引</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> tail;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 数据的个数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> count;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        MyArrayBlockingQueue&lt;Integer&gt; aQueue = <span class="keyword">new</span> MyArrayBlockingQueue&lt;&gt;();</span><br><span class="line">        aQueue.put(<span class="number">3</span>);</span><br><span class="line">        aQueue.put(<span class="number">24</span>);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">5</span>; i++) &#123;</span><br><span class="line">            System.out.println(aQueue.take());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">MyArrayBlockingQueue</span><span class="params">(<span class="keyword">int</span> maxSize)</span> </span>&#123;</span><br><span class="line">        items = (T[]) <span class="keyword">new</span> Object[maxSize];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">MyArrayBlockingQueue</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>(<span class="number">10</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">put</span><span class="params">(T t)</span> </span>&#123;</span><br><span class="line">        lock.lock();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">while</span> (count == getCapacity()) &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;数据已满，等待&quot;</span>);</span><br><span class="line">                notFull.await();</span><br><span class="line">            &#125;</span><br><span class="line">            items[tail] = t;</span><br><span class="line">            <span class="keyword">if</span> (++tail == getCapacity()) &#123;</span><br><span class="line">                tail = <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            ++count;</span><br><span class="line">            <span class="comment">// 唤醒等待数据的线程</span></span><br><span class="line">            notEmpty.signalAll();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            lock.unlock();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> T <span class="title">take</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        lock.lock();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">while</span> (count == <span class="number">0</span>) &#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;还没有数据，请等待&quot;</span>);</span><br><span class="line">                notEmpty.await();</span><br><span class="line">            &#125;</span><br><span class="line">            T ret = items[head];</span><br><span class="line">            items[head] = <span class="keyword">null</span>;</span><br><span class="line">            <span class="keyword">if</span> (++head == getCapacity()) &#123;</span><br><span class="line">                head = <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            --count;</span><br><span class="line">            <span class="comment">// 唤醒添加数据的线程</span></span><br><span class="line">            notFull.signalAll();</span><br><span class="line">            <span class="keyword">return</span> ret;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            lock.unlock();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getCapacity</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> items.length;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">size</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        lock.lock();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> count;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            lock.unlock();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="put-方法">put 方法</h4><ol type="1"><li>拿到了线程竞争 lock 锁，拿到了 lock 锁的线程就进入下一步，没有拿到 lock 锁的线程就自旋竞争锁；</li><li>判断阻塞队列是否已满，如果满了就调用<code>await()</code>方法阻塞这个线程，notFull（生产者）挂起，最后释放 lock 锁，等待被消费者线程唤醒；</li><li>如果没有满，则调用<code>enqueue()</code>方法将元素 put 进阻塞队列；</li><li>唤醒一个标记为<code>notEmpty()</code>（消费者）的线程。</li></ol><h4 id="take-方法">take 方法</h4><ol type="1"><li>拿到了线程竞争 lock 锁，拿到了 lock 锁的线程就进入下一步，没有拿到 lock 锁的线程就自旋竞争锁；</li><li>判断阻塞队列是否为空，如果为空就调用<code>await()</code>方法阻塞这个线程，notEmpty（生产者）挂起，最后释放 lock 锁，等待被生产者线程唤醒；</li><li>如果没有空，则调用<code>dequeue()</code>方法将元素 take 出阻塞队列；</li><li>唤醒一个标记为<code>notFull()</code>（消费者）的线程。</li></ol><h3 id="linkedblockingqueue">LinkedBlockingQueue</h3><p>LinkedBlockingQueue 是基于链表的阻塞队列，其内部维持着一个数据缓冲队列（该队列由一个链表组成），当生产者往队列中放入一个数据时，队列会从生产者中获取数据，并缓存在队列内部，而生产者立即返回；只有当队列缓冲区达到最大值缓存容量时，才会阻塞生产者队列，直到消费者队列消费了数据，生产者才能继续工作。反之消费者端也是同样的。</p><p>LinkedBlockingQueue 之所以能够高效处理并发数据，是因为对生产者端和消费者端都分别采用了独立的锁来控制数据同步，所以在高并发的情况下，生产者和消费者可以并行地操作队列中的数据，以此提高整个队列的并发性能。</p><h3 id="delayqueue">DelayQueue</h3><p>DelayQueue 中的元素只有当自己指定的延迟时间到了，才可以从队列中获取到该元素。DelayQueue 是一个没有大小限制的队列，因此往队列中插入数据是不会被阻塞的，只有获取数据会被阻塞。</p><h3 id="priorityblockingqueue">PriorityBlockingQueue</h3><p>PriorityBlockingQueue 是基于优先级的阻塞队列（优先级的判断是通过构造函数传入的<code>Compator</code>对象来决定的）。PriorityBlockingQueue 不会阻塞生产者，只会当没有可消费的数据时，才会阻塞消费者。所以，<strong>生产者生产数据的速度绝对不能快于消费者数据的速度</strong>，否则时间长了后会耗尽所有的可用的堆内存空间（因为不会阻塞生产者）。</p><blockquote><p>实现 PriorityBlockingQueue 时，内部控制线程同步的锁采用的是公平锁。</p></blockquote><h3 id="synchronousqueue">SynchronousQueue</h3><p>SynchronousQueue 是一种无缓冲的等待队列，类似于无中介的直接交易，生产者直接与消费者交易，少了一个中间经销商的环节（缓冲区）。</p><p>声明一个 SynchronousQueue 有两种不同的方式：公平模式和非公平模式。</p><p><strong>公平模式</strong>：SynchronousQueue 会采用公平锁，并配合一个 FIFO 队列来阻塞多余的生产者和消费者，从而体系整体的公平策略。</p><p><strong>非公平模式</strong>：SynchronousQueue 会采用非公平锁，同时配合一个 LIFO 的队列来管理多余的生产者和消费者。</p><h2 id="四种拒绝策略">四种拒绝策略</h2><h3 id="abortpolicy">AbortPolicy</h3><blockquote><p>丢弃任务并抛出 RejectedExecutionException 异常</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">rejectedExecution</span><span class="params">(Runnable r, ThreadPoolExecutor e)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> RejectedExecutionException(<span class="string">&quot;Task&quot;</span> + r.toString()</span><br><span class="line">        + <span class="string">&quot; rejected from &quot;</span> + e.toString());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="discardpolicy">DiscardPolicy</h3><blockquote><p>丢弃任务，但是并不抛出异常</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">rejectedExecution</span><span class="params">(Runnable r, ThreadPoolExecutor e)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="discardoldsetpolicy">DisCardOldSetPolicy</h3><blockquote><p>丢弃队列最前面的任务，然后提交新来的任务</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">rejectedExecution</span><span class="params">(Runnable r, ThreadPoolExecutor e)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!e.isShutdown()) &#123;</span><br><span class="line">        e.getQueue().poll();</span><br><span class="line">        e.executor();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="callerrunpolicy">CallerRunPolicy</h3><blockquote><p>由调用线程（提交任务的线程，主线程）处理该任务</p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">rejectedExecution</span><span class="params">(Runnable r, ThreadPoolExecutor e)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!e.isShutdown()) &#123;</span><br><span class="line">        r.run();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Android </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 线程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Android Jetpack 组件</title>
      <link href="/2020/09/22/Android%20Jetpack%E7%BB%84%E4%BB%B6/"/>
      <url>/2020/09/22/Android%20Jetpack%E7%BB%84%E4%BB%B6/</url>
      
        <content type="html"><![CDATA[<h1 id="Jetpack"><a href="#Jetpack" class="headerlink" title="Jetpack"></a>Jetpack</h1><p>Jetpack 是 Google 推出的一个框架，主要是可以对代码的逻辑和 UI 界面实现深层的解耦，打造数据驱动型的 UI 界面。Android Architecture 组件是 Android Jetpack 的一部分，包含以下组件等：</p><ul><li><strong>Lifecycle</strong>：能够处理 Activity 和 Fragment 的生命周期，在 AndroidX 中，Fragment 和 Activity 已经对 Lifecycle 提供了默认的支持。</li><li><strong>ViewModel</strong>：当做 MVVM 的 ViewModel 层，并具有生命周期意识的处理和 UI 相关的数据。</li><li><strong>LiveData</strong>：和 RxJava 的作用是一样的，对数据进行监听，优点是无需处理生命周期、无内存泄漏等。</li><li><strong>Paging</strong>：是一个易于使用的数据分页库，支持 RecyclerView。</li><li><strong>Room</strong>：强大的 ORM 数据库框架。</li><li><strong>Navigation</strong>：一个用于管理 Fragment 切换的工具类，可视化、可绑定控件、支持动画等优点。</li><li><strong>WorkManager</strong>：灵活、简单、延迟和保证执行的后台任务处理库。</li><li><strong>StartUp</strong>：一个和启动有关的库。</li><li><strong>DataBinding</strong>：加速 MVVM 的创建。</li></ul><span id="more"></span><p>使用 Android Jetpack 组件具有以下优势：</p><ul><li>轻松管理应用程序的生命周期</li><li>构建可观察的数据对象，以便在基础数据库更改时通知视图</li><li>存储在应用程序轮换中未销毁的 UI 相关数据，在界面重建后恢复数据</li><li>轻松地实现 SQLite 数据库</li><li>系统自动调度后台任务的执行，优化使用性能</li><li>支持 RxJava：由于 RxJava 强大的生态环境，几乎和数据相关的组件都对 RxJava 提供了支持。</li><li>减少代码量：以 Data Binding + ViewModel + LiveData 或者 RxJava 构建的 MVVM 模式能够显著地减少代码量，比平时用的 MVP 模式也会更加方便，无需主动更新 UI。</li></ul><p><img data-src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F865d2955-9b17-4632-b308-8aee02af4f1b%2FUntitled.png?table=block&id=69603571-79da-4800-8939-caed7ae499f1&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=1410&userId=&cache=v2" alt="Android JetPack 组件"><span class="image-caption">Android JetPack 组件</span></p><p>上述组件的架构功能如下：</p><ul><li>Activity 和 Fragment 负责产品与用户的交互</li><li>ViewModel 作为数据的存储和驱动</li><li>Resposity 负责调度数据的获取</li><li>Room 储存本地序列化的数据</li><li>Retrofit 获取远程数据的数据</li></ul><h2 id="Navigation"><a href="#Navigation" class="headerlink" title="Navigation"></a>Navigation</h2><p>Navigation 是一个可以简化 Android 导航的库和插件。它可以用来管理 Fragment 的切换。</p><ul><li>处理 Fragment 的切换</li><li>默认情况下正确处理 Fragment 的前进和后退</li><li>为过渡动画提供标准化的资源</li><li>可以用来绑定 Toolbar、BottomNavigationView 以及 ActionBar 等</li><li>支持 ViewModel</li></ul><p>Navigation 有重要的三要素：</p><ul><li>Navigation Graph：这是一个新的资源文件，用户可以在可视化界面中看到具体的屏幕界面和跳转流程的关系</li><li>NavHostFragment：是当前 Fragment 的容器</li><li>NavController：导航的控制者</li></ul><h2 id="Data-Binding"><a href="#Data-Binding" class="headerlink" title="Data Binding"></a>Data Binding</h2><p>Data Binding 和 MVVM 其实是两个不同的概念，MVVM 是一种架构模式，而 Data Binding 是一个实现数据和 UI 绑定的框架，即 Data Binding 是构建 MVVM 模式的一个工具。</p><h2 id="Lifecycle"><a href="#Lifecycle" class="headerlink" title="Lifecycle"></a>Lifecycle</h2><p>Lifecycle 是一个生命周期的感知组件，执行操作以响应另一个组件（例如 Activity 和 Fragment）的生命周期状态的更改，可以监听 Activity 组件生命周期的变化，在每个生命周期执行相应的方法。</p><p>不同于以往会在生命周期中执行相应的方法时，需要设置接口，然后在生命周期中回调接口，这样会造成代码的耦合，也会引发生命周期的问题。Lifecycle 的<strong>优点</strong>是实现了执行的逻辑和活动的分离，代码解耦并且增加了代码的可读性。Lifecycle 在活动结束时会自定义移除监听。</p><h2 id="LiveData"><a href="#LiveData" class="headerlink" title="LiveData"></a>LiveData</h2><p>一个应用肯定要进行数据的更新。当用户执行某种操作或者服务器端的数据发生改变后，都需要重新获取数据，再次刷新界面的 UI。那么，每改变一次就需要重复一次，如何使用一个方式可以监听数据状态，在数据变化时就自动更新 UI 呢？LiveData 就是用来实现此功能的，它解决了数据展示和刷新的问题：只需要创建 LiveData 实例后，为可观察的数据添加观察者，在数据改变时会自动回调观察者。</p><h2 id="ViewModel"><a href="#ViewModel" class="headerlink" title="ViewModel"></a>ViewModel</h2><p>用户在使用应用的过程中，可能随时会被中断或者界面发生了重建，如果重新进入后数据丢失了就会造成不好的用户体验。我们可以使用<code>onSaveInstanceState()</code>方法来保存数据，然后在界面重建后使用<code>onRestoreInstanceState()</code>方法来恢复数据。这种方式虽然可以解决问题，但是如果过于频繁，在每个界面都要编写重建和恢复的代码，就会造成十分繁琐，且数据量过大时会影响执行性能。ViewModel 就是来解决这个问题的。</p><p>ViewModel 会在活动重建时仍然保存数据，在活动创建完成后从中获取数据。</p><p>ViewModel 的优点：</p><ul><li>数据和界面的分离，使数据驱动界面</li><li>解决了运行中断和界面重建时的数据保存问题</li><li>配合 LiveData 实时地获取最新的数据</li><li>实现了 Activity 和 Fragment 之间的数据交互</li></ul><p>ViewModel 的<strong>原理</strong>：将数据保存到 ViewModel 中，然后为活动中添加一个 HolderFragment，HolderFragment 中保存了 ViewStore 的实例，ViewStore 中使用 Map 保存了 ViewModel，从而在活动重新创建时获取到原来的 ViewModel。</p><hr><blockquote><p>一般 ViewModel 会和 LiveData 组合，保存可观察的数据</p></blockquote><p>在研究生毕业设计的项目中，我在安卓端的代码中就使用到了 LiveData 搭配 ViewModel 的组合。</p><p>在<code>ContractViewModel</code>类中的代码如下。这里主要是使用到了一个<code>MutableLiveData</code>的类。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ContractViewModel</span> <span class="keyword">extends</span> <span class="title">ViewModel</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> MutableLiveData contractModel = <span class="keyword">new</span> MutableLiveData();</span><br><span class="line">    <span class="keyword">private</span> MutableLiveData callContractResult = <span class="keyword">new</span> MutableLiveData();</span><br><span class="line">    <span class="keyword">private</span> MutableLiveData proofPlace = <span class="keyword">new</span> MutableLiveData();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> MutableLiveData&lt;ContractModel&gt; <span class="title">getContractModel</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> contractModel;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> MutableLiveData&lt;Boolean&gt; <span class="title">getCallContractResult</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> callContractResult;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> MutableLiveData&lt;String&gt; <span class="title">getProofPlace</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> proofPlace;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后，在 Fragment 中这样使用：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> ContractViewModel mViewModel;</span><br><span class="line"></span><br><span class="line">mViewModel = ViewModelProviders.of(fragmentActivity).get(ContractViewModel.class);</span><br><span class="line"></span><br><span class="line">mViewModel = mViewModel.getContractModel().observe(<span class="keyword">this</span>, o -&gt; &#123;</span><br><span class="line">    CertificateModel certificateModel = (CertificateModel) o;</span><br><span class="line">    <span class="comment">// TODO</span></span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">mViewModel.getCallContractResult().postValue(XXX);</span><br><span class="line">mViewModel.getProofPlace().postValue(XXX);</span><br></pre></td></tr></table></figure><p>从上面可以看出，<code>mViewModel</code>可以通过<code>ViewModelProviders</code>与<code>fragmentActivity</code>，再与<code>ContractViewModel</code>绑定。<code>mViewModel.getContractModel().observe()</code>的方式。除此之外，可以使用<code>postValue()</code>的方式去传递值。</p><h2 id="Room"><a href="#Room" class="headerlink" title="Room"></a>Room</h2><p>在此之前，在 Android 通常是使用第三方的优秀 ORM 数据库框架，例如 GreenDao 等，但是现在，谷歌官方已经推出了 Room 这个强大的 SQLite 数据库框架。</p><ul><li>与 SQL 语句接近</li><li>支持 RxJava2，支持 LiveData</li></ul><h2 id="Paging"><a href="#Paging" class="headerlink" title="Paging"></a>Paging</h2><p>当使用到 RecyclerView 进行大量的数据展示时，列表通常需要进行分页的操作。Paging 就是 Jetpack 中的分页库。</p><p>而实际上，分页的解决方法有很多种，为什么我们需要使用 Paging 呢？</p><ul><li>支持 RxJava2、LiveData、Room 等</li><li>可以自定义分页策略</li><li>可以异步处理数据</li></ul><h2 id="WorkManager"><a href="#WorkManager" class="headerlink" title="WorkManager"></a>WorkManager</h2><p>WorkManger 是一个可兼容、灵活和简单的延迟后台任务。而Android 中处理后台任务的选择有很多种，比如 Service 等等，那么为什么选择使用 WorkManager 呢？</p><ul><li>可以指定约束条件，比如必须在有网络的条件下执行</li><li>可以定时执行或者单次执行</li><li>监听和管理任务状态</li><li>多个任务可以使用任务链的方式</li></ul><h2 id="StartUp"><a href="#StartUp" class="headerlink" title="StartUp"></a>StartUp</h2><p>StartUp 是一个和启动有关的库。在之前的开发中，许多第三方的库需要在 Application 中进行初始化，即进入 Activity 之前就要初始化完成。常用的初始化的方式有两种：</p><ol><li>自定义 Application，然后在<code>onCreate()</code>方法中进行初始化。</li><li>自定义 ContentProvider，在<code>onCreate()</code>方法中进行初始化。</li></ol><p>StartUp 库采用的是上面的第二种方式。</p>]]></content>
      
      
      <categories>
          
          <category> Android </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Jetpack </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java 中的 String 为什么是不可变的</title>
      <link href="/2020/09/22/Java%E4%B8%AD%E7%9A%84String%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF%E4%B8%8D%E5%8F%AF%E5%8F%98%E7%9A%84/"/>
      <url>/2020/09/22/Java%E4%B8%AD%E7%9A%84String%E4%B8%BA%E4%BB%80%E4%B9%88%E6%98%AF%E4%B8%8D%E5%8F%AF%E5%8F%98%E7%9A%84/</url>
      
        <content type="html"><![CDATA[<p>在 Java 中，String 类是不可变的，即 String 中的对象是不可变的。</p><span id="more"></span><h3 id="区别对象和对象的引用"><a href="#区别对象和对象的引用" class="headerlink" title="区别对象和对象的引用"></a>区别对象和对象的引用</h3><p>对于 Java 初学者， 对于 String 是不可变对象总是存有疑惑。例如如下代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">String s = <span class="string">&quot;ABCabc&quot;</span>;</span><br><span class="line">System.out.println(<span class="string">&quot;s = &quot;</span> + s);</span><br><span class="line"></span><br><span class="line">s = <span class="string">&quot;123456&quot;</span>;</span><br><span class="line">System.out.println(<span class="string">&quot;s = &quot;</span> + s);</span><br></pre></td></tr></table></figure><p>打印出的结果为：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">s = ABCabc</span><br><span class="line">s = <span class="number">123456</span></span><br></pre></td></tr></table></figure><p>首先创建一个 String 对象 s，然后让 s 的值为“ABCabc”， 然后又让 s 的值为“123456”。从打印结果可以看出，s 的值确实改变了，那么为什么说 String 对象是不可变的呢？其实这里存在一个误区：<strong>s 只是一个 String 对象的引用，并不是对象本身</strong>。对象在内存中是一块内存区，成员变量越多，这块内存区占的空间越大。引用只是一个 4 字节的数据，里面存放了它所指向的对象的地址，通过这个地址可以访问对象。</p><p>也就是说，s 只是一个引用，它指向了一个具体的对象，当<code>s=“123456”;</code>这句代码执行过之后，又创建了一个新的对象“123456”， 而引用 s 重新指向了这个新的对象，原来的对象“ABCabc”还在内存中存在，并没有改变。内存结构如下图所示：</p><p><img data-src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F5cdc9ca4-6687-464e-a795-ddf801bec2fb%2FUntitled.png?table=block&id=2c762025-a9e3-4d61-aceb-77549318bf59&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=870&userId=&cache=v2" alt="String 真实的内存结构"><span class="image-caption">String 真实的内存结构</span></p><h3 id="不可变类"><a href="#不可变类" class="headerlink" title="不可变类"></a>不可变类</h3><blockquote><p>如果一个对象，在它创建完成之后，不能再改变它的状态，那么这个对象就是不可变的。即不能改变对象内的成员变量，包括基本数据类型的值不能改变，引用类型的变量不能再指向其它的对象，引用类型指向的对象的状态也不能改变。</p></blockquote><p>《Effective Java》中第 15 条<strong>使可变性最小化</strong>中对<strong>不可变类</strong>的解释：</p><blockquote><p>不可变类只是其实例不能被修改的类。每个实例中包含的所有信息都必须在创建该实例的时候就提供，并且在对象的整个生命周期内固定不变。为了使类不可变，要遵循下面五条规则：</p><ol><li>不要提供任何会修改对象状态的方法。</li><li>保证类不会被扩展。一般的做法是让这个类称为<code>final</code>的，防止子类化，破坏该类的不可变行为。</li><li>使所有的域都是<code>final</code>的。</li><li>使所有的域都成为私有的。防止客户端获得访问被域引用的可变对象的权限，并防止客户端直接修改这些对象。</li><li>确保对于任何可变性组件的互斥访问。如果类具有指向可变对象的域，则必须确保该类的客户端无法获得指向这些对象的引用。</li></ol></blockquote><p>在 Java 平台类库中，包含许多不可变类，例如<code>String</code>, 基本类型的包装类，<code>BigInteger</code>, <code>BigDecimal</code>等等。综上所述，不可变类具有一些显著的通用特征：类本身是<code>final</code>修饰的；所有的域几乎都是私有<code>final</code>的；不会对外暴露可以修改对象属性的方法。通过查阅 String 的源码，可以清晰的看到这些特征。</p><h3 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h3><p>通过查看 Java 中 String 的源码，如下所示：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">String</span> <span class="keyword">implements</span> <span class="title">Serializable</span>, <span class="title">Comparable</span>&lt;<span class="title">String</span>&gt;, <span class="title">CharSequence</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Stable</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">byte</span>[] value;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>首先，String 类是通过<code>final</code>修饰的，满足了第二条的：类不能被拓展。</p><p>其次，在类中，最重要的一条<code>private final byte[] value;</code>中，我们可以看到 Java 是使用<strong>字节数组</strong>（Java9，之前的版本是采用字符 char 数组实现）来实现字符串的，并且使用了<code>final</code>修饰，这就是 String 为什么不可变的原因。</p><p>因为它使用了<code>private final</code>，导致正常情况下外界没有办法去修改它的值。这满足了第三条：使所有的域都是<code>final</code>的，和第四条：使所有的域都是私有的。然而仅仅这样也仍然不是万无一失的。</p><p>第一条原则是：不要提供任何会修改对象状态的方法。String 类在这点中做得很好。在 String 类中许多会对字符串进行操作的方法中，例如<code>replaceAll()</code>或者<code>substring()</code>等，其中的每一步实现都不会对<code>value</code>产生任何影响。即 String 类中并没有提供任何可以改变其值的方法，这比<code>final</code>更能确保其是不变的。</p><h3 id="好处"><a href="#好处" class="headerlink" title="好处"></a>好处</h3><p>《Effective Java》一书中总结了不可变类的特点：</p><ul><li>不可变类比较简单。</li><li>不可变对象本质上是线程安全的，它们不要求同步。不可变对象可以被自由地共享。</li><li>不仅可以共享不可变对象，甚至可以共享它们的内部信息。</li><li>不可变对象为其他对象提供了大量的构建。</li><li>不可变类真正唯一的缺点是，对于每个不同的值都需要一个单独的对象。</li></ul><h3 id="String-真的不可变吗"><a href="#String-真的不可变吗" class="headerlink" title="String 真的不可变吗"></a>String 真的不可变吗</h3><p>其实可以通过<strong>反射机制</strong>来破坏 String 的不可变性。可以反射出 String 对象中的 value 属性，进而改变通过获得的 value 引用改变数组的结构。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">testReflection</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 创建字符串&quot;Hello World&quot;， 并赋给引用 s</span></span><br><span class="line">    String s = <span class="string">&quot;Hello World&quot;</span>;</span><br><span class="line"></span><br><span class="line">    System.out.println(<span class="string">&quot;s = &quot;</span> + s);<span class="comment">// Hello World</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取 String 类中的 value 字段</span></span><br><span class="line">    Field valueFieldOfString = String.class.getDeclaredField(<span class="string">&quot;value&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 改变 value 属性的访问权限</span></span><br><span class="line">    valueFieldOfString.setAccessible(<span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取 s 对象上的 value 属性的值</span></span><br><span class="line">    <span class="keyword">char</span>[] value = (<span class="keyword">char</span>[]) valueFieldOfString.get(s);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 改变 value 所引用的数组中的第 5 个字符</span></span><br><span class="line">    value[<span class="number">5</span>] = <span class="string">&#x27;_&#x27;</span>;</span><br><span class="line"></span><br><span class="line">    System.out.println(<span class="string">&quot;s = &quot;</span> + s);  <span class="comment">// 变成 Hello_World</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> 面试 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Interview-Review(BlockChain)</title>
      <link href="/2020/06/07/Interview-Review(BlockChain)/"/>
      <url>/2020/06/07/Interview-Review(BlockChain)/</url>
      
        <content type="html"><![CDATA[<p>本篇主要是面试复习内容的区块链部分。</p><span id="more"></span><ol type="1"><li><p><strong>什么是区块链</strong></p><p>区块链是不间断的经济交易数字分类账本，可以进行编程，以记录不仅是金融交易，还可以记录几乎所有有价值的东西。它是<strong>一个不可变记录的分散式、分布式数据库</strong>，该数据库由计算机集群管理，但不属于任何单个实体。</p></li><li><p><strong>区块链是如何工作的</strong></p><p>区块链由不可变的数据记录（称为<strong>数据块</strong>）组成，这些数据使用<strong>密码学</strong>进行链接。密码学不过是在读取私人消息时对第三方进行加密和保护数据通信的过程。在区块链中，<strong>一旦记录了数据，就不会更改</strong>。区块链就像带有<strong>时间戳</strong>的数学公证人一样工作，以避免篡改信息。</p></li><li><p><strong>为什么区块链是一种值得信赖的方法</strong></p><ul><li>它具有开源特性，与其它业务应用程序相互兼容</li><li>透明度和安全性</li><li>提高效率和速度</li><li>无需依赖任何中央权威</li></ul></li><li><p><strong>什么是区块链中的区块，如何识别</strong></p><p>区块链中的<strong>区块用于存储数据并永久锁定</strong>。添加在块上的数据是<strong>不可变的</strong>，即<strong>不能更改或删除数据</strong>。可以通过块的<strong>高度</strong>和<strong>块头哈希</strong>来识别块。块中的数据通过称为哈希函数的计算机算法进行检测。它不仅锁定了区块链参与者可以看到的数据，而且使数据不可变。<strong>每个块都有哈希函数</strong>。</p></li><li><p><strong>块的主要元素是什么</strong></p><p>以下是块的主要元素：</p><ul><li><strong>指向上一个块的哈希指针</strong></li><li><strong>时间戳</strong> Timestamp</li><li><strong>交易</strong> Transaction</li></ul></li><li><p><strong>是否可以从区块链的网络中删除一个或多个块</strong></p><p>可以的，因为有时只需要考虑在线分类账本的特定部分。通过使用默认过滤器和选项，可以删除这些块。</p></li><li><p><strong>将数据写入块后是否可以更改数据</strong></p><p>不可以。</p></li><li><p><strong>区块链数据库中可用的记录类型是什么</strong></p><p>区块链数据库中有两种类型的记录。他们是：</p><ul><li>交易记录</li><li>阻止记录</li></ul></li><li><p><strong>有哪些不同类型的区块链</strong></p><ul><li>公有区块链（公有链）：没有人负责，任何人都可以读写/审核区块链。</li><li>私有区块链（私有链）：它是个人或者组织的私有财产。</li><li>联合区块链（联盟链）：选定的成员可以读取/写入/审核区块链。</li></ul></li><li><p><strong>什么是分类账本，并命名区块链中用户考虑的常见分类账类型</strong></p><p>分类账是一个不断增长的文件，它存储了在区块链网络上两方之间的所有交易的永久记录。</p><p>用户考虑的常见分类帐类型：</p><ul><li><strong>集中式分类账</strong></li><li><strong>分散的分类帐</strong></li><li><strong>分布式分类账</strong></li></ul></li><li><p><strong>公钥和私钥有什么区别</strong></p><p>在区块链中，需要使用<strong>公钥进行标识</strong>，而使用<strong>私钥进行加密和身份验证</strong>。发送方可以使用接收方的公钥发送消息，而接收方可以使用私钥对消息或交易进行解密。通过同时使用两个密钥，可以确保通信或交易的安全和防篡改。</p></li><li><p><strong>区块链以什么顺序连接</strong></p><p>区块链中的所有区块都以反向顺序连接，或者每个区块都与其前一个区块连接。</p></li><li><p><strong>区块链分类账和普通分类账有何不同</strong></p><p>区块链是一种数字账本，可以很容易地分散，与原始账本相比，区块链账本中的错误机会要少得多。区块链自动执行其所有任务，而在普通分类账本中，每项任务都是手动或者人工完成的。</p></li><li><p><strong>什么是共识算法</strong></p><p>共识算法是一种方法，通过该方法，区块链网络的所有对等方都可以达成分布式账本当前状态的标准协议。它可实现高可靠性，并在分布式计算环境中的未知对等方之间建立信任。</p></li><li><p><strong>共识算法有哪些</strong></p><ul><li>工作量证明PoW</li><li>容量证明PoC</li><li>活动证明PoA</li><li>委托权益证明DPoS</li><li>股权证明PoS</li><li>权威证明</li><li>燃烧证明</li><li>唯一节点列表</li><li>重量证明</li><li>拜占庭容错PBFT</li></ul></li><li><p><strong>什么是加密货币</strong></p><p>加密货币是一种数字资产，可以用作使用加密功能进行金融交易的交换媒介。加密货币利用区块链技术获得透明度，去中心化和不变性。加密货币可以使用公钥和私钥在两方之间直接发送，而手续费极低。</p></li><li><p><strong>区块链架构的核心组件是什么</strong></p><ul><li><strong>节点</strong>：区块链结构中的用户/计算机</li><li><strong>交易</strong>：区块链系统的最小组成部分</li><li><strong>块</strong>：用于维护一组分配给网络中所有节点的事务</li><li><strong>链</strong>：块顺序</li><li><strong>矿工</strong>：在添加到区块链结构之前执行块验证过程的特定节点</li><li><strong>共识协议</strong>：进行区块链操作的规则集</li></ul></li><li><p><strong>区块链的一个区块永远不能有多个父区块吗</strong></p><p><strong>区块链永远不会有父区块</strong>，每个区块在区块链中都会独立的。</p></li><li><p><strong>什么是51%攻击</strong></p><p>51%攻击或者双花攻击是指区块链上的单个或者一组矿工，他们试图控制超过50%的网络挖掘哈希率或计算能力。这些攻击者试图阻止新交易获得确认，并使他们停止某些或所有用户之间的付款。它们还能够撤销在控制网络时完成的交易。这意味着他们可以双倍花费硬币。</p></li><li><p><strong>什么是RAS算法</strong></p><p>RSA算法也被称为非对称密码算法，它对两个不同的密钥（即公共密钥和私有密钥）起作用。公共密钥可以与任何人共享，并且私有密钥必须保密。公有密钥可以与任何人共享，而私有密钥必须保密。</p><p>该算法是用于签名数据和加密的第一个算法。它最广泛运用于保护敏感数据。</p></li><li><p><strong>RSA会受到攻击吗</strong></p><p>RAS可能会遭到攻击。通常，有两种攻击RSA的方法：</p><ul><li>蛮力：包括所有潜在的秘密密钥。</li><li>数学攻击：在这种情况下，需要使用不同的技术来近似地计算两个素数的乘积。</li></ul></li><li><p><strong>什么是双重支出</strong></p><p>双倍支出被认为是数字现金计划的潜在缺陷，因为多次使用相同的数字令牌。令牌通常由可以轻松克隆的数字文件组成。比特币用户通过在区块链上付款时等待确认来保护自己免受双重支出欺诈；随着确认的增加，交易变得不可逆转。</p></li><li><p><strong>什么是盲目签名</strong></p><p>盲目签名是密码术中数字签名的一种形式，其中消息的内容在签名或者考虑之前是不可见的。它主要用于作者和签名方不同的隐私相关协议中，这是一种经过验证的方法。</p></li><li><p><strong>区块链中有助于消除安全威胁的关键原则是什么</strong></p><ul><li>连续性计划</li><li>稽核</li><li>确保测试和类似方法</li><li>数据库安全</li><li>保护应用程序</li><li>数字化劳动力培训</li></ul></li><li><p><strong>权益证明和工作量证明有什么区别</strong></p><ul><li><strong>工作量证明</strong>是区块链中的原始共识算法。它用于确认交易并为链产生新的区块。矿工相互竞争以完成网络上的交易并获得奖励。</li><li><strong>股权证明</strong>使共识机制完全虚拟。在这种情况下，一组节点决定放样其交易验证的加密货币。</li></ul></li><li><p><strong>什么是默克尔树，它在区块链中的重要性是什么</strong></p><p>Merkle树也称为哈希树，主要由以太坊和比特币使用。区块链中的Merkle树的重要性在于，<strong>如果有人想验证某个区块中的特定交易，他们可以下载区块头链，而不必下载每个交易和每个区块</strong>。</p><p>默克尔树在区块链技术中起着重要作用。它描述了由各种数据块组成的数据结构。它还通过提供整个交易集的数字指纹来汇总一个块中的所有交易。它可以对大量数据进行有效且安全的内容验证。</p></li><li><p><strong>什么是秘密共享</strong></p><p>秘密共享是用于在区块链中提供数据安全性的主要方法之一。这种方法将个人信息或机密信息分为不同的单元，然后将其发送给网络上的用户。原始信息共享给分配了秘密共享的参与者。</p></li><li><p><strong>什么是安全策略</strong></p><p>安全策略是一个正式且简短的计划，其中包含组织的目标，目的和信息安全程序。简而言之，它定义了确切地需要保护免受威胁的条件以及在威胁发生时如何处理情况。</p></li><li><p><strong>为什么区块链需要硬币或者代币</strong></p><p>令牌/代币被视为是交换媒介。它们是内置的数字资产，可在区块链内执行特定的功能。某人进行交易时，状态会发生变化，coin会从一个地址转移到另外一个地址。</p></li><li><p><strong>什么是采矿</strong></p><p>挖掘是通过向网络提供工作证明来向大型分布式公共分类账添加交易的过程，即生成的区块是有效的。它还将新硬币添加到生成的块中。</p></li><li><p><strong>脱链交易和链上交易有什么不同</strong></p><p><strong>链上交易</strong>：这些交易在区块链上可用，并且对区块链网络上的所有节点都是可见的。包括由一定数量的参与者对交易进行身份验证和确认； <strong>链下交易</strong>：这些交易处理区块链外部的值，可以使用多种方法进行。</p></li><li><p><strong>集中式网络，分散式网络和分布式分类账之间有什么区别</strong></p><p><strong>集中式网络</strong>：具有中央机构以方便其操作； <strong>分散网络</strong>：分散网络中的连接节点不依赖于单个服务器点，并且每个节点都拥有网络配置的整个副本； <strong>分布式分类账</strong>：这是共享分类帐，不受任何中央机构的控制。本质是分散的，并充当金融、法律或电子资产的数据库。</p></li><li><p><strong>区块链生态系统的主要元素是什么</strong></p><ul><li><strong>共享账本</strong>：本质上是分散的，是区块链的核心组成部分；</li><li><strong>节点应用程序</strong>：一种软件，可以让计算机与区块链连接；</li><li><strong>虚拟应用程序</strong>：处理区块链承担的所有任务；</li><li><strong>共识算法</strong>：用于管理区块链规则，通过该规则每个节点都可以得出结论。</li></ul></li><li><p><strong>在保护交易记录时，如何进行风险管理</strong></p><p>基于数据的价值。</p><ul><li>第一种，确定与组织的财务记录相关的威胁和漏洞，并相应地采取正确的对策。</li><li>第二种，注意备份计划。</li><li>第三种，购买新的风险管理软件。</li></ul></li><li><p><strong>在组织中采用区块链技术是否有特定于网络的条件</strong></p><p>使用区块链没有特定的网络条件。但是，该网络必须是特定协议下的对等网络。</p></li><li><p><strong>区块链有哪些框架</strong></p><ul><li>Hyperledger Fabric：是区块链技术的一种实现，旨在作为开发区块链应用程序或解决方案的基础。</li><li>Hyperledger Iroha：是一个分布式分类帐项目，旨在简化并易于整合到需要分布式分类帐技术的基础设施项目中。</li><li>Chain：Chain Core 的基础设施使企业能够在许可网络上发布和转移金融资产，仅允许授权和识别的实体成为区块链网络的一部分。</li><li>IOTA：IOTA的分类帐非常适合需要小额支付和连接设备的场景。</li><li>以太坊：是一个运行智能合约的去中心化平台：完全按照设定程序运行的应用程序，不涉及任何停机、审查、欺诈或第三方干扰。</li><li>Libra：Facebook推出的区块链框架。</li></ul></li><li><p><strong>如何在保证所有人都可以访问的情况下防止篡改</strong></p><p>区块链主要是依靠加密技术来保障数据的安全，主要使用到了加密哈希函数。</p><p>哈希算法是无论输入的大小如何，输出始终是相同的字节。但如果输入发生变化，输出将完全不相同。只要输入不变，则不管运行多少次哈希函数，输出的哈希值都是始终相同的。</p><p>在区块链中，输出值（即哈希）是数据块的唯一标识符。每个区块的哈希是相对于前一个区块的哈希生成的。区块的哈希值是由其所包含的哈希函数决定的，任何数据的改变都会更改哈希值。所以，该区块的哈希值是由所包含的数据和前一区块的哈希值决定的。这就确保了区块链的安全性和不可篡改性。</p></li><li><p><strong>描述一下从交易发出到交易上链，以及如何实现共识</strong></p><p>区块“链”的链，包含“<strong>数据链</strong>”和“<strong>节点链</strong>”。“数据链”指用链式结构组织区块数据，构成数据校验和追溯的链条；“节点链”指多个节点通过网络连接在一起，互相共享信息，其中的共识节点则联合执行共识算法，产生并确认区块。</p><p><img data-src="https://i.loli.net/2021/01/07/2uz8cQTtSWNUqRx.png" /></p><p>交易“上链”的简要过程如下：</p><ol type="1"><li><p>记账者们收录交易，按链式数据结构打包成“区块”。</p></li><li><p>共识算法驱动大家验证新区块里的交易，确保计算出一致的结果。</p></li><li><p>数据被广播到所有节点，稳妥存储下来，每个节点都会存储一个完整的数据副本。</p></li></ol><p>交易一旦“上链”，则意味着得到完整执行，达成了“分布式事务性”，即永久可见且无法更改。</p><p>“上链”意味着“<strong>共识</strong>”和“<strong>存储</strong>”，两者缺一不可。交易不经过共识，则不能保证一致性和正确性，无法被链上所有参与者接受；共识后的数据不被多方存储，意味着数据有可能丢失或被单方篡改，更谈不上冗余可用。</p><p>除此之外，如果仅仅是调用接口查询一下，没有改变任何链上数据，也不需要进行共识确认，则不算“上链”。</p><hr /><p>区块链是通过共识算法来让不同的节点之间达成共识。例如PoW、PoS等。</p></li><li><p><strong>区块链有哪些应用场景</strong></p></li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> 面试 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Interview-Review(CloudComputing)</title>
      <link href="/2020/06/06/Interview-Review(CloudComputing)/"/>
      <url>/2020/06/06/Interview-Review(CloudComputing)/</url>
      
        <content type="html"><![CDATA[<p>本篇主要是面试复习内容的云计算部分。</p><span id="more"></span><h3 id="基本概念">基本概念</h3><ol type="1"><li><p>云计算中弹性与可拓展性的区别是什么 可拓展性通过增加资源容量的比例来处理不断增加的工作量。通过使用可拓展性，如果流量引发需求，则体系结构提供随需应变的资源。</p><p>弹性是一种特征，它提供动态调试和退役大量资源容量的概念。它通过资源的需求速度和资源的使用来衡量。</p></li><li><p>使用云计算的优点</p><ul><li>数据备份和数据存储</li><li>强大的服务器功能</li><li>提高生产力</li><li>非常划算且节省时间</li></ul></li><li><p>哪些平台可用于大规模云计算</p><ul><li>Apache Hadoop</li><li>MapReduce</li></ul></li><li><p>云计算部署的不同模型</p><ul><li>私有云</li><li>公共云</li><li>混合云</li><li>社区云</li></ul></li><li><p>云计算与移动计算有何区别 移动计算和云计算在概念上略有相同。移动计算使用云计算的概念。云计算为用户提供他们在移动计算中所需的数据，在远程服务器上运行的应用程序以及为用户提供存储和管理的访问权限。</p></li><li><p>用户如何得益于公益计算（Utility Computing） 公用计算让用户可以只需要为使用的资源付费。它是由决定从云端部署哪种类型的服务的企业组织管理的一种插件。</p></li><li><p>云在安全方面的措施有哪些</p><ul><li>身份管理：授权应用程序服务</li><li>访问控制：将权限授予用户，用户就可以控制进入到云环境的另一个用户的访问</li><li>验证和授权：只允许通过授权和验证的用户访问数据和应用程序</li></ul></li><li><p>虚拟化平台在实施云中的主要用途（有何要求）</p><ul><li>它用于管理服务级别策略</li><li>云操作系统</li><li>虚拟化平台有助于保持后端级别和用户级别概念彼此不同</li></ul></li><li><p>在使用云计算平台前，用户需要考虑哪些必要的方面</p><ul><li>合规</li><li>数据丢失</li><li>数据存储</li><li>业务连续性</li><li>正常运行时间</li><li>云计算的数据完整性</li></ul></li><li><p>开源的云计算平台数据库有哪些</p><ul><li>MongoDB</li><li>CouchDB</li></ul></li><li><p>解释软件即服务（SaaS）的不同模式</p><ul><li>简单的多租户模式：在该模式中，每个用户有独立的资源，与其它用户分开来，是一种高效的模式；</li><li>细粒度的多租户模式：在该模式中，资源由许多租户共享，功能仍然一样；</li></ul></li><li><p>API在云服务中有何用途 API用于云平台，它提供了一种替代方法，无需编写完全成熟的应用程序，它可以在一个或者多个应用程序之间进行通信。</p></li><li><p>为云计算部署了哪些不同的数据中心</p><ul><li>集装箱式数据中心</li><li>低密度数据中心</li></ul></li><li><p>云计算中有哪些不同的层</p><ul><li>SaaS：软件即服务，它让用户可以直接访问云应用程序，不必在系统上安装任何东西</li><li>IaaS：基础设施即服务，它从硬件等层面提供了基础设施</li><li>PaaS：平台即服务，它为开发人员提供了云应用程序平台</li></ul></li><li><p>云服务是什么 云服务用来通过互联网，使用网络中的服务器来构建应用程序，它提供了这种便利：不必将云应用程序安装到计算机上，即可直接使用。它还减少了维护和支持使用云服务开发的应用程序的工作。</p></li><li><p>云架构具有的好处</p><ul><li>无需基础设施投入</li><li>适时的基础设施</li><li>更高效地利用资源</li></ul></li><li><p>云架构有别于传统架构的特点</p><ul><li>按照需求，云架构满足硬件要求</li><li>云架构能够按需增减资源</li><li>云架构能够管理和处理动态工作负载，顺畅无阻</li></ul></li><li><p>在云架构中，必须的不同部分有哪些</p><ul><li>云入站</li><li>处理器速度</li><li>云存储服务</li><li>云提供商服务</li><li>云间通信</li></ul></li><li><p>在云架构中，经历的不同阶段有哪些</p><ul><li>启动阶段</li><li>监测阶段</li><li>关闭阶段</li><li>清理阶段</li></ul></li></ol><h3 id="kubernetes">Kubernetes</h3><ol type="1"><li>Kubernetes与Docker Swarm的区别如何</li><li>Kubernetes与Docker有什么关系</li><li>在主机和容器上部署应用程序有什么区别</li><li>什么是Container Orchestration</li><li>Container Orchestration需要什么</li><li>Kubernetes Architecture的不同组件有哪些</li><li>Kubernetes包含几个组件，各个组件的功能是什么，组件之间是如何交互的</li><li>k8s中的pod内几个容器之间的关系是什么</li><li>一个经典pod的完整生命周期</li><li>容器编排的价值和好处是什么</li><li>如何在 Kubernetes 中实现负载均衡</li></ol><h3 id="openstack">OpenStack</h3><ol type="1"><li>OpenStack及其主要组件</li><li>什么服务通常在控制节点上运行</li><li>什么服务通常在计算节点上运行</li><li>计算节点上虚拟机的默认地址是什么</li></ol><h3 id="opennebula">OpenNebula</h3><h3 id="serverless">Serverless</h3><h3 id="container">Container</h3><h3 id="docker">Docker</h3><h3 id="swarm">Swarm</h3>]]></content>
      
      
      
        <tags>
            
            <tag> 面试 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Interview-Review(Algorithm)</title>
      <link href="/2020/06/06/Interview-Review(Algorithm)/"/>
      <url>/2020/06/06/Interview-Review(Algorithm)/</url>
      
        <content type="html"><![CDATA[<p>本篇主要是面试复习内容的算法部分。</p><span id="more"></span><h2 id="深度学习">深度学习</h2><h3 id="模型评估方法">模型评估方法</h3><ol type="1"><li><p>Accuracy作为指标有哪些局限性</p><p>准确率的定义是：分类正确的样本占总样本个数的比例，<span class="math inline">\(Accuracy = \frac{n_{correct}}{n_{total}}\)</span>。但是此指标存在以下缺陷：</p><p>当正负样本非常不均衡时，占比大的类别就成为了影响准确率的主要因素，比如负样本占90%时，即使把所有样本都预测为负样本，也可以轻松获得90%的准确率，而这样的准确率是没有意义的，不足以说明分类器的好坏。</p></li><li><p>ROC曲线和PR曲线各是什么</p></li><li><p>编程实现AUC的计算，复杂度是多少</p></li><li><p>AUC指标有什么特点？放缩结果对AUC是否有影响</p></li><li><p>余弦距离与欧氏距离有什么特点</p></li></ol><h3 id="基本方法">基本方法</h3><ol type="1"><li><p>如何划分训练集？如何选择验证集？</p><p>有以下几种不同的方法划分训练集与验证集：</p><ul><li><p>留出法：</p><ol type="1"><li>把数据集划分成互不相交的两部分，一部分作为训练集，一部分作为测试集；</li><li>保持数据的分布大致一致，类似分层抽样；</li><li>训练集数据所占比例应该为2/3或4/5左右</li><li>为了保证随机性，将数据集多次随机划分为训练集和测试集，然后再对多次划分的结果去平均</li></ol></li><li><p>k折交叉验证法：</p><ol type="1"><li>将数据集随机分为互斥的k个子集，为保证随机性，使用p次随机划分取平均；</li><li>将k个子集随机分为k-1个组，剩下一个为另一组，有k种分法；</li><li>在每一种方法的分组结果中，那个k-1个子集的组都作为训练集，剩下的一个组作为测试集，这样就产生了k次预测，并对其取平均；</li><li>这种方法称为p次k折交叉验证，一般k取10</li></ol></li><li><p>自助法：</p><ol type="1"><li>当样本量足够时，使用自助法不如使用留出法和交叉验证法，因为无法满足数据分布一致。而如果样本量较小，无法划分，就可以使用自助法；</li><li>每次随机从数据集中抽取一个样本，然后再放回（可能会被重复抽出），m次之后会得到有m个样本的数据集，将其作为训练集；</li><li>始终没有抽到的样本的比例按概率算约是36.8%，这也保证了训练集占比大概在2/3左右</li></ol></li></ul></li><li><p>什么是偏差和方差？</p></li><li><p>什么是过拟合？在深度学习中，解决过拟合的方法有哪些？</p><p>过拟合（overfitting）是指在模型参数拟合过程中的问题。由于训练数据包含了抽样误差，而训练时，复杂的模型将抽样的误差也考虑在内。</p><p>过拟合具体的表现就是最终模型在<strong>训练集</strong>上效果很好，但<strong>测试集</strong>上效果很差。模型的泛化能力弱。</p><p>产生过拟合的原因有：</p><ul><li>样本方面的原因。样本数量太少或者抽出的样本数据不能有效地代表场景；</li><li>样本里的噪声数据干扰过大，使得模型过分地记住了噪声特征，反而忽略了真实的输入输出间的关系；</li><li>参数太多以及模型复杂度高；</li></ul><p>降低过拟合的方法有：</p><ul><li>正则化：可以使用L0正则化、L1正则化或L2正则化，机器学习中一般采用L2正则化；</li><li>dropout：可以随机地，以一定的概率让一部分神经元失活或者丢弃；</li><li>batch normalization：BN在训练某层时，会对每一个batch数据都进行标准化或者叫归一化（normalization）处理，使得输出的规范呈正态分布；</li><li>early stopping：当随着模型的能力提升，训练集的误差会先减小后增大，所以可以提前终止算法缓解过拟合的现象（例如决策树的预剪枝方法）；</li><li>重新清洗数据：有可能是因为数据不纯导致的，所以需要重新清洗数据；</li><li>Data expending：增大数据的训练量。过拟合有可能是因为训练集的数据量太小导致的，或者训练数据占总数据的比例太小导致的；</li></ul></li><li><p>深度模型参数调整的一般方法论</p></li></ol><h3 id="优化方法">优化方法</h3><ol type="1"><li><p>简述了解的优化器</p><ol type="1"><li><p>SGD(Stochastic Gradient Descent)</p><p><span class="math inline">\(\theta=\theta-\eta \cdot \nabla_{\theta} J\left(\theta ; x^{(i)} ; y^{(i)}\right)\)</span></p><p>SGD随机梯度下降参数的更新原则是<strong>一条数据都可以对参数进行一次更新</strong>。其它的优化器都是在这个优化器的基础上改善得来的。</p><p>优点：参数的更新速度快；</p><p>缺点：由于每次参数更新时采用的数据量小，造成梯度更新时的震荡幅度较大，但是大多数情况是向着梯度较小的方向；</p><p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(nb_epochs):</span><br><span class="line">    np.random.shuffle(data)</span><br><span class="line">    <span class="keyword">for</span> example <span class="keyword">in</span> data:</span><br><span class="line">        params_grad = eval_gradient(loss_function, example, params)</span><br><span class="line">        params = params - learning_rate * params_grad</span><br></pre></td></tr></table></figure></p><p><img data-src="https://s1.ax1x.com/2020/05/25/tpQUgK.png" /></p><p>从上图可以看出，SGD的噪音较多，不是每次迭代都向着整体最优化方向。所以虽然训练速度快，但是准确率下降，并不是<strong>全局最优</strong>。</p></li><li><p>BGD(Batch Gradient Descent)</p><p><span class="math inline">\(\theta=\theta-\eta \cdot \nabla_{\theta} J(\theta)\)</span></p><p>BGD批量梯度下降的参数更新原则是：<strong>所有数据</strong>都参与梯度的每一次更新。</p><p>优点：因为每次参数更新时采用的数据量都非常大，所以梯度更新时比较平滑；</p><p>缺点：由于参数更新时需要的数据量大，所以更新的速度非常慢；</p><p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(nb_epochs):</span><br><span class="line">    params_grad = eval_gradient(loss_function, example, params)</span><br><span class="line">    params = params - learning_rate * params_grad</span><br></pre></td></tr></table></figure></p></li><li><p>MBGD(Mini-Batch Gradient Descent)</p><p><span class="math inline">\(\theta=\theta-\eta \cdot \nabla_{\theta} J\left(\theta ; x^{(i: i+n)} ; y^{(i: i+n)}\right)\)</span></p><p>MBGD是每一次利用一小批样本，即<strong>n个样本</strong>进行计算，这样就可以<strong>降低参数更新时的方差，收敛更稳定</strong>。</p><p>优点：相比SGD，由于参与梯度更新的数据量大，所以梯度更新时较为平滑；相比BGD，参与梯度更新的数据量小，参数更新速度会更快一些。</p><p>缺点：</p><ol type="1"><li>如果数据是稀疏的，希望对出现频率低的特征进行更大的更，learning_rate会随着更新的次数逐渐变小；</li><li>不能保证很好的收敛性，learning_rate如果选择得太小，收敛速度会很慢，如果太大，loss_function就会在极小值处不停地震荡甚至偏离。</li></ol><p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(nb_epochs):</span><br><span class="line">    np.random.shuffle(data)</span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> get_batches(data, batch_size=n):</span><br><span class="line">        params_grad = eval_gradient(loss_function, batch, patams)</span><br><span class="line">        params = params - learning_rate * params_grad</span><br></pre></td></tr></table></figure></p><p>这里的<code>batch_size=n</code>的n一般取值在50~256之间。</p></li><li><p>Momentum</p><p><span class="math inline">\(v_{n+1}=\gamma v_{n}+\eta \theta J(\theta)\)</span></p><p><span class="math inline">\(\theta^{n+1}=\theta^{n}-v_{n+1}\)</span></p><p>Momenntum通过引入<span class="math inline">\(\gamma v_{n}\)</span>，加速SGD，并且抑制震荡。<span class="math inline">\(\gamma\)</span>一般取值为0.9左右，</p><p>优点：因为当我们将一个小球从山上滚下来时，没有阻力的话，它的动量就会越来越大，但是如果遇到了阻力，速度就会变小。所以加入了动量，**可以使得梯度方向不变的维度速度变快，梯度方向有所改变的维度上的更新速度变慢，这样就可以加快收敛并且减小震荡。</p><p>缺点：当梯度方向改变时，梯度更新速度不能及时减小导致适应性差。</p></li><li><p>Adagrad(Adaptive gradient algorithm)</p><p>Adagrad解决了不能根据参数重要性而对不同参数进行不同程度更新的问题。它的参数更新原则是：对低频的参数做较大的更新，对高频的参数做较小的更新。一般超参数<span class="math inline">\(\eta\)</span>取值0.01。</p><p><span class="math inline">\(\theta_{t+1, i}=\theta_{t, i}-\frac{\eta}{\sqrt{G_{t, i i}+\epsilon}} \cdot g_{t, i}\)</span></p><p>其中g是t时刻时参数<span class="math inline">\(\theta_i\)</span>的梯度。</p><p><span class="math inline">\(g_{t, i}=\nabla_{\theta} J\left(\theta_{i}\right)\)</span></p><p>优点：对于稀疏的数据它的表现很好，很好地提高了SGD的鲁棒性。</p><p>缺点：它的缺点是分母会不断的积累，这样学习率就会收缩最终会变得非常小。</p></li><li><p>Adadelta</p><p>Adadelta解决的就是Adagrad的缺点，即分母不断积累，导致学习率收缩变得非常小的问题。</p><p>Adadelta的参数更新原则就是和Adagrad相比，将分母的<span class="math inline">\(G_{t, i i}\)</span>换成了过去的梯度平方的衰减平均值，指数衰减平均值。</p><p><span class="math inline">\(\Delta \theta_{t}=-\frac{\eta}{\sqrt{E\left[g^{2}\right]_{t}}+\epsilon} g_{t}\)</span></p></li><li><p>RMSprop</p><p>同样是为了解决Adagrad的学习率急剧下降的问题。参数更新原则同样是使用指数加权平均。</p><p><span class="math inline">\(E\left[g^{2}\right]_{t}=0.9 E\left[g^{2}\right]_{t-1}+0.1 g_{t}^{2}\)</span></p><p><span class="math inline">\(\theta_{t+1}=\theta_{t}-\frac{\eta}{\sqrt{E\left[g_{t}^{2}\right]+\epsilon}} g_{t}\)</span></p><p>超参数<span class="math inline">\(\gamma\)</span>为0.9，学习率<span class="math inline">\(\eta\)</span>为0.001。</p></li><li><p>Adam(Adaptive Moment Estimation)</p><p>Adam相当于RMSprop+Momentum。</p></li></ol></li><li><p>常用的损失函数有哪些，分别适用于场景</p><p>损失函数是用来<strong>估量模型的预测值<span class="math inline">\(f(x)\)</span>与真实值Y的不一致程度</strong>。它是一个非负实值函数，通常使用<span class="math inline">\(L(Y, f(x))\)</span>来表示。<strong>损失函数越小，模型的鲁棒性就越好</strong>。</p><ul><li><p>LogLoss对数损失函数</p><p>可以适用于<strong>逻辑回归，交叉熵损失</strong>等。<span class="math inline">\(\log\)</span>损失函数的标准形式是：</p><p><span class="math inline">\(L(Y, P(Y | X))=-\log P(Y | X)\)</span></p><p>softmax使用的是<strong>交叉熵损失函数</strong>，binary_crossentropy使用的是<strong>二分类交叉熵损失函数</strong>，categorical_crossentropy使用的是<strong>多分类交叉熵损失函数</strong>。</p></li><li><p>平方损失函数</p><p>可以适用于<strong>最小二乘法</strong>等。平方损失函数的标准形式如下：</p><p><span class="math inline">\(L(Y, f(X))=(Y-f(X))^{2}\)</span></p><p>在实际应用中，通常使用均方差MSE作为一项衡量指标，公式如下：</p><p><span class="math inline">\(M S E=\frac{1}{n} \sum_{i=1}^{n}\left(\tilde{Y}_{i}-Y_{i}\right)^{2}\)</span></p></li><li><p>指数损失函数</p><p>可以使用于Adaboost算法。</p></li><li><p>Hinge损失函数</p><p>在机器学习算法中，hinge损失函数与SVM是息息相关的。其标准形式是：</p><p><span class="math inline">\(L(y)=\max (0,1-y \tilde{y}), y=\pm 1\)</span></p></li><li><p>其它损失函数</p><p>0-1损失函数：<span class="math inline">\(L(Y, f(X))=\left\{\begin{array}{ll}  1, &amp; Y \neq f(X) \\  0, &amp; y=f(X)  \end{array}\right.\)</span></p><p>绝对值损失函数：<span class="math inline">\(L(Y, f(X))=|Y-f(X)|\)</span></p></li><li><p>Keras/Tensorflow中常用的cost function：</p><ul><li>mean_squared_error或者MSE</li><li>mean_absolute_error或者MAE</li><li>mean_absolute_percentage_error或者MAPE</li><li>mean_squared_logarithmic_error或者MSLE</li><li>squared_hinge</li><li>hinge</li><li>categorical_hinge</li><li>binary_crossentropy</li><li>logcosh</li><li>categorical_crossentropy</li></ul></li></ul></li><li><p>梯度下降与牛顿法、拟牛顿法的异同</p></li><li><p>L1和L2正则分别有什么特点？为什么L1更稀疏</p></li><li><p>如何提高小型网络的精度</p></li></ol><h3 id="深度学习基础">深度学习基础</h3><ol type="1"><li>用一层隐藏层的神经网络，以ReLU作为激活函数，MSE作为损失函数推导反向传播</li><li>NN的权重参数能否初始化为0</li><li>什么是梯度消失和梯度爆炸，梯度爆炸的解决方法</li><li>常用的激活函数和导数</li><li>ReLU的优点和局限性，改进方法是什么</li><li>sigmoid和tanh为什么会导致梯度消失</li><li>相比sigmoid激活函数，ReLU激活函数有什么优势</li><li>一个隐藏层需要多少个节点能实现包含n元输入的任意布尔函数</li><li>多个隐藏层实现包含n元输入的任意布尔函数，需要多少个节点和网络层</li><li>Dropout为什么能够防止过拟合</li><li>Dropout和BN在前向传播和反向传播阶段的区别</li><li>解释批量归一化的原理</li><li>什么是反卷积，有哪些用途</li></ol><h3 id="cnn">CNN</h3><ol type="1"><li>给定卷积核的尺寸，特征图大小的计算方法</li><li>网络容量的计算方法</li><li>共享参数有什么优点</li><li>常用的池化操作有哪些，有什么特点，池化层有什么作用</li><li>CNN如何用于文本分类</li><li>ResNet提出的背景和核心理论是什么</li><li>空洞卷积是什么？有什么应用场景，作用是什么</li></ol><h3 id="rnn">RNN</h3><ol type="1"><li>简述RNN，LSTM，GRU的区别和联系</li><li>画出LSTM的结构图，写出公式</li><li>RNN的梯度消失问题，如何解决</li><li>LSTM中是否可以用ReLU作为激活函数</li><li>LSTM各个门分别使用什么作为激活函数</li><li>简述seq2seq模型</li><li>seq2seq在解码的时候有哪些方法</li><li>注意力机制是什么</li></ol><h2 id="机器学习">机器学习</h2><h3 id="基础">基础</h3><ol type="1"><li><p>样本不均衡如何处理（如何解决不平衡数据集的分类问题）</p><p>样本不均衡是指不同类别样本的比例相差悬殊，就会对算法的学习过程造成重大的干扰。例如，有1000个样本，只有5个正样本，995个负样本，那么算法把所有的样本都预测为负样本，精度也能达到99.5%。虽然精度很高，但是没有任何意义。</p><p>解决方法有：</p><ul><li><p>欠采样，减少数量较多的那一类的样本的数量，使得正负样本的比例均衡。</p><p>欠采样又分为随机欠采样、EasyEnsemble和BalanceCascade以及基于KNN欠采样。</p><ul><li>随机欠采样是指随机从多数类样本中抽取一部分数据进行删除。缺点就是未考虑到样本的分布情况，而采样过程又具有很大的随机性，可能会误删多数类样本中的一些重要信息。</li><li>EasyEnsemble是通过从多数的那一类样本中<strong>有放回</strong>的随机抽取一部分样本生成多个子数据集，将每个子集与少数类数据联合起来进行训练生成多个模型，然后综合多个模型的结果进行判断。方法和随机森林的原理很相似。</li><li>BalanceCascade是通过一次随机欠采样产生训练集，训练一个分类器，对于那些分类正确的多数类的样本不放回，然后剩下的多数类样本再次进行欠采样产生第二个训练器，训练第二个分类器，同样进行操作，以此类推，直到满足某个停止条件。最终的模型也是多个分类器的组合。</li><li>基于KNN欠采样：有四种KNN欠采样的方法。<ul><li>NearMiss-1：选择到最近的三个少数类样本平均距离最小的那些多数类样本</li><li>NearMiss-2：选择到最远的三个少数类样本平均距离最小的那些多数类样本</li><li>NearMiss-3：为每个少数类样本选择给定数目的最近多数类样本，目的是保证每个少数类样本都被一些多数类样本包围</li><li>最远距离：选择到最近的三个少数类样本平均距离最大的那些多数类样本</li></ul></li></ul></li><li><p>过采样，增加数量较少的那一类的样本的数量，使得正负样本的比例均衡。</p><p>过采样又分为随机过采样、SMOTE算法和Borderline-SMOTE算法以及基于K-means过采样。</p><ul><li>随机过采样是指多次随机从少数类样本中有放回的抽取数据，采取数量大于原有的少数类样本的数量。其中的有一部分数据会出现重复，而重复数据的出现会增大方差造成模型的过拟合。</li><li>SMOTE的全称是Synthetic Minority Oversampling Technique，即合成少数类过采样技术。它是基于随机过采样算法的一种改机方案。SMOTE算法的基本思想是对少数类样本进行分析并根据少数类样本人工合成新样本添加到数据集中。</li><li>Borderline-SMOTE算法较SMOTE算法提升的地方是只为那些K近邻中有一半以上多数类样本的少数类样本生成新样本，因为这些样本容易被错分，而在这些少数类样本附近生存人工合成样本，有助于少数类样本的分类正确。而如果少数类样本周围全是多数类样本，这种情况下，这个样本会被认定为噪声样本。</li><li>基于K-means聚类过采样方法是首先分别对正负例进行K-means聚类，聚类之后，对其中较小的蔟进行上面的过采样方法扩充样本数量。然后再进行正负类样本的均衡扩充。</li></ul></li><li><p>不处理样本，样本分类阈值移动。</p></li></ul></li><li><p>什么是生成模型什么是判别模型</p></li><li><p>什么是鞍点问题</p></li><li><p>集成学习的分类？有什么代表性的模型和方法</p></li><li><p>常用的特征筛选方法有哪些</p></li><li><p>文本如何构造特征</p></li><li><p>类别变量如何构造特征</p></li><li><p>连续值变量如何构造特征</p></li><li><p>哪些模型需要对特征进行归一化</p></li><li><p>什么是组合特征？如何处理高维组合特征</p></li></ol><h3 id="处理分类问题常用算法">处理分类问题常用算法</h3><h4 id="逻辑回归">逻辑回归</h4><ol type="1"><li><p>逻辑回归怎么实现多分类</p><p>我们知道，普通的逻辑回归只能解决二分类问题。要想实现多分类，就要改进逻辑回归。</p><ol type="1"><li>第一种方式是One-Vs-All（或者叫One-Vs-Rest）。直接根据每个类别，都建立一个二分类器。带有这个类别的样本标记为1，带有其它样本的标记为0。如果有k个类别，那么最终就得到了k个针对不同标记的普通的逻辑分类器。</li><li>第二种方式是One-Vs-One。让不同类别的数据两两组合训练分类器。</li><li>第三种方式是修改逻辑回归的损失函数，让其适应多分类问题。即softmax回归。</li></ol></li><li><p>交叉熵公式</p></li><li><p>LR公式，LR的推导和损失函数</p></li><li><p>LR与SVM的区别和联系</p><p>相同点有：</p><ul><li>都是<strong>监督</strong>的分类算法</li><li>都会线性分类算法</li><li>都会判别模型</li></ul><p>不同点有：</p><ul><li>损失函数不同。LR的损失函数是cross entropy：，SVM的损失函数是最大化间隔距离：</li><li>SVM不能产生概率，LR可以产生概率</li><li>SVM依赖于数据的测度，而LR不受影响</li><li>SVM自带结构风险最小化，LR是经验风险最小化</li><li>SVM会用核函数而LR一般不用核函数的原因</li></ul></li><li><p>LR和线性回归的区别</p></li><li><p>为什么正则化可以防止过拟合（为什么L1和L2正则化可以降低过拟合）</p></li><li><p>L1正则和L2正则有什么区别</p></li><li><p>L1正则化不可导，怎么求解</p></li><li><p>逻辑回归为什么一般性能差</p></li><li><p>如何使用LR解决非线性问题</p></li></ol><h4 id="svm">SVM</h4><ol type="1"><li>SVM什么时候使用线性核，什么时候使用高斯核</li><li>SVM的作用和基本实现原理</li><li>SVM的硬间隔和软间隔表达式</li><li>SVM使用对偶计算的目的是什么，如何推导出来的，手写推导</li><li>SVM为什么要求解决对偶问题？为什么对偶问题与原问题等价</li><li>SVM的物理意义是什么</li><li>SVM的核函数的选择</li><li>SVM的核函数的作用</li><li>SVM的核函数的原理</li><li>SVM为什么采用间隔最大化（与感知机的区别）</li><li>为什么SVM对缺失数据敏感</li><li>SVM的优缺点</li><li>SVM如何调节惩罚因子C</li><li>如何处理SVM中样本不平衡的问题</li><li>SVM如何处理多分类问题</li><li>SVM对噪声敏感的原因</li><li>如何使用SMO最优化方法求解SVM模型</li><li>SMO算法优化的终止条件是什么</li><li>是否一定存在参数使得SVM的训练误差到0</li></ol><h4 id="随机森林">随机森林</h4><ol type="1"><li>随机森林与SVM的区别</li><li>随机森林不会发生过拟合的原因</li><li>随机森林与梯度提升树（GBDT）的区别</li><li>随机森林是怎么避免ID3算法信息增益的缺点的</li><li>为什么随机森林能降低方差</li></ol><h4 id="朴素贝叶斯">朴素贝叶斯</h4><ol type="1"><li>朴素贝叶斯的要求（前提假设）是？</li><li>朴素贝叶斯算法原理和工作流程</li><li>什么是先验概率和后验概率</li><li>什么是条件概率</li><li>朴素贝叶斯为什么“朴素”</li><li>朴素贝叶斯可以做多分类吗</li><li>什么是朴素贝叶斯中的零概率问题？如何解决</li><li>朴素贝叶斯中概率计算的下溢问题如何解决</li><li>朴素贝叶斯分类器对异常值敏感吗</li><li>朴素贝叶斯对缺失值敏感吗</li><li>朴素贝叶斯有哪几种常用的分类模型</li><li>朴素贝叶斯算法中使用拉普拉斯平滑，拉普拉斯因子的大小如何确定</li><li>为什么说是朴素贝叶斯是高偏差低方差的</li><li>朴素贝叶斯为什么是增量计算</li><li>高度相关的特征对朴素贝叶斯有什么影响</li><li>朴素贝叶斯有什么优缺点</li></ol><h4 id="决策树">决策树</h4><ol type="1"><li>ID3，C4.5和CART三种决策树的区别</li><li>简述决策树的原理</li><li>简述决策树的构建过程</li><li>决策树有哪些划分指标，其区别和联系</li><li>信息增益率有什么优缺点</li><li>如何对决策树进行剪枝操作，为什么要进行剪枝</li><li>树模型如何调参</li><li>树模型如何剪枝</li><li>预剪枝和后剪枝</li><li>简述一下分类树和回归树</li><li>决策树对缺失值如何处理</li><li>如果决策树属性用完了，但仍未对决策树完成划分该怎么办</li><li>如何避免决策树的过拟合</li><li>决策树需要进行归一化处理吗</li><li>与其它模型比较，决策树有哪些优点和缺点</li></ol><h3 id="处理回归问题常用算法">处理回归问题常用算法</h3><h4 id="线性回归">线性回归</h4><ol type="1"><li>简单介绍一下线性回归的原理（什么是线性回归）</li><li>线性回归的求解方法有哪些</li><li>线性回归为什么用均方差</li></ol><h4 id="普通最小二乘回归">普通最小二乘回归</h4><ol type="1"><li>最小二乘法的推导</li><li>最小二乘法和梯度下降法有哪些区别</li></ol><h4 id="逐步回归">逐步回归</h4><ol type="1"><li>简述逐步回归算法</li></ol><h4 id="多元自适应回归样条">多元自适应回归样条</h4><ol type="1"><li>简述多元自适应回归样条</li></ol><h3 id="处理聚类问题常用算法">处理聚类问题常用算法</h3><h4 id="k均值基于划分的聚类">K均值（基于划分的聚类）</h4><ol type="1"><li>简述一下K-means算法的原理和工作流程</li><li>K-means有什么缺点</li><li>K值如何确定</li><li>初始点选择方法</li><li>K-means不能处理哪种数据</li><li>K-means如何处理大数据（几十亿）</li><li>K-means与KNN有何不同</li></ol><h4 id="dbscan基于密度的聚类">DBSCAN（基于密度的聚类）</h4><ol type="1"><li>DBSCAN与传统的K-means的不同</li><li>DBSCAN的聚类法原理</li></ol><h4 id="lda">LDA</h4><h3 id="推荐系统常用算法">推荐系统常用算法</h3><h4 id="协同过滤算法">协同过滤算法</h4><ol type="1"><li>itemCF与userCF的区别和适用场景</li></ol><h4 id="fm">FM</h4><h3 id="模型融合和提升的常用算法">模型融合和提升的常用算法</h3><h4 id="bagging">Bagging</h4><h4 id="adaboost">Adaboost</h4><h4 id="gbdt">GBDT</h4><h4 id="gbrt">GBRT</h4><h4 id="stacking">Stacking</h4><h4 id="blending">Blending</h4><h4 id="xgboost">XGBoost</h4><h3 id="其它重要算法">其它重要算法</h3><h2 id="cv">CV</h2><h2 id="nlp">NLP</h2><ol type="1"><li>word2vec的原理</li><li>glove的原理</li><li>fasttext的原理</li><li>了解elmo和bert吗？简述与word embedding的联系与趋避</li></ol><h2 id="常用算法">常用算法</h2><h3 id="搜索回溯">搜索回溯</h3><ol type="1"><li>八皇后，全排列，组合</li><li>重复数字的排列，重复数字的组合</li><li>图的搜索</li><li>A star</li></ol><h3 id="概率题">概率题</h3><ol type="1"><li>用rand7构造rand10</li><li>轮盘赌</li></ol><h3 id="动态规划">动态规划</h3><ol type="1"><li>编辑距离</li><li>背包问题</li><li>LCS</li><li>备忘录方法</li></ol><h3 id="字符串">字符串</h3><ol type="1"><li>给定字符串是否符合正则表达式</li><li>给定字符串是否是数字</li><li>KMP</li><li>超大数相加</li></ol><h3 id="海量数据">海量数据</h3><ol type="1"><li>海量日志的出现最多的K个字符串</li><li>10亿个1-10的数字排序</li><li>trie树</li><li>布隆过滤器</li></ol><h2 id="基本概念">基本概念</h2><ol type="1"><li>算法的几个特征是什么</li><li>算法复杂性的定义，大O、θ、Ω、小o分别表示的含义</li><li>递归算法的定义、递归算法的两个要素</li><li>分治算法的思想</li><li>动态规划算法的两个要素是什么</li><li>贪心算法的思想，贪心算法的两个要素</li><li>回溯法的思想，回溯法中有哪两种典型的模型</li><li>分支限界法思想，有哪两种分支限界法</li></ol>]]></content>
      
      
      
        <tags>
            
            <tag> 面试 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Interview-Review(BigData)</title>
      <link href="/2020/06/06/Interview-Review(BigData)/"/>
      <url>/2020/06/06/Interview-Review(BigData)/</url>
      
        <content type="html"><![CDATA[<p>本篇主要是面试复习内容的大数据部分。</p><span id="more"></span><h3 id="hadoop">Hadoop</h3><ol type="1"><li><p>什么是Hadoop</p><blockquote><p>Hadoop是一个开源软件框架，用于存储大量数据，并发处理/查询在具有多个商用硬件节点的集群上的那些数据。</p></blockquote><p>HDFS（Hadoop Distributed File System，Hadoop分布式文件系统）：HDFS允许以一种分布式和冗余的方式存储大量数据。例如，1024MB可以拆分为16*128MB文件，并存储在Hadoop集群中的8个不同的节点上。每个分裂可以复制3次，以实现容错，以便如果1个节点故障的话，也有备份。</p><p>MapReduce：是一个计算框架（Google三剑客之一：GFS、BigTable、MapReduce）。它以分布式和并行的方式处理大量的数据。例如，当对所有年龄大于18的用户在上面的1024MB文件中查询时，会有8个Map函数并行运行，以在其128MB拆分文件中提取年龄大于18的用户，然后Reduce函数将运行以将所有单独的输出组合成单个最终结果。Map就是拆解，Reduce就是组装，本治就是分治法。</p></li><li><p>正常工作的Hadoop集群中都需要启动哪些进程，作用分别是什么</p><ul><li>NameNode：是HDFS的守护进程，负责记录文件是如何分割成数据块，以及这些数据块分别被存储到哪些数据节点上，它的主要功能是对内存以及IO进行集中管理；</li><li>Secondary NameNode：辅助后台程序，与NameNode进行通信，以便定期保存HDFS元数据的快照；</li><li>DataNode：负责把HDFS数据块读写到本地的文件系统；</li><li>JobTracker：负责分配task，并监控所有运行的task；</li><li>TaskTracker：负责执行具体的task，并与JobTracker进行交互；</li></ul></li><li><p>列举出流行的Hadoop调度器，并简要说明其工作方法</p><p>Hadoop调度器的基本作用就是根据节点资源使用情况和作业的要求，将任务调度到各个节点上执行；</p><p><strong>调度器需要考虑的因素有三种</strong>：</p><ul><li>作业优先级：作业优先级越高，能够获取到的资源也越多。Hadoop提供了5种作业优先级，分别是<code>VERY_HIGH</code>、<code>HIGH</code>、<code>NORMAL</code>、<code>LOW</code>、<code>VERY_LOW</code>、<code>VERY_LOW</code>，通过<code>mapreduce.job.priority</code>属性来设置。</li><li>作业提交时间：作业提交的时间越早，就越先执行；</li><li>作业所在队列的资源限制：调度器可以分为多个队列，不同的产品线放到不同的队列里运行。<strong>不同的队列会设置一个边缘限制</strong>，这样不同的队列就会有自己独立的资源，不会出现抢占和滥用资源的情况。</li></ul><p><strong>自带调度器有三种</strong>：</p><ul><li><p>先进先出调度器（FIFO）：</p><p>FIFO是Hadoop中默认的调度器，也是一种<strong>批处理调度器</strong>。它先按照作业的优先级高低，再按照到达时间的先后选择被执行的作业。</p></li><li><p>容量调度器（Capacity Scheduler）：</p><p>支持多个队列，每个队列可以配置一定的资源量，每个队列采用FIFO调度策略，<strong>为了防止同一个用户的作业独占队列中的资源，该调度器会对同一用户提交的作业所占资源量进行限定</strong>；</p></li><li><p>公平调度器（Fair Scheduler）：</p><p>支持多队列多用户，每个队列中的资源量可以配置，<strong>同一队列中的作业公平共享队列中的所有资源</strong>。</p></li></ul></li><li><p><strong>简要说一下Hadoop的MapReduce编程模型</strong></p><p>首先Map task会从本地文件系统读取数据，转换成key-value形式的键值对集合。使用的是Hadoop内置的数据类型，比如longwritable、text等。然后将键值对集合输入mapper进行业务处理过程，将其转换成需要的key-value再输出。</p><p>之后会进行一个partition的分区操作，默认使用的是hashpartitioner，可以通过重写hashpartitioner的getpartition方法来自定义分区的规则；</p><p>之后会对key进行sort排序，grouping分组操作将相同key的value合并分组输出；</p><p>之后进行combiner归约操作，即一个本地段的reduce预处理，以减小后面shuffle和reducer的工作量；</p><p>reduce task通过网络将各个数据收集进行reduce处理，最后将数据保存或者显示，结束整个job。</p></li><li><p>MapReduce的大致过程：</p><p>MapReduce大致可以分为<strong>input</strong>、<strong>split</strong>、<strong>map</strong>、<strong>shuffle</strong>、<strong>reduce</strong>、<strong>output</strong>六个步骤。</p><ul><li>输入input：输入数据，一般是HDFS上的文件或目录</li><li>拆分split：切割文件，例如将字符串分割成每个单词</li><li>映射map：将拆分的内容转换成key-value形式</li><li>派发shuffle：将key相同的放到一起value是一个序列，这步涉及到数据移动，会将key相同的数据移动到一台机器上</li><li>缩减recude：将同样key的value序列进行计算</li><li>输入output：输出结果</li></ul></li><li><p>为什么要用flume导入HDFS，HDFS的架构是怎么样的</p><p>flume是可以实时地导入数据到hdfs中，当hdfs上的文件达到一个指定大小的时候，就会形成一个文件，超过指定时间的话，也会形成一个文件。</p><p>文件是存储在DataNode上，NameNode记录着DataNode的元数据信息，而NameNode的元数据信息是存在内存中的。所以，当文件切片很小或者很多的时候，就会卡死。</p></li><li><p>MapReduce程序运行的时候会有什么比较常见的问题</p><p>比如键值对对任务分配不均匀造成的<strong>数据倾斜</strong>问题。解决的办法是在分区的时候，重新定义分区规则，对于value数据很多的key可以进行拆分、均匀打散等处理，或者是在map端的Combiner中进行数据预处理的操作。</p></li><li><p>Hadoop的性能调优</p><ol type="1"><li>从应用角度进行优化：<ol type="1"><li>避免不必要的reduce任务</li><li>为job添加一个Combiner</li><li>根据处理数据特征使用最适合和最简洁的Writable类型</li><li>重用Writable类型</li><li>使用StringBuffer而不是String</li></ol></li><li>对Hadoop参数进行调优：<ol type="1"><li>关闭不必要的linux服务</li><li>关闭ipv6</li><li>调整文件最大打开数</li><li>修改linux内核参数</li></ol></li><li>从系统实现角度进行调优：从Hadoop实现机制的角度，发现当前Hadoop设计和实现上的缺点，然后进行源码级的修改。</li></ol></li><li><p>HDFS的特点</p><ul><li>处理超大文件</li><li>高容错性，运行在廉价机器上</li><li>横向扩展</li><li>流式数据处理，而不是随机读写（流式数据读取指的是一个文件只能写一次，后面一直追加，所以每次读取只需要从头开始一直往后读即可）</li><li>不支持文件修改，只能追加写入</li><li>对大量的小文件性能不好</li></ul><ol type="1"><li>主从架构，有两种角色namenode和datanode。namenode负责管理存储元数据，处理客户端读写请求；datanode存储真正的数据，执行读写操作；</li><li>读流程：客户端访问namenode，验证权限，返回数据具体的datanode的地址，客户端访问datanode读取数据；</li><li>写流程：客户端访问namenode，验证权限并确定文件是否存在，然后先记录到editLog返回输出流对象，客户端最近的一个datanode写数据，每写一个数据块，其余的datanode自己同步</li></ol></li><li><p>YARN的工作原理，简述其工作方法</p><p>YARN全称yet another resource negotiator，即另一种资源调度器。</p><p><strong>ResourceManager</strong>：</p><p>ResourceManager有为所有应用程序仲裁资源的权限的功能，用来代替JobTracker，主要由schedule和ApplicationManager组成。</p><p>schedule通过container来分配资源，封装了磁盘、内存、CPU等资源。</p><p>ApplicationManager负责接收作业的提交，并申请第一个container来执行作业的ApplicationMaster，并提供失败时重启ApplicationManager的container，而作业的ApplicationMaster向schedule申请资源。</p><p><strong>NodeManager</strong>：</p><p>NodeManager是YARN在每台机器上的代理，负责启动并管理节点上的container，container执行具体的由ApplicationMaster划分的任务。</p><p><strong>整体流程</strong>：</p><ol type="1"><li>客户端向ResourceManager的ApplicationManager提交程序；</li><li>ResourceManager的ApplicationManager在NodeManager启动第一个container执行ApplicationManager</li><li>ApplicationManager拆分程序，划分成一个个的task，这些task可以在container上运行，然后向ResourceManager申请资源执行task，并向ResourceManager发送心跳；</li><li>申请到container后，ApplicationMaster会和NodeManager通信，并将task发送到对应的container执行，task会向ApplicationMaster发送心跳；</li><li>程序执行完成，ApplicationMaster会向ResourceManager注销并释放资源；</li></ol></li></ol><h3 id="spark">Spark</h3><ol type="1"><li><p>Spark有几种部署模式，每种模式的特点</p><ul><li>local模式（本地模式）：运行在一台机器上，常用于本地开发测试，本地模式还分为local单线程和local-cluster多线程；</li><li>standalone模式（集群模式）：典型的Master/Slave模式，起初Master是有单点故障的；</li><li>yarn模式（集群模式）：运行在yarn资源管理器框架之上，由yarn负责资源管理，Spark负责任务调度和计算；</li><li>mesos模式（集群模式）：运行在mesos资源管理器框架之上，由mesos负责资源管理，Spark负责任务调度和计算；</li></ul></li><li><p>Spark为什么比MapReduce快（Run workloads 100x faster）</p><ul><li>Spark是基于内存计算的，减少了低效的磁盘交互；而MapReduce是基于磁盘的迭代。<ul><li>MapReduce的设计：中间结果保存在文件中，提高了可靠性，减少了内存占用，但是牺牲了性能；</li><li>Spark的设计：数据在内存中进行交换，要更快一些，所以性能要比MapReduce好，但是内存的可靠性不如磁盘；</li></ul></li><li>高效的调度算法，基于DAG；</li><li>容错机制Linage；</li></ul></li><li><p>Spark有哪些组件</p><ul><li><code>master</code>：管理集群和节点，不参与计算</li><li><code>worker</code>：计算节点，进程本身不参与计算</li><li><code>driver</code>：运行程序的Main方法，创建spark context对象</li><li><code>spark context</code>：控制整个application的生命周期，包括dag sheduler和task scheduler等组件</li><li><code>client</code>：用户提交程序的入口</li></ul></li><li><p>Hadoop和Spark的shuffle相同和差异</p><ul><li>高层面：两者并没有太大的差别，都是将<code>mapper</code>的输出进行<code>partition</code>，不同的是<code>partition</code>是送到不同的<code>reducer</code>里。</li><li>低层面：Hadoop是<code>sort-based</code>，在进入<code>combine()</code>和<code>reduce()</code>之后，<strong>必须先排序</strong>；Spark默认是<code>hash-based</code>，通常使用HashMap来对shuffle来的数据进行汇总，<strong>不需要提前排序</strong>；</li><li>实现角度：Hadoop MapReduce需要将处理流程划分成明显的几个部分：<code>map</code>、<code>split</code>、<code>merge</code>、<code>shuffle</code>、<code>sort</code>、<code>recude</code>，而Spark没有这样功能明确的阶段；</li></ul></li><li><p>RDD宽依赖和窄依赖</p><ul><li>窄依赖：每一个parent RDD的Partition最多被子RDD的一个Partition使用（即<strong>一父一子</strong>）</li><li>宽依赖：多个子RDD的Partition会依赖同一个parent RDD的Partition（<strong>一父多子</strong>）</li></ul></li><li><p>cache和pesist的区别</p><p>cache和persist都是用于缓存RDD，避免重复计算，<code>.cache()==.persist(MEMORY_ONLY)</code></p></li><li><p>RDD有哪些缺陷</p><ul><li>不支持细粒度的写和更新操作：Spark写数据是粗粒度的，就是批量写入数据，但是读数据可以细粒度</li><li>不支持增量迭代计算（Flink）支持</li></ul></li><li><p>RDD有哪几种操作类型</p></li><li><p>Spark的工作机制</p></li><li><p>Spark的优化怎么做</p></li><li><p>Spark中数据的位置是被谁管理的</p></li><li><p>Spark的数据本地性有哪几种</p></li><li><p>Spark的常用算子区别</p></li><li><p>Transformation和action是什么，有什么区别，举出一些常用方法</p></li><li><p>Spark on Yarn模式有哪些优点</p></li><li><p>描述Yarn执行一个任务的过程</p></li></ol><h3 id="storm">Storm</h3><ol type="1"><li>Storm的工作原理是什么</li><li>流的模式是什么？默认是什么？</li><li>Storm Group分类</li><li>Storm的特点和特性是什么<ul><li>编程简单：开发人员只需要关注应用逻辑，而且跟Hadoop类似，Storm提供的编程语言也很简单</li><li>高性能，低延迟：可以应用于广告搜索引擎等要求实时响应的场景</li><li>分布式：可以轻松应对数据量大，单机搞不定的场景</li><li>可拓展：随着业务的发展，数据量和计算量越来越大，系统可水平扩展</li><li>容错：单个节点挂了是不影响应用的</li><li>消息不丢失：保证了消息处理</li></ul></li><li>Storm组件有哪些</li></ol><h3 id="kafka">Kafka</h3><blockquote><p>Kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者规模的网站中的所有动作流数据。</p></blockquote><ol type="1"><li><p>Kafka的设计是怎么样的</p><p><img data-src="https://i.loli.net/2021/01/07/n6oUKCm4tZrGTv3.png" alt="Kafka的设计结构" /><span class="image-caption">Kafka的设计结构</span></p><ol type="1"><li>Kafka是可以配合zookeeper集群进行工作的</li><li>Kafka集群中有若干个Broker，<strong>其中一个是leader，其它的是follower</strong></li><li>Consumer外面还包裹了一层Consumer Group</li></ol></li><li><p>数据传输的事物定义有哪三种</p></li><li><p>Kafka判断一个节点是否还活着的两个条件</p></li><li><p>Kafka与传统消息系统之间的三个关键区别</p></li><li><p>Kafka高消息文件存储设计的特点</p></li><li><p>Kafka有哪几个组件</p><ul><li>Broker：Kafka集群包含一个或者多个服务器，这种服务器被称为broker</li><li>Topic：每条发布到Kafka集群的消息都有一个类别，类别就被称为是topic（物理上topic是分开存储的）</li><li>Partition：是一个物理上的概念，每个Topic包含一个或者多个Partition</li><li>Producer：负责发布消息到Kafka broker上</li><li>Consumer：消息消费者，向Kafka broker读取消息的客户端</li><li>Consumer Group：每个Consumer都属于一个特性的Consumer Group</li></ul></li><li><p>Kafka的特性</p><ul><li>以时间复杂度为<span class="math inline">\(O(1)\)</span>的方式提供消息持久化能力，即使TB以上的数据也能保证常数的时间复杂度的访问性能</li><li>高吞吐率：即使在廉价的机器上也能支持高吞吐率的传输</li><li>支持Kafka Server间的消息分区以及分布式消费，同时保证每个Partition内的消息<strong>顺序传输</strong></li><li>Scale out：支持在线水平扩展</li></ul></li><li><p>Kafka的应用场景</p><ul><li>构建可在系统或者应用程序之间可靠获取数据的<strong>实时流</strong>数据管道</li><li>构建实时流应用程序，可以转换或者响应数据流</li></ul></li><li><p>Kafka四个核心api</p><ul><li>Producer：使用Producer API发布消息到1个或者多个topic中</li><li>Consumer：应用程序使用Consumer API订阅一个或者多个topic，并处理产生的消息</li><li>Streams：使用Streams API充当一个流处理器，从1个或多个topic消息输入流，产生一个输出流到1个或者多个topic，有效地<strong>将输入流转化为输出流</strong></li><li>Connector：允许构建或者运行可重复使用的生产者或者消费者，将topic连接到现有的应用程序或者数据系统</li></ul><p><img data-src="https://i.loli.net/2021/01/07/OltHomjCFWpG2Sk.png" alt="Kafka的四个核心API" /><span class="image-caption">Kafka的四个核心API</span></p></li><li><p>Kafka分区的概念</p><p>大多数消息系统，在同一个topic下的消息，都会存储在一个队列中。而分区的概念就是**把这个队列划分为若干个小的队列，每一个小的队列就是一个分区。</p><p>创建分区的好处就是可以让多个消费者同时消费，这样速度就大大提升。</p><p><img data-src="https://i.loli.net/2021/01/07/hvbTipcM2yne87j.png" alt="Kafka分区的概念" /><span class="image-caption">Kafka分区的概念</span></p><p>分区有以下几个特征：</p><ul><li>一个partition只能被同组的一个consumer对象消费</li><li>同一个组里的consumer可以消费多个partition</li><li>消费效率最高的情况是partition和consumer的数量相等，这样可以保证每个consumer都专职负责一个partition</li><li>consumer数量是不能大于partition的数量的，不然就会有consumer闲置</li><li>consumer group是一个订阅者的集群，其中的每个consumer负责自己消费的分区</li></ul><p><img data-src="https://i.loli.net/2021/01/07/N7KpFanochzJBM5.png" alt="Kafka分区的特征" /><span class="image-caption">Kafka分区的特征</span></p></li></ol><h3 id="zookeeper">ZooKeeper</h3><blockquote><p>ZooKeeper是一个经典的分布式数据一致性解决方案，致力于为分布式应用提供一个高性能、高可用，且具有严格顺序访问控制能力的分布式协调服务。 分布式应用程序可以基于ZooKeeper实现数据发布与订阅、负责均衡、命名服务、分布式协调与通知、集群管理、Leader选举、分布式锁、分布式队列等功能。</p></blockquote><ol type="1"><li><p>ZooKeeper都要哪些功能</p><ol type="1"><li><p>统一命名服务（naming）</p><p>分布式应用中，通常需要一套完整的命名规则，既能够产生唯一的命名便于记住，又不需要将名称关联到特定的资源上，类似数据库中产生的唯一的主键。</p></li><li><p>配置管理</p><p>配置信息可以交个Zookeeper来管理，将配置信息保存在Zookeeper中的某个目录节点中，然后将所有需要修改的应用监控配置信息的状态。一旦配置信息发生变化，每台应用就会收到Zookeeper的通知，获取新的配置信息应用到系统中。</p></li><li><p>集群管理</p><p>Zookeeper不仅能够帮助维护当前的集群中机器的服务状态，而且能够帮助选出一个Master来管理集群。</p></li><li><p>对列管理</p><ul><li>当一个队列的成员都聚齐时，这个队列才可用，否则就需要一直等待，这就是<strong>同步队列</strong>。</li><li>队列按照FIFO方式进行出队和入队操作，例如实现生产者和消费者模型。</li></ul></li></ol></li><li><p>ZooKeeper怎么保证主从节点的状态同步</p></li><li><p>ZooKeeper有几种部署模式</p><ul><li>单机部署：一台集群上运行；</li><li>集群部署：多台集群上运行；</li><li>伪集群部署：一台集群启动多个ZooKeeper实例运行</li></ul></li><li><p>ZooKeeper的通知机制</p></li><li><p>集群中有 3 台服务器，其中一个节点宕机，这个时候 Zookeeper 还可以使用吗</p></li><li><p>两阶段提交和三阶段提交的过程</p></li><li><p>ZooKeeper宕机如何处理</p></li><li><p>获得分布式锁的流程</p></li><li><p>ZooKeeper队列管理</p></li><li><p>ZooKeeper下Server的工作状态</p></li><li><p>ZooKeeper是如何保证事务的顺序一致性的</p></li><li><p>ZooKeeper负载均衡和nginx负载均衡区别</p></li></ol><h3 id="flink">Flink</h3><h3 id="flume">Flume</h3><h3 id="hive">Hive</h3><ol type="1"><li><p>Hive中存放的是什么</p><p>Hive中存放的是<strong>表</strong>，存的是和hdfs的映射关系，hive是逻辑上的数据仓库，实际操作的是HDFS上的文件，HQL是用sql语法编写的MapReduce程序。</p></li><li><p>Hive与关系型数据库的关系</p><p>没有任何关系，hive是数据仓库弥，不能和数据库一样进行实时的CRUD操作，是一次写入多次读取的操作。</p></li><li><p>Hive表关联查询，如何解决数据倾斜的问题</p><p><strong>倾斜原因</strong>：map输出数据，按照key的Hash值分配到reduce中。由于key分布不均匀、业务数据本身的特性、建表时考虑不周等等原因造成的reduce上的数据量差异过大。</p><ul><li>key分布不均匀</li><li>业务数据本身的特性</li><li>建表时考虑不周</li><li>某些SQL语句本身就会有数据倾斜</li></ul><p><strong>解决方案</strong>：</p><ul><li>参数调节：有数据倾斜的时候进行负载均衡</li><li>SQL语句调节：<ul><li>选择<code>join key</code>分布最均匀的表作为驱动表，做好裁剪、filter等操作，以达到两表做<code>join</code>的时候，数据量相对变小的效果</li><li>大表<code>join</code>小表：把空值的key变成一个字符串加上随机数，把倾斜的数据分到不同的reduce上</li><li><code>count distinct</code>大量相同的特殊值</li><li>大小表<code>join</code>：使用<code>map join</code>让小的维度表先进内存，在map端完成reduce。</li></ul></li></ul></li><li><p>Hive的HSQL转换为<code>MapReduce</code>的过程</p><ol type="1"><li><strong>SQL Parser</strong>：（<strong>将HQL转换成抽象语法树</strong>）定义SQL的语法规则，完成SQL语法，语法解析，将SQL转化为抽象语法树AST Tree</li><li><strong>Semantic Analyzer</strong>：（<strong>将抽象语法树转换成查询块</strong>）遍历AST Tree，抽象出查询的基本组成单元QueryBlock</li><li><strong>Logical Plan</strong>：（<strong>将查询块转换成逻辑查询计划</strong>）遍历QueryBlock，翻译为执行操作树OperatorTree</li><li><strong>Logical Plan Optimizer</strong>：（<strong>重写逻辑查询计划</strong>）逻辑层优化器进行OperatorTree变换，合并不必要的ReduceSinkOperator，减少shuffle数据量；</li><li><strong>Physical Plan</strong>：（<strong>将逻辑计划转成物理计划</strong>）遍历OperatorTree，也就是翻译为MapReduce任务；</li><li><strong>Logical Plan Optimizer</strong>：物理层优化器进行MapReduce任务的变换，生成最终的执行计划；</li></ol></li><li><p>Hive特点</p><p>Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供完整的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。优点是学习成本低，可以通过类SQL语句快速实现简单的MapReduce统计，无需专门开发MapReduce应用，但是<strong>不支持实时查询</strong>。</p></li><li><p>Hive内部表和外部表的区别</p><ul><li><strong>创建表时</strong>：创建内部表，会将数据移动到数据仓库指向的路径；若创建外部表，仅记录数据所在的路径，不对数据的位置做出任何改变；</li><li><strong>删除表时</strong>：内部表的元数据会和数据一起删除，外部表只是删除数据元数据，不删除数据。</li></ul></li><li><p>Hive底层与数据库的交互原理</p><p>由于Hive的元数据可能要面临不断地更新、修改和读取操作，所以它显然不适合使用Hadoop文件系统进行存储。所以，目前Hive是将元数据存储在RDBMS中，比如存储在MySQL中。元数据的信息包括：存在的表、表的列、权限和更多信息。</p></li></ol><h3 id="hbase">Hbase</h3><h3 id="pig">Pig</h3><h3 id="sqoop">Sqoop</h3><h3 id="kylin">Kylin</h3><h3 id="布隆过滤器">布隆过滤器</h3><p>布隆过滤器（Bloom Filter）是一个节省空间的概率数据结构，用来测试一个元素是否在一个集合里。它实际上是一个很长的<strong>二进制向量</strong>和<strong>一系列随机映射函数</strong>。相比于传统的List、Set、Map等数据结构，它更高效、占用空间更少，但是缺点是<strong>返回的结果是概率性的，不是确定的</strong>。</p><h3 id="原理">原理</h3><p><img data-src="https://i.loli.net/2021/01/07/S4tU26X9d7Evpbw.png" /></p><ol type="1"><li><p><strong>插入</strong></p><p>当一个元素要被加入到集合中时，需要通过K个Hash函数将这个元素映射成一个位数组中的K个点，把它们置为1</p></li><li><p><strong>查找</strong></p><p>当需要查找某个元素时，首先需要判断其是否存在，只要看这些点是不是都是1就可知道集合中是否含有它。如果这些点有任何一个0，都说明被查找的元素不存在；如果都是1，则被检的元素很可能存在。</p></li></ol><h3 id="运用场景">运用场景</h3><ul><li>解决了redis等其它缓存穿透的问题</li><li>判断是否存在该行或者列，以减少对磁盘的访问，提高数据库的访问性能</li><li>分布式数据库BigTable使用了布隆过滤器来查找不存在的行或者列，可以减少磁盘查找的IO次数</li></ul><h4 id="优缺点">优缺点</h4><p><strong>优点</strong>：</p><ul><li>节省存储空间</li><li>查找速度快</li></ul><p><strong>缺点</strong>：</p><ul><li>存在误判：因为可能hash之后得到的k个位置都是1，但是要查到的元素并没有在容器中</li><li>删除困难：一个放入的容器中的元素映射到bit数组的k个位置上都是1，所以删除的时候并不能简单地直接设置为0，因为这样会影响其它元素的判断</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 面试 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Weka 中实现 J48 决策树算法</title>
      <link href="/2020/02/04/Weka%E4%B8%AD%E5%AE%9E%E7%8E%B0J48%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95/"/>
      <url>/2020/02/04/Weka%E4%B8%AD%E5%AE%9E%E7%8E%B0J48%E5%86%B3%E7%AD%96%E6%A0%91%E7%AE%97%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h2 id="WEKA"><a href="#WEKA" class="headerlink" title="WEKA"></a>WEKA</h2><p>WEKA（Waikato Environment for Knowledge Analysis）诞生于 University of Waikato（新西兰），并在 1997 年首次以现代的格式实现。</p><span id="more"></span><p>为了将数据加载到 WEKA，我们必须将数据放入一个我们能够理解的格式。WEKA 建议加载的数据格式是 Attribute Relation File Format（ARFF）。其中含有三个重要的注解：</p><ul><li>@RELATION</li><li>@ATTRIBUTE</li><li>@DATA</li></ul><h2 id="J48-决策树算法"><a href="#J48-决策树算法" class="headerlink" title="J48 决策树算法"></a>J48 决策树算法</h2><p>J48 的全名是<code>weka.classifiers.trees.J48</code>。J48 算法是著名的 C4.5 算法的改进，Weka 对于这个算法赋予了默认的参数：-C 0.25 -M 2。该命令给出了分类器的默认参数配置，一般很少需要为提高性能而修改参数配置。前者是用于剪枝的置信因子，后者指定了每个叶结点最小的实例数。</p><p>通过运行 weather.nominal.arff 文件，在分类器面板的 Test options 部分选择 Use training set，然后点击 Start 按钮创建分类器并进行评估。</p><p>运行完成后，可以在右侧的 Classifier output 中查看结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">&#x3D;&#x3D;&#x3D; Run information &#x3D;&#x3D;&#x3D;</span><br><span class="line"></span><br><span class="line">Scheme:       weka.classifiers.trees.J48 -C 0.25 -M 2</span><br><span class="line">Relation:     weather.symbolic</span><br><span class="line">Instances:    14</span><br><span class="line">Attributes:   5</span><br><span class="line">              outlook</span><br><span class="line">              temperature</span><br><span class="line">              humidity</span><br><span class="line">              windy</span><br><span class="line">              play</span><br><span class="line">Test mode:    evaluate on training data</span><br><span class="line"></span><br><span class="line">&#x3D;&#x3D;&#x3D; Classifier model (full training set) &#x3D;&#x3D;&#x3D;</span><br><span class="line"></span><br><span class="line">J48 pruned tree</span><br><span class="line">------------------</span><br><span class="line"></span><br><span class="line">outlook &#x3D; sunny</span><br><span class="line">|   humidity &#x3D; high: no (3.0)</span><br><span class="line">|   humidity &#x3D; normal: yes (2.0)</span><br><span class="line">outlook &#x3D; overcast: yes (4.0)</span><br><span class="line">outlook &#x3D; rainy</span><br><span class="line">|   windy &#x3D; TRUE: no (2.0)</span><br><span class="line">|   windy &#x3D; FALSE: yes (3.0)</span><br><span class="line"></span><br><span class="line">Number of Leaves  : 5</span><br><span class="line"></span><br><span class="line">Size of the tree : 8</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Time taken to build model: 0.01 seconds</span><br><span class="line"></span><br><span class="line">&#x3D;&#x3D;&#x3D; Evaluation on training set &#x3D;&#x3D;&#x3D;</span><br><span class="line"></span><br><span class="line">Time taken to test model on training data: 0 seconds</span><br><span class="line"></span><br><span class="line">&#x3D;&#x3D;&#x3D; Summary &#x3D;&#x3D;&#x3D;</span><br><span class="line"></span><br><span class="line">Correctly Classified Instances          14              100      %</span><br><span class="line">Incorrectly Classified Instances         0                0      %</span><br><span class="line">Kappa statistic                          1     </span><br><span class="line">Mean absolute error                      0     </span><br><span class="line">Root mean squared error                  0     </span><br><span class="line">Relative absolute error                  0      %</span><br><span class="line">Root relative squared error              0      %</span><br><span class="line">Total Number of Instances               14     </span><br><span class="line"></span><br><span class="line">&#x3D;&#x3D;&#x3D; Detailed Accuracy By Class &#x3D;&#x3D;&#x3D;</span><br><span class="line"></span><br><span class="line">                 TP Rate  FP Rate  Precision  Recall   F-Measure  MCC      ROC Area  PRC Area  Class</span><br><span class="line">                 1.000    0.000    1.000      1.000    1.000      1.000    1.000     1.000     yes</span><br><span class="line">                 1.000    0.000    1.000      1.000    1.000      1.000    1.000     1.000     no</span><br><span class="line">Weighted Avg.    1.000    0.000    1.000      1.000    1.000      1.000    1.000     1.000     </span><br><span class="line"></span><br><span class="line">&#x3D;&#x3D;&#x3D; Confusion Matrix &#x3D;&#x3D;&#x3D;</span><br><span class="line"></span><br><span class="line"> a b   &lt;-- classified as</span><br><span class="line"> 9 0 | a &#x3D; yes</span><br><span class="line"> 0 5 | b &#x3D; no</span><br></pre></td></tr></table></figure><h3 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h3><h4 id="Instances"><a href="#Instances" class="headerlink" title="Instances"></a>Instances</h4><p>代表输入的数据量</p><h4 id="Attributes"><a href="#Attributes" class="headerlink" title="Attributes"></a>Attributes</h4><p>代表数据中有哪些数据分类，即属性</p><h4 id="Number-of-Leaves"><a href="#Number-of-Leaves" class="headerlink" title="Number of Leaves"></a>Number of Leaves</h4><p>叶子树</p><h4 id="Size-of-the-tree"><a href="#Size-of-the-tree" class="headerlink" title="Size of the tree"></a>Size of the tree</h4><p>决策树大小</p><h4 id="Kappa-statistic"><a href="#Kappa-statistic" class="headerlink" title="Kappa statistic"></a>Kappa statistic</h4><p>这个参数是把分类器与随机分类器作比较得出的一个对分类器的评价值。</p><h4 id="Mean-absolute-error和Root-mean-squared-error"><a href="#Mean-absolute-error和Root-mean-squared-error" class="headerlink" title="Mean absolute error和Root mean squared error"></a>Mean absolute error和Root mean squared error</h4><p>平均绝对误差，用来衡量分类器预测值和实际结果的差异，越小越好。</p><h4 id="Relative-absolute-error和Root-relative-squared-error"><a href="#Relative-absolute-error和Root-relative-squared-error" class="headerlink" title="Relative absolute error和Root relative squared error"></a>Relative absolute error和Root relative squared error</h4><p>有时候绝对误差不能体现误差的真实大小，而<strong>相对误差</strong>通过体现误差占真值的比重来反映误差大小的效果会更好。</p><h4 id="Confusion-Matrix"><a href="#Confusion-Matrix" class="headerlink" title="Confusion Matrix"></a>Confusion Matrix</h4><p>混淆矩阵。这个矩阵上对角线的数字越大，说明预测得越好。</p>]]></content>
      
      
      <categories>
          
          <category> 数据挖掘 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 开发工具 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CloudSim NetworkExample1</title>
      <link href="/2020/02/02/CloudSim-NetworkExample1/"/>
      <url>/2020/02/02/CloudSim-NetworkExample1/</url>
      
        <content type="html"><![CDATA[<p>CloudSim 中的 Network 包同样含有很多个 Example。在<code>NetworkExample1.java</code>文件中，与<code>Example1.java</code>的不同，主要在于模拟之前，需要初始化网络拓扑。即有以下代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// load the network topology file</span></span><br><span class="line"><span class="comment">// 直接运行有可能会运行失败，报错找不到 toplogy.brite 文件</span></span><br><span class="line"><span class="comment">// 方法一：buildNetworkTopology() 中的参数改为 topology.brite 的绝对路径</span></span><br><span class="line"><span class="comment">// 方法二：把 topology.brite 拷贝到项目的根目录下</span></span><br><span class="line">NetworkTopology.buildNetworkTopology(<span class="string">&quot;topology.brite&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// maps CloudSim entities to BRITE entities</span></span><br><span class="line"><span class="comment">// PowerDatacenter will correspond to BRITE node 0</span></span><br><span class="line"><span class="keyword">int</span> briteNode=<span class="number">0</span>;</span><br><span class="line">NetworkTopology.mapNode(datacenter0.getId(),briteNode);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Broker will correspond to BRITE node 3</span></span><br><span class="line">briteNode=<span class="number">3</span>;</span><br><span class="line">NetworkTopology.mapNode(broker.getId(),briteNode);</span><br></pre></td></tr></table></figure><p>那么，NetworkTopology 这个类的作用是什么呢？</p><p>它的实现主要是根据一个 brite 文件建立一个网络拓扑模型，topology.brite 文件如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Topology: ( 5 Nodes, 8 Edges ) </span><br><span class="line">Model (1 - RTWaxman): 5 5 5 1 2 0.15000000596046448 0.20000000298023224 1 1 </span><br><span class="line">10.0 1024.0 </span><br><span class="line"></span><br><span class="line">Nodes: ( 5 ) </span><br><span class="line">0 1 3 3 3 -1 RT_NODE </span><br><span class="line">1 0 3 3 3 -1 RT_NODE </span><br><span class="line">2 4 3 3 3 -1 RT_NODE </span><br><span class="line">3 3 1 3 3 -1 RT_NODE </span><br><span class="line">4 3 3 4 4 -1 RT_NODE </span><br><span class="line"></span><br><span class="line">Edges: ( 8 ) </span><br><span class="line">0 2 0 3.0 1.1 10.0 -1 -1 E_RT U </span><br><span class="line">1 2 1 4.0 2.1 10.0 -1 -1 E_RT U </span><br><span class="line">2 3 0 2.8284271247461903 3.9 10.0 -1 -1 E_RT U </span><br><span class="line">3 3 1 3.605551275463989 4.1 10.0 -1 -1 E_RT U </span><br><span class="line">4 4 3 2.0 5.0 10.0 -1 -1 E_RT U </span><br><span class="line">5 4 2 1.0 4.0 10.0 -1 -1 E_RT U </span><br><span class="line">6 0 4 2.0 3.0 10.0 -1 -1 E_RT U </span><br><span class="line">7 1 4 3.0 4.1 10.0 -1 -1 E_RT U </span><br></pre></td></tr></table></figure><p>程序运行后会寻找标记<code>Nodes</code>和<code>Edges</code>，<code>Nodes</code>是节点信息，其中第一列是节点序号，第二列是节点的横坐标，第三列是节点的纵坐标；<code>Edges</code>是边信息，第一列是边序号，第二列是始节点序号，第三列是终节点序号，第四列是边长度，第五列是边时延，第六列是边带宽。</p><p>这里有一个关键类<code>ToplogicalGraph</code>，描绘了图的拓扑的数据结构。这里面包含两个链表，分别用来存储节点<code>ToplogicalNode</code>和边<code>ToplogicalLink</code>。</p><p>在<code>ToplogicalGraph</code>中通过<code>readGraphFile</code>方法，将文件中的描述，转化为网络拓扑模型。接着用得到的网络拓扑，通过<code>generateMatrices()</code>和<code>createBwMatrix()</code>生成一个是实体间的时延矩阵和带宽矩阵。</p>]]></content>
      
      
      <categories>
          
          <category> 云计算 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CloudSim </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CloudSim Example1</title>
      <link href="/2020/02/01/CloudSim-Example1/"/>
      <url>/2020/02/01/CloudSim-Example1/</url>
      
        <content type="html"><![CDATA[<h2 id="介绍">介绍</h2><p>CloudSim 是一个云计算基础架构和服务的建模和仿真框架，由 Java 语言编写，提供给研究人员做仿真实验。</p><span id="more"></span><h2 id="主要特点">主要特点</h2><ul><li>支持大型云计算数据中心的建模和仿真</li><li>支持对虚拟服务器主机进行建模和仿真，并具有可自定义的策略，用于向虚拟机提供主机资源</li><li>支持对应用程序容器进行建模和仿真</li><li>支持能源感知计算资源的建模和仿真</li><li>支持对数据中心网络拓扑和消息传递应用程序进行建模和仿真</li><li>支持动态插入模拟元素，停止和继续模拟</li><li>支持用于将主机分配给虚拟机的用户定义策略以及用于将主机资源分配给虚拟机的资源</li></ul><!-- more --><h2 id="example1">Example1</h2><p>Inspect <strong>ClouldSimExample1.java</strong>. Study the code and try to get an overall feel for what it is doing (or supposed to do). You should focus on the following aspects:</p><ul><li>Virtual Machine creation</li><li>Virtual Machine description</li><li>Broker</li><li>Cloudlet</li><li>Data centre</li><li>Simulation parameter setting</li><li>Simulation output</li></ul><p><code>CloudSimExample1.java</code>主要创建了一个含有一个云主机的数据中心，并在其上运行一个云任务。以下是部分代码分析：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CloudSimExample1</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 云用户数量</span></span><br><span class="line">            <span class="keyword">int</span> num_user = <span class="number">1</span>;</span><br><span class="line">            <span class="comment">// 用当前日期和时间初始化字段的日历</span></span><br><span class="line">            Calendar calendar = Calendar.getInstance();</span><br><span class="line">            <span class="comment">// 事件追踪</span></span><br><span class="line">            <span class="keyword">boolean</span> trace_flag = <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 初始化 CloudSim 工具包</span></span><br><span class="line">            CloudSim.init(num_user, calendar, trace_flag);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 创建数据中心</span></span><br><span class="line">            Datacenter datacenter0 = createDatacenter(<span class="string">&quot;Datacenter 0&quot;</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 创建 Broker 代理</span></span><br><span class="line">            DatacenterBroker broker = createBroker();</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 创建一个虚拟机列表</span></span><br><span class="line">            vmlist = <span class="keyword">new</span> ArrayList&lt;Vm&gt;();</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 创建一个虚拟机</span></span><br><span class="line">            Vm vm = <span class="keyword">new</span> Vm(vmid, brokerId, mips, pesNumber, ram, bw, size, vmm, <span class="keyword">new</span> CloudletSchedulerTimeShared());</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 将虚拟机添加到虚拟机列表中</span></span><br><span class="line">            vmlist.add(vm);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 将虚拟机列表提交到数据中心代理</span></span><br><span class="line">            broker.submitVmList(vmlist);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 创建云任务列表</span></span><br><span class="line">            cloudletList = <span class="keyword">new</span> ArrayList&lt;Cloudlet&gt;();</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 创建云任务</span></span><br><span class="line">            Cloudlet cloudlet = <span class="keyword">new</span> Cloudlet(id, length, pesNumber, fileSize, outputSize, utilizationModel, utilizationModel, utilizationModel);</span><br><span class="line">truetruetruecloudlet.setUserId(brokerId);</span><br><span class="line">truetruetruecloudlet.setVmId(vmid);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 将云任务添加到列表中</span></span><br><span class="line">            cloudletList.add(cloudlet);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 将云任务列表提交到数据中心代理</span></span><br><span class="line">            broker.submitCloudletList(cloudletList);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 开始模拟</span></span><br><span class="line">            CloudSim.startSimulation();</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 结束模拟</span></span><br><span class="line">            CloudSim.stopSimulation();</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 输出结果</span></span><br><span class="line">            List&lt;Cloudlet&gt; newList = broker.getCloudletReceivedList();</span><br><span class="line">            printCloudletList(newList);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 创建数据中心</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> Datacenter <span class="title">createDatacenter</span><span class="params">(String name)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 创建列表用于储存机器，简称主机列表</span></span><br><span class="line">        List&lt;Host&gt; hostList = <span class="keyword">new</span> ArrayList&lt;Host&gt;();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建处理器，并添加到Pe列表中</span></span><br><span class="line">        peList.add(<span class="keyword">new</span> Pe(<span class="number">0</span>, <span class="keyword">new</span> PeProvisionerSimple(mips)));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建处理器，并将其添加到主机列表中</span></span><br><span class="line">        <span class="keyword">int</span> hostId = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> ram = <span class="number">2048</span>;</span><br><span class="line">        <span class="keyword">long</span> storage = <span class="number">1000000</span>;</span><br><span class="line">        <span class="keyword">int</span> bw = <span class="number">10000</span>;</span><br><span class="line"></span><br><span class="line">        hostList.add(<span class="keyword">new</span> Host(hostId, <span class="keyword">new</span> RamProvisionerSimple(ram), <span class="keyword">new</span> BwProvisionerSimple(bw), storage, peList, <span class="keyword">new</span> VmSchedulerTimeShared(peList)));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建数据中心特征，它表示了数据中心的静态属性：体系架构、操作系统、主机列表、分配策略、时间或空间共享、时区、价格</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建 Power 数据中心</span></span><br><span class="line">        Datacenter datacenter = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            datacenter = <span class="keyword">new</span> Datacenter(name, characteristics, <span class="keyword">new</span> VmAllocationPolicySimple(hostList), storageList, <span class="number">0</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> datacenter;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 创建代理，可以根据特定需求发展自己的代理协议来提交虚拟机和云任务</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> DatacenterBroker <span class="title">createBroker</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 打印</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">printCloudletList</span><span class="params">(List&lt;Cloudlet&gt; list)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 云计算 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CloudSim </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NP 完全性证明</title>
      <link href="/2019/12/24/NP%E5%AE%8C%E5%85%A8%E6%80%A7%E8%AF%81%E6%98%8E/"/>
      <url>/2019/12/24/NP%E5%AE%8C%E5%85%A8%E6%80%A7%E8%AF%81%E6%98%8E/</url>
      
        <content type="html"><![CDATA[<h2 id="NP-完全性的证明"><a href="#NP-完全性的证明" class="headerlink" title="NP 完全性的证明"></a>NP 完全性的证明</h2><p><strong>引理</strong>：如果语言 $L$ 是一种满足对任意 $L’\in NPC$ 都有 $L’\le_{p}L$ 的语言，则 $L$ 是 NP-hardness。此外，如果 $L\in NP$，则 $L\in NPC$。</p><span id="more"></span><p><strong>证明</strong>：</p><p>$\because L’\in NPC$</p><p>$\therefore$ 对于所有 $L’’\in NP$，都有 $L’’\le _{p}L’$</p><p>根据假设，$L’\le _{p}L$</p><p>$\therefore$ 根据传递性，$L’’\in _{p}L$</p><p>$\therefore$ $L$ 是 NP-hardness</p><p>那么，如果 $L\in NP$，且 $L$ 是 NP-hardness</p><p>$\therefore L\in NPC$</p><h3 id="证明某种语言-L-是-NP-完全问题的方法"><a href="#证明某种语言-L-是-NP-完全问题的方法" class="headerlink" title="证明某种语言 $L$ 是 NP 完全问题的方法"></a>证明某种语言 $L$ 是 NP 完全问题的方法</h3><ol><li>证明 $L\in NP$</li><li>选取一种已知的 NP 完全语言 $L’$</li><li>描述一种可计算函数 $f(x)$ 的算法，其中 $f$可将 $L’$ 中每一个实例 $x\in \left{0,1\right}^*$ 映射为 $L$ 中的实例 $f(x)$</li><li>证明函数 $f$ 满足 $x\in L’$ 当前仅当对于所有的 $x\in \left{0,1\right}^*$ 都有 $f(x)\in L$</li><li>证明计算函数 $f(x)$ 的算法具有多项式运行时间</li></ol><p>第 2 步 ~ 第 5 步是为了证明 $L$ 是 NP-hardness，然后结合第一步的 $L$ 是 NP 问题，就可以得出 $L\in NPC$。</p><h2 id="典型-NPC-问题"><a href="#典型-NPC-问题" class="headerlink" title="典型 NPC 问题"></a>典型 NPC 问题</h2><p><img data-src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F9c299e0d-6391-4f97-b49b-a483f14441d4%2FUntitled.png?table=block&id=16487c1a-777e-4ad6-8f47-5796971c5669&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=1440&userId=&cache=v2" alt="一些典型的 NPC 问题"><span class="image-caption">一些典型的 NPC 问题</span></p><ul><li><strong>SAT</strong>：布尔公式的可满足性问题</li><li><strong>3-CNF-SAT</strong>：3 合取范式的布尔公式的可满足性问题</li><li><strong>团问题 CLIQUE</strong>：寻找无向图中的最大团</li><li><strong>顶点覆盖问题 VERTEX COVER</strong>：在无向图中找出最小规模的顶点覆盖</li><li><strong>哈密顿回路问题 HAM-CYCLE</strong>：无向图中是否存在哈密顿回路，即通过每个顶点的简单回路</li><li><strong>旅行商问题 TSP</strong>：寻找通过无向图每个顶点一次的最小回路</li><li><strong>子集和问题 SUBSET-SUM</strong>：给定正整数集合和正整数 t，判断是否存在一个子集的元素和为 t</li></ul><h2 id="布尔组合电路"><a href="#布尔组合电路" class="headerlink" title="布尔组合电路"></a>布尔组合电路</h2><p>布尔组合电路由一个或多个布尔组合元素通过线路连接而成，布尔组合电路是不包括回路的。</p><p>一个布尔组合电路的<strong>真值赋值</strong>是指一组布尔输入值。如果一个单输出布尔组合电路具有可满足性赋值，则称该布尔组合电路是可满足的。</p><p>布尔值取自集合 $\left{0,1\right}$，0 代表 false，1 代表 true。</p><p>布尔组合元素称为逻辑门：$\begin{cases}与门\quad AND\或门\quad OR\非门\quad NOT\end{cases}$</p><p>For example：</p><ol><li>对此电路的输入赋值 $&lt;x_1=1, x_2=1, x_3=0&gt;$，使得电路的输出为 1，那么电路是可满足的。</li><li>如果对此电路输入的任何一种赋值都不能使得输出为 1，则电路不满足。</li></ol><h3 id="NP-完全性证明"><a href="#NP-完全性证明" class="headerlink" title="NP 完全性证明"></a>NP 完全性证明</h3><p>给定一个电路 C，通过检查输入的所有可能赋值来确定它是否来自可满足性电路。</p><p>那么，如果有 $k$ 个输入，就有检查 $2^k$ 种可能，因为$\begin{cases}1\0\end{cases}$</p><p>所以当电路 C 的规模为 $k$ 的多项式时，对每个电路的检查要花费 $\Omega(2^k)$ 的时间，呈多项式关系。</p><p>$\therefore$ 该问题是 NP 完全的</p><h2 id="布尔可满足性问题-SAT"><a href="#布尔可满足性问题-SAT" class="headerlink" title="布尔可满足性问题 SAT"></a>布尔可满足性问题 SAT</h2><p><strong>定理</strong>：布尔公式的可满足性问题是 NP 完全的。</p><p><strong>证明</strong>：</p><ol><li>证明 $SAT\in NP$，即证明对于输入公式 $\phi$，由它的一个可满足性赋值所组成的证书可以在多项式时间内得到验证</li><li>证明 $CIRCUIT-SAT\le _{p}SAT$ 从而得出 SAT 是 NP-hard</li><li>根据语言 $L\in NP$ 且 $L\in NP-hard$ 能推出 $L\in NPC$，得证</li></ol><h2 id="3-CNF-可满足性"><a href="#3-CNF-可满足性" class="headerlink" title="3-CNF 可满足性"></a>3-CNF 可满足性</h2><p>即布尔公式中的一个文字（literal）是指一个变量或非 “$\neg$”。</p><h3 id="合取范式"><a href="#合取范式" class="headerlink" title="合取范式"></a>合取范式</h3><p>如果一个布尔公式可以表示为所有子句的“与”，并且每个字句都是一个或多个文字的“或”，则称该布尔公式为合取范式。</p><p>如果每个字句恰好有三个不同的<strong>“文字”</strong>，则该布尔公式为 3 合取范式，即 3-CNF。</p><p>For example：</p><p><img data-src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F2b67041d-82e7-4592-9000-aa6f8dae8600%2FUntitled.png?table=block&id=6565d542-a1bd-4da3-b5e5-b940dc5ae943&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=1260&userId=&cache=v2" alt="合取范式"><span class="image-caption">合取范式</span></p><p><strong>定理</strong>：3 合取范式形式的布尔公式的可满足性是 NP 完全的。</p><p><strong>证明</strong>：要证明 $3-CNF-SAT\le NP$，仅需证明 $SAT\le _{p}3-CNF-SAT$。</p><h2 id="团问题-CLIQUE"><a href="#团问题-CLIQUE" class="headerlink" title="团问题 CLIQUE"></a>团问题 CLIQUE</h2><p>无向图 $G=(V,E)$ 的团 (clique) 是一个顶点子集 $V’\subseteq V$，其中每一对顶点之间都由 $E$ 中的一条边来连接。</p><p>一个团是 $G$ 中的一个完全子图，<strong>图的规模是指它所包含的顶点数</strong>。</p><p>团问题就是关于寻找图中规模最大的团的优化问题。</p><p>事实上，团问题的有效算法是不大可能存在的。因为要确定一个具有 $|V|$ 个顶点的无向图 $G=(V,E)$ 是否包含一个规模为 $k$ 的团，有一种朴素算法：</p><p>列出V的所有规模为 $k$ 的子集，对其中的每一个进行检查，看它是否是一个团。这个算法的运行时间是与 $k$ 有关。如果 $k$ 是常数，那么该算法的运行时间是多项式时间的。然而，在一般情况下，$k$ 可能接近于 $|V|/2$。这样的话，运行时间就是超多项式时间。所以，团问题的有效算法是不大可能存在的。</p><h3 id="形式语言定义"><a href="#形式语言定义" class="headerlink" title="形式语言定义"></a>形式语言定义</h3><p>$CLIQUE=\left{&lt;G,k&gt;:G是一个包含规模为k的团的图\right}$</p><p><strong>定理</strong>：$CLIQUE\subseteq NP-Complete$</p><p><strong>证明</strong>：首先，证明 $CLIQUE\in NP$。然后，证明 $CLIQUE\in NP-hard$</p><ol><li>对于一个给定的图 $G=(V,E)$，用图中顶点集 $V’\subseteq V$ 作为 $G$ 的一个证书。对于任意一对顶点 $\mu,\nu\in V’$，通过检查边 $(\mu,\nu)$ 是否属于 $E$，就可以在多项式时间内确定 $V’$ 是否是团。</li><li>通过证明 $3-CNF-SAT\le _{p}CLIQUE$ 来说明 $CLIQUE\in NP-hard$。</li></ol><h2 id="顶点覆盖问题-Vertex-Cover"><a href="#顶点覆盖问题-Vertex-Cover" class="headerlink" title="顶点覆盖问题 Vertex Cover"></a>顶点覆盖问题 Vertex Cover</h2><p>无向图 $G=(V,E)$ 的顶点覆盖是一个子集 $V’\subseteq V$，满足如果有 $(\mu,\nu)\in E$，则 $\mu\in V’$ 或 $\nu\in V’$（或两者同时成立）。</p><p>顶点覆盖的规模是指它所包含的顶点数。顶点覆盖问题就是在一个给定的图中，找出具有最小规模的顶点覆盖。</p><h3 id="形式语言定义-1"><a href="#形式语言定义-1" class="headerlink" title="形式语言定义"></a>形式语言定义</h3><p>$VERTEX-COVER=\left{&lt;G,k&gt;:图G有一个规模为k的顶点覆盖\right}$</p><p><strong>定理</strong>：$VC\subseteq NP-Complete$</p><p><strong>证明</strong>：首先，证明 $VC\in NP$。然后证明 $CLIQUE\le _{p}VC$ 从而得到 $VC\in NP-hard$</p><h2 id="哈密顿回路问题-HAM-CYCLE"><a href="#哈密顿回路问题-HAM-CYCLE" class="headerlink" title="哈密顿回路问题 HAM-CYCLE"></a>哈密顿回路问题 HAM-CYCLE</h2><p><strong>定理</strong>：哈密顿回路问题是 NP-Complete</p><p><strong>证明</strong>：首先，证明 $HAM-CYCLE\in NP$。然后通过证明 $VC\le _{p}HAM-CYCLE$ 从而得到 $HAM-CYCLE\in NP-hard$</p><h2 id="旅行商问题-TSP"><a href="#旅行商问题-TSP" class="headerlink" title="旅行商问题 TSP"></a>旅行商问题 TSP</h2><h3 id="形式语言定义-2"><a href="#形式语言定义-2" class="headerlink" title="形式语言定义"></a>形式语言定义</h3><p>$$TSP=\left{&lt;G,c,k&gt;:G=(V,E)是一个完全图，c是V*V\rightarrow Z上的一个函数，k\in Z，G中包含一个最大花费为k的旅行回路。\right}$$</p><p><strong>定理</strong>：旅行商问题是 NP-Complete</p><p><strong>证明</strong>：首先，证明 $TSP\in NP$。然后通过证明 $HAM-CYCLE\le _{p}TSP$ 从而得到 $TSP\in NP-hard$</p><h2 id="子集和问题-SUBSET-SUM-problem"><a href="#子集和问题-SUBSET-SUM-problem" class="headerlink" title="子集和问题 SUBSET-SUM problem"></a>子集和问题 SUBSET-SUM problem</h2><p>给定一个正整数有限集 $S$ 和一个整数目标 $t&gt;0$，问是否存在一个子集 $S’\subseteq S$，其元素和为 $t$。</p><h3 id="形式语言定义-3"><a href="#形式语言定义-3" class="headerlink" title="形式语言定义"></a>形式语言定义</h3><p>$SUBSET-SUM=\left{&lt;S,t&gt;:存在一个子集S’\subseteq S，使得t= \sum\limits_{S\in S’}S\right}$</p><p><strong>定理</strong>：子集和问题是 NP-Complete</p><p><strong>证明</strong>：首先，证明 $SUBSET-SUM\in NP$。然后，通过证明 $3-CNF-SAT\le _{p}SUBSET-SUM$ 从而得到 $SUBSET-SUM\in NP-hard$</p>]]></content>
      
      
      <categories>
          
          <category> 图论 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> NP 问题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>马尔可夫决策过程</title>
      <link href="/2019/12/20/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B/"/>
      <url>/2019/12/20/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="马尔可夫性"><a href="#马尔可夫性" class="headerlink" title="马尔可夫性"></a>马尔可夫性</h2><p>某一状态信息包含了相关的历史，只要当前状态可知，所有的历史信息都不再需要，当前状态就可以决定未来，则认为该状态具有马尔可夫性（Markov Property）。</p><span id="more"></span><p><img data-src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F85a2a0ef-1501-4f10-9cd6-8dc92dd3631b%2FUntitled.png?table=block&id=3df1ebe9-9a02-4257-8192-179619bcd7b1&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=1050&userId=&cache=v2" alt="马尔可夫性"><span class="image-caption">马尔可夫性</span></p><h2 id="马尔可夫过程"><a href="#马尔可夫过程" class="headerlink" title="马尔可夫过程"></a>马尔可夫过程</h2><p>又叫马尔可夫链（Markov Chain）。它是一个无记忆的随机过程，可以用一个元组 $&lt;S, P&gt;$ 表示，其中 $S$ 是有限数量的状态集，$P$ 是状态转移概率矩阵。</p><p><img data-src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F1d11c3d6-4818-4819-9d1b-c587d59140f4%2FUntitled.png?table=block&id=be3a0c8d-98a9-496b-ba8a-3b4cefd4e8c2&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=1410&userId=&cache=v2" alt="马尔可夫过程"><span class="image-caption">马尔可夫过程</span></p><h2 id="马尔可夫奖励过程"><a href="#马尔可夫奖励过程" class="headerlink" title="马尔可夫奖励过程"></a>马尔可夫奖励过程</h2><p>马尔可夫奖励过程（Markov Reward Process）在马尔可夫过程的基础上增加了奖励R和衰减系数V：$&lt;S, P, R, V&gt;$。$R$ 是一个奖励函数。$S$ 状态下的奖励是某一时刻 $(t)$ 处所在状态 $s$ 下在下一个时刻 $(t+1)$ 能获得的奖励期望：<br>$$<br>R_s = E[R_{t+1}|S_t=s]<br>$$<br>衰减系数（Discount Factor）：$\gamma\in[0, 1]$，避免无限循环。</p><h2 id="马尔可夫决策过程"><a href="#马尔可夫决策过程" class="headerlink" title="马尔可夫决策过程"></a>马尔可夫决策过程</h2><p>Markov Decision Process，MDP</p><p>多了一个行为集合 $A$，元组 $&lt;S, A, P, R, V&gt;$。<br>$$<br>P^a_{ss’} = P[S_{t+1}=s’|S_t=s, A_t=a]<br>$$<br>$$<br>R^a_s=E[R_{t+1}|S_t=s, A=a]<br>$$<br>当给定一个 MDP： $&lt;S, R, P,R, \gamma&gt;$ 和一个策略 $\pi$，那么状态序列 $S_1，S_2$，是一个马尔可夫过程 $&lt;S, P^\pi&gt;$。</p><p>下一个时刻的状态 $S_{t+1}$ 和<strong>当前时刻的状态 $S_t$ 以及动作 $a_t$ 有关</strong>。</p><h3 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h3><p>$$<br>初始化状态agent所处状态s_0<br>$$<br>$$<br>\Downarrow<br>$$<br>$$<br>根据policy\quad\pi(a|s)采取动作a_0，a_0\sim\pi(a|s_0)<br>$$<br>$$<br>\Downarrow<br>$$<br>$$<br>根据转移概率p(s’|s,a)采取新状态s_1，s_1\sim p(s’|s,a)<br>$$<br>$$<br>\Downarrow<br>$$<br>$$<br>得到单步奖励r_1=R^{a_0}<em>{s_0s_1}<br>$$<br>$$<br>\Downarrow<br>$$<br>$$<br>持续，得到终止状态S_T，得到轨迹\gamma=(s_0,a_0,s_1,a_1,\dots,s_T)<br>$$<br>$$<br>\Downarrow<br>$$<br>$$<br>轨迹的联合概率：<br>$$<br>$$<br>p(r)=p(S_0)·\prod^\pi</em>{t=1}p(a_{t-1}|S_{t-1})·p(S_t|S_{t-1},a_{t-1})<br>$$<br>$$<br>\Downarrow<br>$$<br>$$<br>对于每一条轨迹，累计奖励函数是关于单步奖励的函数<br>$$<br>$$<br>R=f(r_0,r_1\dots r_{T-1})<br>$$<br>$$<br>\downarrow<br>$$<br>$$<br>可以是T步累计奖励函数R=\sum^{T-1}<em>{t=0}r_t，<br>$$<br>$$<br>也可以是\gamma折扣奖励函数，R=\sum^{T-1}</em>{t=0}\gamma^t·r_t<br>$$<br>$$<br>\Downarrow<br>$$<br>$$<br>期望累计奖励是E_R=E_p(r)[\sum^{T-1}<em>{t=0}\gamma^t·r_t^T]<br>$$<br>$$<br>\therefore agent的目标策略就是使得期望累计奖励最大的策略<br>$$<br>$$<br>\pi=\max\limits</em>{\pi}E_{p(r)}^\pi[\sum^{T-1}_{t=0}\gamma^t·r_t]<br>$$</p><h3 id="状态-state"><a href="#状态-state" class="headerlink" title="状态 state"></a>状态 state</h3><p>agent 在每个步骤中所处于的状态集合。</p><h3 id="行为-action"><a href="#行为-action" class="headerlink" title="行为 action"></a>行为 action</h3><p>agent 在每个步骤中所能执行的动作集合。</p><h3 id="转移概率-transition"><a href="#转移概率-transition" class="headerlink" title="转移概率 transition"></a>转移概率 transition</h3><p>agent 处于状态 $s$ 下，执行动作 $a$ 后，会转移到状态 $s’$ 的概率。</p><h3 id="奖励-reward"><a href="#奖励-reward" class="headerlink" title="奖励 reward"></a>奖励 reward</h3><p>agent 处于状态 $s$ 下，执行动作 $a$ 后，转移到状态 $s’$ 后获得的立即奖励值。</p><h3 id="策略-Policy"><a href="#策略-Policy" class="headerlink" title="策略 Policy"></a>策略 Policy</h3><p>策略 $\pi$ 是概率的集合或分布，其元素 $\pi(a|s)$ 为对过程中的<strong>某一状态 $s$ 采取可能的行为 $a$ 的概率</strong>。</p><p>agent 处于状态 $s$ 下，应执行动作 $a$ 的概率。</p><p>一个策略定义了个体在各个状态下的各种可能的行为方式以及其概率的大小。</p><h3 id="回报-Return"><a href="#回报-Return" class="headerlink" title="回报 Return"></a>回报 Return</h3><p>回报 $G_t$ 为在一个马尔可夫奖励链上<strong>从 $t$ 时刻开始往后所有的奖励的有衰减的总和</strong>。</p><h3 id="价值函数-Value-Function"><a href="#价值函数-Value-Function" class="headerlink" title="价值函数 Value Function"></a>价值函数 Value Function</h3><p>价值函数给出了某一状态或某一行为的长期价值。</p><p>某一状态的价值函数为从该状态开始的马尔可夫链收获的期望。</p><p><strong>Bellman Optimality Equation</strong></p><p>针对 $V*$，一个状态的最优价值等于从该状态出发采取的所有行为产生的行为价值中<strong>最大的</strong>那个行为价值：<br>$$<br>V_*(s)=\max_aq_*(s,a)<br>$$</p><h2 id="值函数"><a href="#值函数" class="headerlink" title="值函数"></a>值函数</h2><h3 id="状态值函数-State-Value-Function"><a href="#状态值函数-State-Value-Function" class="headerlink" title="状态值函数 State Value Function"></a>状态值函数 State Value Function</h3><p>$V^\pi(s)$ 为状态值函数，表示从状态 $s$ 开始，执行策略 $\pi$ 得到的期望总回报：<br>$$<br>V^\pi(s)=E_{r\sim p(r)}[\sum^{T-1}<em>{t=0}\gamma^t·r</em>{t+1}|\tau_{s_0}=s]<br>$$<br>其中 $\tau_{s_0}$ 表示轨迹 $\gamma$ 的起始状态。<br>$$<br>V^\pi(s)=E_{a\sim\pi}(a|s)E_{s’\sim p(s’|s,a)}[r(s,a,s’)+\gamma V^\pi(s’)]<br>$$<br>$$<br>\downarrow<br>$$<br>Bellman equation，表示当前状态的值函数可以通过下个状态的值函数来计算。</p><h3 id="状态——动作值函数"><a href="#状态——动作值函数" class="headerlink" title="状态——动作值函数"></a>状态——动作值函数</h3><p>也叫 Q 函数，Q-function。指初始状态为 $s$ 并进行动作 $a$，然后执行策略 $\pi$ 得到的期望总回报，即 state-action value function。<br>$$<br>Q^\pi(s,a)=E_{s’\sim p(s’|s,a)}[r(s,a,s’)+\gamma·V^\pi(s’)]<br>$$<br>也可以写成：<br>$$<br>Q^\pi(s,a)=E_{s’\sim p(s’|s,a)}[r(s,a,s’)+\gamma·E_{a’\sim\pi(a’|s’)}[Q^\pi(s’,a’)]]<br>$$<br>$$<br>\uparrow<br>$$<br>$$<br>Q 函数的 Bellman 方程<br>$$</p><hr><p><strong>基于值函数的策略学习方法</strong></p><p>主要分为<strong>动态规划</strong>和<strong>蒙特卡罗</strong>。</p><h2 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a>动态规划</h2><p>动态规划又分为<strong>策略迭代（policy iteration）</strong>算法和<strong>值迭代（value iteration）</strong>算法。</p><h3 id="策略迭代"><a href="#策略迭代" class="headerlink" title="策略迭代"></a>策略迭代</h3><ol><li><p>策略评估 policy evaluation</p><p>计算当前策略下，每个状态的值函数。可以通过 Bellman 方程进行迭代计算$V^\pi(s)$。</p></li><li><p>策略改进 policy improvement</p><p>根据值函数更新策略。</p></li></ol><h3 id="值迭代"><a href="#值迭代" class="headerlink" title="值迭代"></a>值迭代</h3><p>将策略评估与策略改进合并，来直接计算出最优策略。</p><p><img data-src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ffa8e4064-5d63-4df0-8f3f-32c995f14cf7%2FUntitled.png?table=block&id=2b8da031-5dfa-42e4-896a-c378c414d599&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=1400&userId=&cache=v2" alt="策略迭代 vs 值迭代"><span class="image-caption">策略迭代 vs 值迭代</span></p><h2 id="蒙特卡罗"><a href="#蒙特卡罗" class="headerlink" title="蒙特卡罗"></a>蒙特卡罗</h2><p>Q 函数。$Q^\pi(s,a)$ 为初始状态为 $s$，并执行动作 $a$ 后所能得到的期望总回报。<br>$$<br>Q^\pi(s,a)=E_{r\sim p(r)}[G(\tau_{s_0}=s,a_0=a)]<br>$$<br>$\tau_{s_0}=s，a_0=a$ 表示轨迹 $\tau$ 的起始状态和动作为$s$，$a$。</p><h3 id="蒙特卡罗方法"><a href="#蒙特卡罗方法" class="headerlink" title="蒙特卡罗方法"></a>蒙特卡罗方法</h3><p>Q 函数通过<strong>采样</strong>进行计算。</p><p>对于一个策略 $\pi$，agent 从状态 $s$，执行动作 $a$ 开始，然后通过随机游走的方法探索环境，并计算其总回报。</p><p>在得到 Q 函数 $Q^\pi(s,a)$ 之后，进行策略改进，在新策略下采样估计 Q 函数，不断重复。</p><h3 id="epsilon-贪心法"><a href="#epsilon-贪心法" class="headerlink" title="$\epsilon$-贪心法"></a>$\epsilon$-贪心法</h3><p>$$<br>\pi^\epsilon=\begin{cases}<br>\pi(s),按概率1-\epsilon\<br>随机选择\mathcal{A}中的动作，按概率\epsilon<br>\end{cases}<br>$$</p><p>将一个仅利用的策略转为带探索的策略，每次选择动作 $\pi(s)$ 的概率为 $1-\epsilon+\frac{1}{|\mathcal{A}|}$，其它动作的概率为 $\frac{1}{\mathcal{A}}$。</p><p><img data-src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fa460b2a9-25c7-4c7b-b9d8-89f2ebe3b4a3%2FUntitled.png?table=block&id=f7e70acc-b9e4-49ad-9f73-65e88be88f75&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=1380&userId=&cache=v2" alt="同策略与异策略"><span class="image-caption">同策略与异策略</span></p><h2 id="时序差分学习方法"><a href="#时序差分学习方法" class="headerlink" title="时序差分学习方法"></a>时序差分学习方法</h2><p>蒙特卡罗采样方法一般需要拿到完整的轨迹，才能对策略进行评估并更新模型，因此效率较低。</p><p><strong>时序差分学习（temporal-difference learning）</strong>结合了动态规划和蒙特卡罗方法：模拟一段轨迹，每行动一步（或几步）就利用 Bellman 方程来评估行动前状态的值。（当每次更新动作数为最大数时，就等价于蒙特卡罗方法）。</p><h3 id="SARSA-算法"><a href="#SARSA-算法" class="headerlink" title="SARSA 算法"></a>SARSA 算法</h3><p><strong>State Action Reward State Action</strong></p><p>只需要知道当前状态 $s$ 和动作 $a$，奖励 $r(s,a,s’)$，下一步的状态 $s’$ 和动作 $a’$，其采样和优化的策略都是 $\pi^\epsilon$，因此是同策略。<br>$$<br>Q^\pi(s,a)\longleftarrow Q^\pi(s,a)+\alpha(r(s,a,s’)+rQ^\pi(s’,a’)-Q^\pi(s,a))<br>$$</p><p><img data-src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F3c4449b1-30c6-49a5-b0eb-a3f6b0b27e79%2FUntitled.png?table=block&id=c036d6ba-ecde-4ba2-8571-d4bdb3a7982e&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=1330&userId=&cache=v2" alt="SARSA 算法"><span class="image-caption">SARSA 算法</span></p><h3 id="Q-学习算法"><a href="#Q-学习算法" class="headerlink" title="Q 学习算法"></a>Q 学习算法</h3><p><strong>Q-learning</strong><br>$$<br>Q(s,a)\longleftarrow Q(s,a)+\alpha(r+\gamma\max_{a’}Q(s’,a’)-Q(s,a))<br>$$</p><p><img data-src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F113bff08-4673-463a-ad01-9e6a6d9b932f%2FUntitled.png?table=block&id=58cefee8-f331-438f-89bb-ec4b8974be2f&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=1280&userId=&cache=v2" alt="Q-learning 算法"><span class="image-caption">Q-learning 算法</span></p><p>与 SARSA 不同，Q-learning 不通过 $\pi^\epsilon$ 来选下一步的动作 $a’$，而是<strong>直接选最优的 Q 函数</strong>。更新后的 Q 函数是关于策略 $\pi$ 的，而不是策略 $\pi^\epsilon$ 的。</p>]]></content>
      
      
      <categories>
          
          <category> 强化学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 马尔可夫 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>二分图与完美匹配</title>
      <link href="/2019/11/04/%E4%BA%8C%E5%88%86%E5%9B%BE%E4%B8%8E%E5%AE%8C%E7%BE%8E%E5%8C%B9%E9%85%8D/"/>
      <url>/2019/11/04/%E4%BA%8C%E5%88%86%E5%9B%BE%E4%B8%8E%E5%AE%8C%E7%BE%8E%E5%8C%B9%E9%85%8D/</url>
      
        <content type="html"><![CDATA[<h2 id="二分图定义"><a href="#二分图定义" class="headerlink" title="二分图定义"></a>二分图定义</h2><p>可以把图中的点分成两部分，使得每部分内部两两点之间没有连边。</p><h2 id="判定是否是二分图"><a href="#判定是否是二分图" class="headerlink" title="判定是否是二分图"></a>判定是否是二分图</h2><p>没有奇数环的图，或者能够黑白染色（染色问题）的图。</p><h2 id="完美匹配"><a href="#完美匹配" class="headerlink" title="完美匹配"></a>完美匹配</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>一个图的最大匹配中的每个点都是匹配点</p><h3 id="Hall-定理"><a href="#Hall-定理" class="headerlink" title="Hall 定理"></a>Hall 定理</h3><p>设 $G$ 是具有二划分 $(X, Y)$ 的二部图，则G有饱和X的匹配当且仅当对 $∀S ⊆ X ， N ( S ) ≥ |S|$，其中 $N(S)$ 表示 $S$ 的所有邻点之集。</p><p>通俗的说，即**选择任意的左部点 $S$ 个，把所有这 $S$ 个点关联的 $K$ 个右部点取出来，一定有 $|S|&lt;=|K|$**。如果满足这个条件，则是二分图。</p><h3 id="Tutte-定理"><a href="#Tutte-定理" class="headerlink" title="Tutte 定理"></a>Tutte 定理</h3><blockquote><p>A graph, <em>G</em> = (<em>V</em>, <em>E</em>), has a <a href="https://en.wikipedia.org/wiki/Perfect_matching">perfect matching</a> <a href="https://en.wikipedia.org/wiki/If_and_only_if">if and only if</a> for every subset <em>U</em> of <em>V</em>, the <a href="https://en.wikipedia.org/wiki/Glossary_of_graph_theory#Subgraphs">subgraph</a> induced by <em>V</em> − <em>U</em> has at most |<em>U</em>| <a href="https://en.wikipedia.org/wiki/Connected_component_(graph_theory)">connected components</a> with an odd number of <a href="https://en.wikipedia.org/wiki/Vertex_(graph_theory)">vertices</a>.</p></blockquote><p>图 $G$ 有完美匹配的充分必要条件是**对 $∀S ⊂ V (G) ， O (G \setminus S ) ≤| S |$**。</p><p>即图 $G$ 有完美匹配等价于，对于图 $G$ 去掉任意一个点集之后，图的奇分支的个数小于等于点集的个数（奇分支：有奇数个点的分支）。</p><p>例如，对于下图，证明其是否有完美匹配。</p><p><img data-src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F28516a4d-ef70-4cad-b9dd-85d6106d8445%2FUntitled.png?table=block&id=394f123e-f5d3-48b8-9d8d-6282899d24aa&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=1300&userId=&cache=v2"></p><p>可以在图中挑出一些点，使得点与点之间分隔后的部分有<strong>奇数</strong>个顶点，然后比较挑出的点的数量，与分隔后的部分的数量的大小。如果分隔后部分的数量小于等于挑出点的数量，则有完美匹配。</p><p><img data-src="https://www.notion.so/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F1ea4428a-cbc5-4cf5-89b4-f47ede43afff%2FUntitled.png?table=block&id=fb4cf1c4-847a-4c30-81da-1fcad9878c05&spaceId=77b9deb7-cc8a-4bc2-82c7-73fdf2893565&width=1300&userId=&cache=v2"></p><p>如上图所示，挑出 12 个红点，这 12 个红点将图分成了 14 个部分（每个部分必须含有奇数个顶点）。因为 12 &lt; 14，不满足 Tutte 定理，所以这个图没有完美匹配。</p>]]></content>
      
      
      <categories>
          
          <category> 图论 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 二分图 </tag>
            
            <tag> 完美匹配 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
